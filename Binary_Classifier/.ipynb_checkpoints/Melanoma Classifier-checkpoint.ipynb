{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdbb5c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'archive', 'skin-lesion-classification-acc-90-pytorch.ipynb', 'test_database']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# python libraties\n",
    "import os, cv2,itertools, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# to make the results are reproducible\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea261e1",
   "metadata": {},
   "source": [
    "## Step 1: Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84e4ab",
   "metadata": {},
   "source": [
    "We are working with the HAM10000 dataset. The goal is to build a binary classifier to detect benign moles from melanoma. We know the metadata file contains 7 classes. Since some of them are really under-represented in the dataset, we have chosen to bind the class 'Melanocytic nevi' and 'Benign keratosis-like lesion' as the 'benign' class, and the 'melanoma' as the malignant class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d4d70",
   "metadata": {},
   "source": [
    "First, from the original HAM10000_metadata.csv file, we want to extract the one which are from the 3 classes of interests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53347642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/original/HAM10000_metadata.csv\")\n",
    "\n",
    "# Filter classes of interest\n",
    "filtered_lesions = ['nv', 'mel', 'bkl']\n",
    "df = df[df['dx'].isin(filtered_lesions)]\n",
    "\n",
    "# Creating benign and malignant classes\n",
    "df['class'] = df['dx'].apply(lambda x: 'benign' if x in ['nv', 'blk'] else 'malignant')\n",
    "\n",
    "# Saving obtained csv\n",
    "df.to_csv('dataset/new/filtered_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd79c1",
   "metadata": {},
   "source": [
    "Create a dictionary with key being the ISIC id and the value the path to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "907d0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set(df['image_id'])\n",
    "dest_dir = 'dataset/new/images'\n",
    "data_dir = 'dataset/original' #database directory\n",
    "\n",
    "# find all files with jpg extension in database directory\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*.jpg')) \n",
    "\n",
    "# map base filaname to its path\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "\n",
    "# copy all images from new metadata file\n",
    "for id in ids: \n",
    "    shutil.copy(imageid_path_dict[id], dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f2a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_path = glob(os.path.join('dataset/new', '*', '*.jpg'))\n",
    "new_imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in new_image_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4cc58e",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4358c",
   "metadata": {},
   "source": [
    "Compute mean and standard deviation over all images, will be used for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f970690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_img_mean_std(image_paths):\n",
    "    \"\"\"\n",
    "        computing the mean and std of three channel on the whole dataset,\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "\n",
    "    img_h, img_w = 224, 224\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    means.reverse()  # BGR --> RGB\n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    return means,stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964c8c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8917/8917 [00:50<00:00, 177.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3, 8917)\n",
      "normMean = [0.7619418, 0.5393057, 0.5631409]\n",
      "normStd = [0.14422414, 0.15430163, 0.17232743]\n"
     ]
    }
   ],
   "source": [
    "norm_mean,norm_std = compute_img_mean_std(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b5b0a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0027419.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0025030.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0026769.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0025661.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0031633.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization      class  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp  malignant   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp  malignant   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp  malignant   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp  malignant   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear  malignant   \n",
       "\n",
       "                                  path  \n",
       "0  dataset/new\\images\\ISIC_0027419.jpg  \n",
       "1  dataset/new\\images\\ISIC_0025030.jpg  \n",
       "2  dataset/new\\images\\ISIC_0026769.jpg  \n",
       "3  dataset/new\\images\\ISIC_0025661.jpg  \n",
       "4  dataset/new\\images\\ISIC_0031633.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add path to image dataframe\n",
    "df['path'] = df['image_id'].map(new_imageid_path_dict.get)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d3d49",
   "metadata": {},
   "source": [
    "The next cells are here to extract the images that are unduplicated in the dataset, and creates a validation set from them. This is because we do not want images both in training and validation set.\n",
    "\n",
    "Note: the validation set is created from 20% of the unduplicated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c08771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  image_id  dx  dx_type  age  sex  localization  class  path\n",
       "0  HAM_0000001         1   1        1    1    1             1      1     1\n",
       "1  HAM_0000003         1   1        1    1    1             1      1     1\n",
       "2  HAM_0000004         1   1        1    1    1             1      1     1\n",
       "3  HAM_0000007         1   1        1    1    1             1      1     1\n",
       "4  HAM_0000008         1   1        1    1    1             1      1     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get how many images are assiocated to each lesion id from HAM dataset\n",
    "df_undup = df.groupby('lesion_id').count()\n",
    "\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "df_undup.reset_index(inplace=True) #reset the indexes from the df_undup\n",
    "df_undup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f517f18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "      <th>duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0027419.jpg</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0025030.jpg</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0026769.jpg</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0025661.jpg</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0031633.jpg</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization      class  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp  malignant   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp  malignant   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp  malignant   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp  malignant   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear  malignant   \n",
       "\n",
       "                                  path  duplicates  \n",
       "0  dataset/new\\images\\ISIC_0027419.jpg  duplicated  \n",
       "1  dataset/new\\images\\ISIC_0025030.jpg  duplicated  \n",
       "2  dataset/new\\images\\ISIC_0026769.jpg  duplicated  \n",
       "3  dataset/new\\images\\ISIC_0025661.jpg  duplicated  \n",
       "4  dataset/new\\images\\ISIC_0031633.jpg  duplicated  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we identify lesion_id's that have duplicate images and those that have only one image.\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_undup['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'\n",
    "\n",
    "# create a new colum that is a copy of the lesion_id column\n",
    "df['duplicates'] = df['lesion_id']\n",
    "# apply the function to this new column\n",
    "df['duplicates'] = df['duplicates'].apply(get_duplicates)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c1c940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unduplicated    5085\n",
       "duplicated      3832\n",
       "Name: duplicates, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1534a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we filter out images that don't have duplicates\n",
    "df_undup = df[df['duplicates'] == 'unduplicated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5acb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "      <th>duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HAM_0001396</td>\n",
       "      <td>ISIC_0025276</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0025276.jpg</td>\n",
       "      <td>unduplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAM_0007207</td>\n",
       "      <td>ISIC_0031326</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0031326.jpg</td>\n",
       "      <td>unduplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HAM_0006071</td>\n",
       "      <td>ISIC_0032343</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0032343.jpg</td>\n",
       "      <td>unduplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HAM_0005612</td>\n",
       "      <td>ISIC_0024981</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0024981.jpg</td>\n",
       "      <td>unduplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HAM_0005388</td>\n",
       "      <td>ISIC_0027815</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>malignant</td>\n",
       "      <td>dataset/new\\images\\ISIC_0027815.jpg</td>\n",
       "      <td>unduplicated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id      image_id   dx dx_type   age     sex localization  \\\n",
       "10  HAM_0001396  ISIC_0025276  bkl   histo  55.0  female        trunk   \n",
       "15  HAM_0007207  ISIC_0031326  bkl   histo  65.0    male         back   \n",
       "20  HAM_0006071  ISIC_0032343  bkl   histo  70.0  female         face   \n",
       "33  HAM_0005612  ISIC_0024981  bkl   histo  80.0    male        scalp   \n",
       "34  HAM_0005388  ISIC_0027815  bkl   histo  80.0    male        chest   \n",
       "\n",
       "        class                                 path    duplicates  \n",
       "10  malignant  dataset/new\\images\\ISIC_0025276.jpg  unduplicated  \n",
       "15  malignant  dataset/new\\images\\ISIC_0031326.jpg  unduplicated  \n",
       "20  malignant  dataset/new\\images\\ISIC_0032343.jpg  unduplicated  \n",
       "33  malignant  dataset/new\\images\\ISIC_0024981.jpg  unduplicated  \n",
       "34  malignant  dataset/new\\images\\ISIC_0027815.jpg  unduplicated  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_undup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a247805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we create a validation set using df because we are sure that none of these images have augmented duplicates in the train set\n",
    "y = df_undup['class']\n",
    "_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5162700f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benign       883\n",
       "malignant    134\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ed1693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benign       4415\n",
       "malignant     670\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b03aa8",
   "metadata": {},
   "source": [
    "Now we want to exclude all the rows that we put in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16199e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This set will be df_original excluding all rows that are in the val set\n",
    "# This function identifies if an image is part of the train or val set.\n",
    "def get_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "# create a new colum that is a copy of the image_id column, and apply the get_val_rows function\n",
    "df['train_or_val'] = df['image_id']\n",
    "df['train_or_val'] = df['train_or_val'].apply(get_val_rows)\n",
    "\n",
    "df_train = df[df['train_or_val'] == 'train'] #keep the train rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b304b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7900\n",
      "1017\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b5f65db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benign       5822\n",
       "malignant    2078\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85b5df3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benign       883\n",
       "malignant    134\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68e704",
   "metadata": {},
   "source": [
    "### Class imbalance issue\n",
    "In the training set, malignant image represent approximately 26% of the dataframe, but only 13% from the validation set. This seems might be because we created the validation set from duplicated images only, maybe indicating that there are more duplicateds from benign cancer. This is an issue that we might want to mitigate later. For now, we will apply an augmentation rate of 3, as I think the issue linked to class balancing will mostly presents itself during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a43412c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malignant    6234\n",
       "benign       5822\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy fewer class to balance the number of 7 classes\n",
    "malignant_augmentation_rate = 3\n",
    "#if rate = 3 => me must add it 3-1 = 2 times\n",
    "\n",
    "df_train=df_train.append([df_train.loc[df_train['class'] == 'malignant',:]]*(malignant_augmentation_rate-1), ignore_index=True)\n",
    "df_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f092292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At the end, reset the pandas dataframe index\n",
    "df_train = df_train.reset_index()\n",
    "df_val = df_val.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d47a6",
   "metadata": {},
   "source": [
    "## Step 3: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0580800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extract is a boolean that defines if we are finetuning or feature extracting. \n",
    "# If feature_extract = False, the model is finetuned and all model parameters are updated. \n",
    "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "713e62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18, resnet34, resnet50, resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet121\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703ddfd",
   "metadata": {},
   "source": [
    "###### Note: it might be interesting to see how the model behave with feature_extract set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ec411f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Build the desired model\n",
    "model_name = 'densenet'\n",
    "num_classes = 2\n",
    "feature_extract = False\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") #on laptop, use cpu torch\n",
    "\n",
    "# device = torch.device('cuda:0')\n",
    "print(device)\n",
    "# Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f82bff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transformation of the train images.\n",
    "train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n",
    "# define the transformation of the val images.\n",
    "val_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "110c26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_int(cls):\n",
    "    if cls == 'benign':\n",
    "        return 0\n",
    "    elif cls == \"malignant\":\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"There was smtg weird, return 1 to avoid crashing\")\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6755963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0 #3400 is benign\n",
    "class_to_int(df_train['class'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cb42fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pytorch dataloader for this dataset\n",
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(class_to_int(df_train['class'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "826d8733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the training set using the table train_df and using our defined transitions (train_transform)\n",
    "training_set = HAM10000(df_train, transform=train_transform)\n",
    "#NOTE: previously set batch_size to 32\n",
    "train_loader = DataLoader(training_set, shuffle=True)\n",
    "# train_loader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Same for the validation set:\n",
    "validation_set = HAM10000(df_val, transform=train_transform)\n",
    "val_loader = DataLoader(validation_set, shuffle=False)\n",
    "# val_loader = DataLoader(validation_set, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7444a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use Adam optimizer, use cross entropy loss as our loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ee91ce62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4564f8",
   "metadata": {},
   "source": [
    "## Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6689fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used during training, to compute the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "12d26735",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        #print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c53ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 10\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
