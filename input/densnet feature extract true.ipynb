{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very interesting task and it's very suitable for beginners, through this task you can learn about data analysis, data processing, model building, model training, parameter optimization and so on. When only use the images, with a common network, such as Resnet, Densenet, you can achieve a relatively good accuracy very easily. \n",
    "\n",
    "By analyzing the data, the basic information of the patient is also related to the classification of the diseased tissue. Therefore, if we can combine the case information to carry out the classification task, it will be a very meaningful work. Actually during clinical diagnosis, doctors will also combine different modal data to make comprehensive judgments.\n",
    "\n",
    "Due to the urgency of time, my current method only uses image data, and then I will consider adding the patient's personal information to the classification task to train a more complete model. I will update my kernel immediately once I finished.\n",
    "\n",
    "Before you really start, I strongly recommend you to read the material of pigmented lesions and dermatoscopic images[https://arxiv.org/abs/1803.10417]. After that, you can learn about the characteristics and distribution of the data from the task description and this kernel[https://www.kaggle.com/kmader/dermatology-mnist-loading-and-processing]\n",
    "\n",
    "In this kernel I have followed following steps for model building and evaluation: \n",
    "\n",
    "> Step 1. Data analysis and preprocessing\n",
    "\n",
    "> Step 2. Model building\n",
    "\n",
    "> Step 3. Model training\n",
    "\n",
    "> Step 4. Model evaluation\n",
    "\n",
    "I used the pytorch framework to complete the entire task. The code contains several common networks, such as Resnet, VGG, Densenet, and Inception. You only need to make minor changes on the code to complete the network switch. Without the hyperparameter adjustment, I used **Densenet-121 to achieve an accuracy of more than 90% on the validation set in 10 epochs.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### First, import all libraries that used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tapioca\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HAM10000_images_part_1', 'HAM10000_images_part_2', 'HAM10000_metadata.csv', 'hmnist_28_28_L.csv', 'hmnist_28_28_RGB.csv', 'hmnist_8_8_L.csv', 'hmnist_8_8_RGB.csv', 'skin-lesion-classification-acc-90-pytorch.ipynb']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# python libraties\n",
    "import os, cv2,itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# to make the results are reproducible\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Data analysis and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the all image data pathsï¼Œ match the row information in HAM10000_metadata.csv with its corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_dir = '../input'\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*.jpg'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to compute the mean and standard deviation on the whole dataset, will use for inputs normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_img_mean_std(image_paths):\n",
    "    \"\"\"\n",
    "        computing the mean and std of three channel on the whole dataset,\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "\n",
    "    img_h, img_w = 224, 224\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    means.reverse()  # BGR --> RGB\n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    return means,stdevs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the mean and std of RGB channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_mean,norm_std = compute_img_mean_std(all_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add three columns to the original DataFrame, path (image path), cell_type (the whole name),cell_type_idx (the corresponding index  of cell type, as the image label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input\\HAM10000_images_part_1\\ISIC_0027419.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input\\HAM10000_images_part_1\\ISIC_0025030.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input\\HAM10000_images_part_1\\ISIC_0026769.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input\\HAM10000_images_part_1\\ISIC_0025661.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>../input\\HAM10000_images_part_2\\ISIC_0031633.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                               path  \\\n",
       "0  ../input\\HAM10000_images_part_1\\ISIC_0027419.jpg   \n",
       "1  ../input\\HAM10000_images_part_1\\ISIC_0025030.jpg   \n",
       "2  ../input\\HAM10000_images_part_1\\ISIC_0026769.jpg   \n",
       "3  ../input\\HAM10000_images_part_1\\ISIC_0025661.jpg   \n",
       "4  ../input\\HAM10000_images_part_2\\ISIC_0031633.jpg   \n",
       "\n",
       "                        cell_type  cell_type_idx  \n",
       "0  Benign keratosis-like lesions               2  \n",
       "1  Benign keratosis-like lesions               2  \n",
       "2  Benign keratosis-like lesions               2  \n",
       "3  Benign keratosis-like lesions               2  \n",
       "4  Benign keratosis-like lesions               2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(os.path.join(data_dir, 'HAM10000_metadata.csv'))\n",
    "df_original['path'] = df_original['image_id'].map(imageid_path_dict.get)\n",
    "df_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)\n",
    "df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0000004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0000007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0000008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id  image_id  dx  dx_type  age  sex  localization  path  \\\n",
       "0  HAM_0000001         1   1        1    1    1             1     1   \n",
       "1  HAM_0000003         1   1        1    1    1             1     1   \n",
       "2  HAM_0000004         1   1        1    1    1             1     1   \n",
       "3  HAM_0000007         1   1        1    1    1             1     1   \n",
       "4  HAM_0000008         1   1        1    1    1             1     1   \n",
       "\n",
       "   cell_type  cell_type_idx  \n",
       "0          1              1  \n",
       "1          1              1  \n",
       "2          1              1  \n",
       "3          1              1  \n",
       "4          1              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will tell us how many images are associated with each lesion_id\n",
    "df_undup = df_original.groupby('lesion_id').count()\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "df_undup.reset_index(inplace=True)\n",
    "df_undup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "      <th>duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input\\HAM10000_images_part_1\\ISIC_0027419.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input\\HAM10000_images_part_1\\ISIC_0025030.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input\\HAM10000_images_part_1\\ISIC_0026769.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input\\HAM10000_images_part_1\\ISIC_0025661.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>../input\\HAM10000_images_part_2\\ISIC_0031633.jpg</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                               path  \\\n",
       "0  ../input\\HAM10000_images_part_1\\ISIC_0027419.jpg   \n",
       "1  ../input\\HAM10000_images_part_1\\ISIC_0025030.jpg   \n",
       "2  ../input\\HAM10000_images_part_1\\ISIC_0026769.jpg   \n",
       "3  ../input\\HAM10000_images_part_1\\ISIC_0025661.jpg   \n",
       "4  ../input\\HAM10000_images_part_2\\ISIC_0031633.jpg   \n",
       "\n",
       "                        cell_type  cell_type_idx  duplicates  \n",
       "0  Benign keratosis-like lesions               2  duplicated  \n",
       "1  Benign keratosis-like lesions               2  duplicated  \n",
       "2  Benign keratosis-like lesions               2  duplicated  \n",
       "3  Benign keratosis-like lesions               2  duplicated  \n",
       "4  Benign keratosis-like lesions               2  duplicated  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we identify lesion_id's that have duplicate images and those that have only one image.\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_undup['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'\n",
    "\n",
    "# create a new colum that is a copy of the lesion_id column\n",
    "df_original['duplicates'] = df_original['lesion_id']\n",
    "# apply the function to this new column\n",
    "df_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unduplicated    5514\n",
       "duplicated      4501\n",
       "Name: duplicates, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5514, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we filter out images that don't have duplicates\n",
    "df_undup = df_original[df_original['duplicates'] == 'unduplicated']\n",
    "df_undup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we create a val set using df because we are sure that none of these images have augmented duplicates in the train set\n",
    "y = df_undup['cell_type_idx']\n",
    "_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    883\n",
       "2     88\n",
       "6     46\n",
       "1     35\n",
       "0     30\n",
       "5     13\n",
       "3      8\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8912\n",
      "1103\n"
     ]
    }
   ],
   "source": [
    "# This set will be df_original excluding all rows that are in the val set\n",
    "# This function identifies if an image is part of the train or val set.\n",
    "def get_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_original['train_or_val'] = df_original['image_id']\n",
    "# apply the function to this new column\n",
    "df_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)\n",
    "# filter out train rows\n",
    "df_train = df_original[df_original['train_or_val'] == 'train']\n",
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5822\n",
       "6    1067\n",
       "2    1011\n",
       "1     479\n",
       "0     297\n",
       "5     129\n",
       "3     107\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi                  883\n",
       "Benign keratosis-like lesions      88\n",
       "dermatofibroma                     46\n",
       "Basal cell carcinoma               35\n",
       "Actinic keratoses                  30\n",
       "Vascular lesions                   13\n",
       "Dermatofibroma                      8\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From From the above statistics of each category, we can see that there is a serious class imbalance in the training data. To solve this problem, I think we can start from two aspects, one is equalization sampling, and the other is a loss function that can be used to mitigate category imbalance during training, such as focal loss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tapioca\\AppData\\Local\\Temp\\ipykernel_62800\\1237178497.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi                  5822\n",
       "Dermatofibroma                    5350\n",
       "dermatofibroma                    5335\n",
       "Vascular lesions                  5160\n",
       "Benign keratosis-like lesions     5055\n",
       "Basal cell carcinoma              4790\n",
       "Actinic keratoses                 4455\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy fewer class to balance the number of 7 classes\n",
    "data_aug_rate = [15,10,5,50,0,40,5]\n",
    "for i in range(7):\n",
    "    if data_aug_rate[i]:\n",
    "        df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n",
    "df_train['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning, I divided the data into three parts, training set, validation set and test set. Considering the small amount of data, I did not further divide the validation set data in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can split the test set again in a validation set and a true test set:\n",
    "# df_val, df_test = train_test_split(df_val, test_size=0.5)\n",
    "df_train = df_train.reset_index()\n",
    "df_val = df_val.reset_index()\n",
    "# df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extract is a boolean that defines if we are finetuning or feature extracting. \n",
    "# If feature_extract = False, the model is finetuned and all model parameters are updated. \n",
    "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18, resnet34, resnet50, resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet121\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change your backbone network, here are 4 different networks, each network also has sevaral versions. Considering the limited training data, we used the ImageNet pre-training model for fine-tuning. This can speed up the convergence of the model and improve the accuracy.\n",
    "\n",
    "There is one thing you need to pay attention to, the input size of Inception is different from the others (299x299), you need to change the setting of compute_img_mean_std() function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tapioca\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tapioca\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# resnet,vgg,densenet,inception\n",
    "model_name = 'vgg'\n",
    "num_classes = 7\n",
    "feature_extract = True\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# Define the device:\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "# Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "norm_std = (0.24703233, 0.24348505, 0.26158768)\n",
    "# define the transformation of the train images.\n",
    "train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n",
    "# define the transformation of the val images.\n",
    "val_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pytorch dataloader for this dataset\n",
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the training set using the table train_df and using our defined transitions (train_transform)\n",
    "# training_set = HAM10000(df_train, transform=train_transform)\n",
    "# train_loader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "# # Same for the validation set:\n",
    "# validation_set = HAM10000(df_val, transform=train_transform)\n",
    "# val_loader = DataLoader(validation_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Define the training set using the table train_df and using our defined transitions (train_transform)\n",
    "training_set = HAM10000(df_train, transform=train_transform)\n",
    "#NOTE: previously set batch_size to 32\n",
    "train_loader = DataLoader(training_set, shuffle=True)\n",
    "#train_loader = DataLoader(training_set, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "# Same for the validation set:\n",
    "validation_set = HAM10000(df_val, transform=train_transform)\n",
    "val_loader = DataLoader(validation_set, shuffle=False)\n",
    "#val_loader = DataLoader(validation_set, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use Adam optimizer, use cross entropy loss as our loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used during training process, to calculation the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 35967], [train loss 2.57471], [train acc 0.12000]\n",
      "[epoch 1], [iter 200 / 35967], [train loss 2.41840], [train acc 0.12500]\n",
      "[epoch 1], [iter 300 / 35967], [train loss 2.35973], [train acc 0.14667]\n",
      "[epoch 1], [iter 400 / 35967], [train loss 2.34163], [train acc 0.14250]\n",
      "[epoch 1], [iter 500 / 35967], [train loss 2.33546], [train acc 0.12800]\n",
      "[epoch 1], [iter 600 / 35967], [train loss 2.33626], [train acc 0.13500]\n",
      "[epoch 1], [iter 700 / 35967], [train loss 2.32009], [train acc 0.14143]\n",
      "[epoch 1], [iter 800 / 35967], [train loss 2.30581], [train acc 0.14375]\n",
      "[epoch 1], [iter 900 / 35967], [train loss 2.30284], [train acc 0.14333]\n",
      "[epoch 1], [iter 1000 / 35967], [train loss 2.29283], [train acc 0.14200]\n",
      "[epoch 1], [iter 1100 / 35967], [train loss 2.29322], [train acc 0.13909]\n",
      "[epoch 1], [iter 1200 / 35967], [train loss 2.28910], [train acc 0.14000]\n",
      "[epoch 1], [iter 1300 / 35967], [train loss 2.28323], [train acc 0.13923]\n",
      "[epoch 1], [iter 1400 / 35967], [train loss 2.28764], [train acc 0.14071]\n",
      "[epoch 1], [iter 1500 / 35967], [train loss 2.29146], [train acc 0.13733]\n",
      "[epoch 1], [iter 1600 / 35967], [train loss 2.28959], [train acc 0.13750]\n",
      "[epoch 1], [iter 1700 / 35967], [train loss 2.28652], [train acc 0.13882]\n",
      "[epoch 1], [iter 1800 / 35967], [train loss 2.28223], [train acc 0.13944]\n",
      "[epoch 1], [iter 1900 / 35967], [train loss 2.27964], [train acc 0.13789]\n",
      "[epoch 1], [iter 2000 / 35967], [train loss 2.28143], [train acc 0.13650]\n",
      "[epoch 1], [iter 2100 / 35967], [train loss 2.28081], [train acc 0.13667]\n",
      "[epoch 1], [iter 2200 / 35967], [train loss 2.27742], [train acc 0.13864]\n",
      "[epoch 1], [iter 2300 / 35967], [train loss 2.27906], [train acc 0.13783]\n",
      "[epoch 1], [iter 2400 / 35967], [train loss 2.27661], [train acc 0.13833]\n",
      "[epoch 1], [iter 2500 / 35967], [train loss 2.27641], [train acc 0.13840]\n",
      "[epoch 1], [iter 2600 / 35967], [train loss 2.27249], [train acc 0.14077]\n",
      "[epoch 1], [iter 2700 / 35967], [train loss 2.27143], [train acc 0.14074]\n",
      "[epoch 1], [iter 2800 / 35967], [train loss 2.26961], [train acc 0.14107]\n",
      "[epoch 1], [iter 2900 / 35967], [train loss 2.26825], [train acc 0.14000]\n",
      "[epoch 1], [iter 3000 / 35967], [train loss 2.26992], [train acc 0.13900]\n",
      "[epoch 1], [iter 3100 / 35967], [train loss 2.26947], [train acc 0.14000]\n",
      "[epoch 1], [iter 3200 / 35967], [train loss 2.27033], [train acc 0.14000]\n",
      "[epoch 1], [iter 3300 / 35967], [train loss 2.26910], [train acc 0.14000]\n",
      "[epoch 1], [iter 3400 / 35967], [train loss 2.26720], [train acc 0.14029]\n",
      "[epoch 1], [iter 3500 / 35967], [train loss 2.26687], [train acc 0.14057]\n",
      "[epoch 1], [iter 3600 / 35967], [train loss 2.26409], [train acc 0.14111]\n",
      "[epoch 1], [iter 3700 / 35967], [train loss 2.26773], [train acc 0.14135]\n",
      "[epoch 1], [iter 3800 / 35967], [train loss 2.26393], [train acc 0.14395]\n",
      "[epoch 1], [iter 3900 / 35967], [train loss 2.26524], [train acc 0.14308]\n",
      "[epoch 1], [iter 4000 / 35967], [train loss 2.26560], [train acc 0.14275]\n",
      "[epoch 1], [iter 4100 / 35967], [train loss 2.26457], [train acc 0.14244]\n",
      "[epoch 1], [iter 4200 / 35967], [train loss 2.26270], [train acc 0.14310]\n",
      "[epoch 1], [iter 4300 / 35967], [train loss 2.26195], [train acc 0.14395]\n",
      "[epoch 1], [iter 4400 / 35967], [train loss 2.26492], [train acc 0.14227]\n",
      "[epoch 1], [iter 4500 / 35967], [train loss 2.26305], [train acc 0.14178]\n",
      "[epoch 1], [iter 4600 / 35967], [train loss 2.26367], [train acc 0.14217]\n",
      "[epoch 1], [iter 4700 / 35967], [train loss 2.26096], [train acc 0.14340]\n",
      "[epoch 1], [iter 4800 / 35967], [train loss 2.26030], [train acc 0.14375]\n",
      "[epoch 1], [iter 4900 / 35967], [train loss 2.25522], [train acc 0.14612]\n",
      "[epoch 1], [iter 5000 / 35967], [train loss 2.25386], [train acc 0.14540]\n",
      "[epoch 1], [iter 5100 / 35967], [train loss 2.25423], [train acc 0.14569]\n",
      "[epoch 1], [iter 5200 / 35967], [train loss 2.25447], [train acc 0.14500]\n",
      "[epoch 1], [iter 5300 / 35967], [train loss 2.25591], [train acc 0.14415]\n",
      "[epoch 1], [iter 5400 / 35967], [train loss 2.25602], [train acc 0.14463]\n",
      "[epoch 1], [iter 5500 / 35967], [train loss 2.25788], [train acc 0.14491]\n",
      "[epoch 1], [iter 5600 / 35967], [train loss 2.25854], [train acc 0.14429]\n",
      "[epoch 1], [iter 5700 / 35967], [train loss 2.25879], [train acc 0.14439]\n",
      "[epoch 1], [iter 5800 / 35967], [train loss 2.25963], [train acc 0.14500]\n",
      "[epoch 1], [iter 5900 / 35967], [train loss 2.26256], [train acc 0.14475]\n",
      "[epoch 1], [iter 6000 / 35967], [train loss 2.26099], [train acc 0.14417]\n",
      "[epoch 1], [iter 6100 / 35967], [train loss 2.26420], [train acc 0.14344]\n",
      "[epoch 1], [iter 6200 / 35967], [train loss 2.26594], [train acc 0.14274]\n",
      "[epoch 1], [iter 6300 / 35967], [train loss 2.26581], [train acc 0.14317]\n",
      "[epoch 1], [iter 6400 / 35967], [train loss 2.26494], [train acc 0.14344]\n",
      "[epoch 1], [iter 6500 / 35967], [train loss 2.26413], [train acc 0.14354]\n",
      "[epoch 1], [iter 6600 / 35967], [train loss 2.26259], [train acc 0.14424]\n",
      "[epoch 1], [iter 6700 / 35967], [train loss 2.26231], [train acc 0.14448]\n",
      "[epoch 1], [iter 6800 / 35967], [train loss 2.26208], [train acc 0.14485]\n",
      "[epoch 1], [iter 6900 / 35967], [train loss 2.26098], [train acc 0.14493]\n",
      "[epoch 1], [iter 7000 / 35967], [train loss 2.25916], [train acc 0.14629]\n",
      "[epoch 1], [iter 7100 / 35967], [train loss 2.26124], [train acc 0.14577]\n",
      "[epoch 1], [iter 7200 / 35967], [train loss 2.26103], [train acc 0.14542]\n",
      "[epoch 1], [iter 7300 / 35967], [train loss 2.26150], [train acc 0.14493]\n",
      "[epoch 1], [iter 7400 / 35967], [train loss 2.26130], [train acc 0.14568]\n",
      "[epoch 1], [iter 7500 / 35967], [train loss 2.26054], [train acc 0.14493]\n",
      "[epoch 1], [iter 7600 / 35967], [train loss 2.25963], [train acc 0.14474]\n",
      "[epoch 1], [iter 7700 / 35967], [train loss 2.26007], [train acc 0.14429]\n",
      "[epoch 1], [iter 7800 / 35967], [train loss 2.25907], [train acc 0.14500]\n",
      "[epoch 1], [iter 7900 / 35967], [train loss 2.25908], [train acc 0.14494]\n",
      "[epoch 1], [iter 8000 / 35967], [train loss 2.25892], [train acc 0.14438]\n",
      "[epoch 1], [iter 8100 / 35967], [train loss 2.25849], [train acc 0.14407]\n",
      "[epoch 1], [iter 8200 / 35967], [train loss 2.25809], [train acc 0.14488]\n",
      "[epoch 1], [iter 8300 / 35967], [train loss 2.25740], [train acc 0.14566]\n",
      "[epoch 1], [iter 8400 / 35967], [train loss 2.25683], [train acc 0.14583]\n",
      "[epoch 1], [iter 8500 / 35967], [train loss 2.25742], [train acc 0.14635]\n",
      "[epoch 1], [iter 8600 / 35967], [train loss 2.25775], [train acc 0.14640]\n",
      "[epoch 1], [iter 8700 / 35967], [train loss 2.25794], [train acc 0.14575]\n",
      "[epoch 1], [iter 8800 / 35967], [train loss 2.25735], [train acc 0.14511]\n",
      "[epoch 1], [iter 8900 / 35967], [train loss 2.25712], [train acc 0.14483]\n",
      "[epoch 1], [iter 9000 / 35967], [train loss 2.25749], [train acc 0.14456]\n",
      "[epoch 1], [iter 9100 / 35967], [train loss 2.25767], [train acc 0.14429]\n",
      "[epoch 1], [iter 9200 / 35967], [train loss 2.25773], [train acc 0.14446]\n",
      "[epoch 1], [iter 9300 / 35967], [train loss 2.25691], [train acc 0.14527]\n",
      "[epoch 1], [iter 9400 / 35967], [train loss 2.25813], [train acc 0.14468]\n",
      "[epoch 1], [iter 9500 / 35967], [train loss 2.25855], [train acc 0.14432]\n",
      "[epoch 1], [iter 9600 / 35967], [train loss 2.25975], [train acc 0.14365]\n",
      "[epoch 1], [iter 9700 / 35967], [train loss 2.25830], [train acc 0.14423]\n",
      "[epoch 1], [iter 9800 / 35967], [train loss 2.25812], [train acc 0.14408]\n",
      "[epoch 1], [iter 9900 / 35967], [train loss 2.25918], [train acc 0.14414]\n",
      "[epoch 1], [iter 10000 / 35967], [train loss 2.25980], [train acc 0.14430]\n",
      "[epoch 1], [iter 10100 / 35967], [train loss 2.26059], [train acc 0.14386]\n",
      "[epoch 1], [iter 10200 / 35967], [train loss 2.25929], [train acc 0.14402]\n",
      "[epoch 1], [iter 10300 / 35967], [train loss 2.26011], [train acc 0.14417]\n",
      "[epoch 1], [iter 10400 / 35967], [train loss 2.26073], [train acc 0.14433]\n",
      "[epoch 1], [iter 10500 / 35967], [train loss 2.25971], [train acc 0.14457]\n",
      "[epoch 1], [iter 10600 / 35967], [train loss 2.26037], [train acc 0.14462]\n",
      "[epoch 1], [iter 10700 / 35967], [train loss 2.26137], [train acc 0.14449]\n",
      "[epoch 1], [iter 10800 / 35967], [train loss 2.25991], [train acc 0.14491]\n",
      "[epoch 1], [iter 10900 / 35967], [train loss 2.26060], [train acc 0.14468]\n",
      "[epoch 1], [iter 11000 / 35967], [train loss 2.26167], [train acc 0.14473]\n",
      "[epoch 1], [iter 11100 / 35967], [train loss 2.26172], [train acc 0.14468]\n",
      "[epoch 1], [iter 11200 / 35967], [train loss 2.26247], [train acc 0.14482]\n",
      "[epoch 1], [iter 11300 / 35967], [train loss 2.26294], [train acc 0.14487]\n",
      "[epoch 1], [iter 11400 / 35967], [train loss 2.26281], [train acc 0.14500]\n",
      "[epoch 1], [iter 11500 / 35967], [train loss 2.26252], [train acc 0.14478]\n",
      "[epoch 1], [iter 11600 / 35967], [train loss 2.26184], [train acc 0.14517]\n",
      "[epoch 1], [iter 11700 / 35967], [train loss 2.26092], [train acc 0.14581]\n",
      "[epoch 1], [iter 11800 / 35967], [train loss 2.26127], [train acc 0.14508]\n",
      "[epoch 1], [iter 11900 / 35967], [train loss 2.26019], [train acc 0.14504]\n",
      "[epoch 1], [iter 12000 / 35967], [train loss 2.26090], [train acc 0.14492]\n",
      "[epoch 1], [iter 12100 / 35967], [train loss 2.26018], [train acc 0.14512]\n",
      "[epoch 1], [iter 12200 / 35967], [train loss 2.25930], [train acc 0.14574]\n",
      "[epoch 1], [iter 12300 / 35967], [train loss 2.25861], [train acc 0.14602]\n",
      "[epoch 1], [iter 12400 / 35967], [train loss 2.25858], [train acc 0.14621]\n",
      "[epoch 1], [iter 12500 / 35967], [train loss 2.25825], [train acc 0.14592]\n",
      "[epoch 1], [iter 12600 / 35967], [train loss 2.25776], [train acc 0.14603]\n",
      "[epoch 1], [iter 12700 / 35967], [train loss 2.25769], [train acc 0.14567]\n",
      "[epoch 1], [iter 12800 / 35967], [train loss 2.25755], [train acc 0.14578]\n",
      "[epoch 1], [iter 12900 / 35967], [train loss 2.25717], [train acc 0.14605]\n",
      "[epoch 1], [iter 13000 / 35967], [train loss 2.25687], [train acc 0.14615]\n",
      "[epoch 1], [iter 13100 / 35967], [train loss 2.25623], [train acc 0.14603]\n",
      "[epoch 1], [iter 13200 / 35967], [train loss 2.25592], [train acc 0.14583]\n",
      "[epoch 1], [iter 13300 / 35967], [train loss 2.25620], [train acc 0.14609]\n",
      "[epoch 1], [iter 13400 / 35967], [train loss 2.25620], [train acc 0.14597]\n",
      "[epoch 1], [iter 13500 / 35967], [train loss 2.25546], [train acc 0.14615]\n",
      "[epoch 1], [iter 13600 / 35967], [train loss 2.25510], [train acc 0.14640]\n",
      "[epoch 1], [iter 13700 / 35967], [train loss 2.25418], [train acc 0.14672]\n",
      "[epoch 1], [iter 13800 / 35967], [train loss 2.25452], [train acc 0.14688]\n",
      "[epoch 1], [iter 13900 / 35967], [train loss 2.25544], [train acc 0.14691]\n",
      "[epoch 1], [iter 14000 / 35967], [train loss 2.25582], [train acc 0.14679]\n",
      "[epoch 1], [iter 14100 / 35967], [train loss 2.25627], [train acc 0.14667]\n",
      "[epoch 1], [iter 14200 / 35967], [train loss 2.25612], [train acc 0.14655]\n",
      "[epoch 1], [iter 14300 / 35967], [train loss 2.25545], [train acc 0.14643]\n",
      "[epoch 1], [iter 14400 / 35967], [train loss 2.25469], [train acc 0.14688]\n",
      "[epoch 1], [iter 14500 / 35967], [train loss 2.25470], [train acc 0.14697]\n",
      "[epoch 1], [iter 14600 / 35967], [train loss 2.25437], [train acc 0.14685]\n",
      "[epoch 1], [iter 14700 / 35967], [train loss 2.25436], [train acc 0.14680]\n",
      "[epoch 1], [iter 14800 / 35967], [train loss 2.25466], [train acc 0.14689]\n",
      "[epoch 1], [iter 14900 / 35967], [train loss 2.25415], [train acc 0.14671]\n",
      "[epoch 1], [iter 15000 / 35967], [train loss 2.25374], [train acc 0.14667]\n",
      "[epoch 1], [iter 15100 / 35967], [train loss 2.25368], [train acc 0.14682]\n",
      "[epoch 1], [iter 15200 / 35967], [train loss 2.25391], [train acc 0.14678]\n",
      "[epoch 1], [iter 15300 / 35967], [train loss 2.25382], [train acc 0.14686]\n",
      "[epoch 1], [iter 15400 / 35967], [train loss 2.25389], [train acc 0.14688]\n",
      "[epoch 1], [iter 15500 / 35967], [train loss 2.25469], [train acc 0.14665]\n",
      "[epoch 1], [iter 15600 / 35967], [train loss 2.25388], [train acc 0.14718]\n",
      "[epoch 1], [iter 15700 / 35967], [train loss 2.25438], [train acc 0.14688]\n",
      "[epoch 1], [iter 15800 / 35967], [train loss 2.25467], [train acc 0.14690]\n",
      "[epoch 1], [iter 15900 / 35967], [train loss 2.25415], [train acc 0.14667]\n",
      "[epoch 1], [iter 16000 / 35967], [train loss 2.25454], [train acc 0.14644]\n",
      "[epoch 1], [iter 16100 / 35967], [train loss 2.25398], [train acc 0.14646]\n",
      "[epoch 1], [iter 16200 / 35967], [train loss 2.25384], [train acc 0.14667]\n",
      "[epoch 1], [iter 16300 / 35967], [train loss 2.25382], [train acc 0.14656]\n",
      "[epoch 1], [iter 16400 / 35967], [train loss 2.25392], [train acc 0.14701]\n",
      "[epoch 1], [iter 16500 / 35967], [train loss 2.25381], [train acc 0.14691]\n",
      "[epoch 1], [iter 16600 / 35967], [train loss 2.25369], [train acc 0.14693]\n",
      "[epoch 1], [iter 16700 / 35967], [train loss 2.25337], [train acc 0.14701]\n",
      "[epoch 1], [iter 16800 / 35967], [train loss 2.25278], [train acc 0.14720]\n",
      "[epoch 1], [iter 16900 / 35967], [train loss 2.25252], [train acc 0.14722]\n",
      "[epoch 1], [iter 17000 / 35967], [train loss 2.25242], [train acc 0.14724]\n",
      "[epoch 1], [iter 17100 / 35967], [train loss 2.25264], [train acc 0.14713]\n",
      "[epoch 1], [iter 17200 / 35967], [train loss 2.25246], [train acc 0.14698]\n",
      "[epoch 1], [iter 17300 / 35967], [train loss 2.25312], [train acc 0.14659]\n",
      "[epoch 1], [iter 17400 / 35967], [train loss 2.25263], [train acc 0.14690]\n",
      "[epoch 1], [iter 17500 / 35967], [train loss 2.25277], [train acc 0.14691]\n",
      "[epoch 1], [iter 17600 / 35967], [train loss 2.25255], [train acc 0.14705]\n",
      "[epoch 1], [iter 17700 / 35967], [train loss 2.25224], [train acc 0.14684]\n",
      "[epoch 1], [iter 17800 / 35967], [train loss 2.25279], [train acc 0.14663]\n",
      "[epoch 1], [iter 17900 / 35967], [train loss 2.25245], [train acc 0.14676]\n",
      "[epoch 1], [iter 18000 / 35967], [train loss 2.25207], [train acc 0.14678]\n",
      "[epoch 1], [iter 18100 / 35967], [train loss 2.25178], [train acc 0.14718]\n",
      "[epoch 1], [iter 18200 / 35967], [train loss 2.25170], [train acc 0.14736]\n",
      "[epoch 1], [iter 18300 / 35967], [train loss 2.25190], [train acc 0.14721]\n",
      "[epoch 1], [iter 18400 / 35967], [train loss 2.25239], [train acc 0.14685]\n",
      "[epoch 1], [iter 18500 / 35967], [train loss 2.25218], [train acc 0.14692]\n",
      "[epoch 1], [iter 18600 / 35967], [train loss 2.25178], [train acc 0.14726]\n",
      "[epoch 1], [iter 18700 / 35967], [train loss 2.25165], [train acc 0.14749]\n",
      "[epoch 1], [iter 18800 / 35967], [train loss 2.25110], [train acc 0.14729]\n",
      "[epoch 1], [iter 18900 / 35967], [train loss 2.25140], [train acc 0.14746]\n",
      "[epoch 1], [iter 19000 / 35967], [train loss 2.25122], [train acc 0.14742]\n",
      "[epoch 1], [iter 19100 / 35967], [train loss 2.25174], [train acc 0.14723]\n",
      "[epoch 1], [iter 19200 / 35967], [train loss 2.25154], [train acc 0.14729]\n",
      "[epoch 1], [iter 19300 / 35967], [train loss 2.25115], [train acc 0.14731]\n",
      "[epoch 1], [iter 19400 / 35967], [train loss 2.25129], [train acc 0.14742]\n",
      "[epoch 1], [iter 19500 / 35967], [train loss 2.25113], [train acc 0.14723]\n",
      "[epoch 1], [iter 19600 / 35967], [train loss 2.25096], [train acc 0.14714]\n",
      "[epoch 1], [iter 19700 / 35967], [train loss 2.25138], [train acc 0.14731]\n",
      "[epoch 1], [iter 19800 / 35967], [train loss 2.25138], [train acc 0.14732]\n",
      "[epoch 1], [iter 19900 / 35967], [train loss 2.25098], [train acc 0.14749]\n",
      "[epoch 1], [iter 20000 / 35967], [train loss 2.25096], [train acc 0.14740]\n",
      "[epoch 1], [iter 20100 / 35967], [train loss 2.25005], [train acc 0.14796]\n",
      "[epoch 1], [iter 20200 / 35967], [train loss 2.25077], [train acc 0.14807]\n",
      "[epoch 1], [iter 20300 / 35967], [train loss 2.25047], [train acc 0.14793]\n",
      "[epoch 1], [iter 20400 / 35967], [train loss 2.25063], [train acc 0.14814]\n",
      "[epoch 1], [iter 20500 / 35967], [train loss 2.25046], [train acc 0.14820]\n",
      "[epoch 1], [iter 20600 / 35967], [train loss 2.25042], [train acc 0.14791]\n",
      "[epoch 1], [iter 20700 / 35967], [train loss 2.24959], [train acc 0.14831]\n",
      "[epoch 1], [iter 20800 / 35967], [train loss 2.24950], [train acc 0.14793]\n",
      "[epoch 1], [iter 20900 / 35967], [train loss 2.24958], [train acc 0.14794]\n",
      "[epoch 1], [iter 21000 / 35967], [train loss 2.24968], [train acc 0.14790]\n",
      "[epoch 1], [iter 21100 / 35967], [train loss 2.24958], [train acc 0.14787]\n",
      "[epoch 1], [iter 21200 / 35967], [train loss 2.24975], [train acc 0.14769]\n",
      "[epoch 1], [iter 21300 / 35967], [train loss 2.24959], [train acc 0.14770]\n",
      "[epoch 1], [iter 21400 / 35967], [train loss 2.24975], [train acc 0.14790]\n",
      "[epoch 1], [iter 21500 / 35967], [train loss 2.25005], [train acc 0.14805]\n",
      "[epoch 1], [iter 21600 / 35967], [train loss 2.25072], [train acc 0.14824]\n",
      "[epoch 1], [iter 21700 / 35967], [train loss 2.25091], [train acc 0.14816]\n",
      "[epoch 1], [iter 21800 / 35967], [train loss 2.25106], [train acc 0.14830]\n",
      "[epoch 1], [iter 21900 / 35967], [train loss 2.25078], [train acc 0.14836]\n",
      "[epoch 1], [iter 22000 / 35967], [train loss 2.25071], [train acc 0.14809]\n",
      "[epoch 1], [iter 22100 / 35967], [train loss 2.25062], [train acc 0.14801]\n",
      "[epoch 1], [iter 22200 / 35967], [train loss 2.25031], [train acc 0.14788]\n",
      "[epoch 1], [iter 22300 / 35967], [train loss 2.25038], [train acc 0.14789]\n",
      "[epoch 1], [iter 22400 / 35967], [train loss 2.25011], [train acc 0.14813]\n",
      "[epoch 1], [iter 22500 / 35967], [train loss 2.25042], [train acc 0.14809]\n",
      "[epoch 1], [iter 22600 / 35967], [train loss 2.25004], [train acc 0.14801]\n",
      "[epoch 1], [iter 22700 / 35967], [train loss 2.24982], [train acc 0.14789]\n",
      "[epoch 1], [iter 22800 / 35967], [train loss 2.24989], [train acc 0.14772]\n",
      "[epoch 1], [iter 22900 / 35967], [train loss 2.24936], [train acc 0.14786]\n",
      "[epoch 1], [iter 23000 / 35967], [train loss 2.24958], [train acc 0.14783]\n",
      "[epoch 1], [iter 23100 / 35967], [train loss 2.24998], [train acc 0.14779]\n",
      "[epoch 1], [iter 23200 / 35967], [train loss 2.24983], [train acc 0.14772]\n",
      "[epoch 1], [iter 23300 / 35967], [train loss 2.25003], [train acc 0.14777]\n",
      "[epoch 1], [iter 23400 / 35967], [train loss 2.25006], [train acc 0.14769]\n",
      "[epoch 1], [iter 23500 / 35967], [train loss 2.25032], [train acc 0.14770]\n",
      "[epoch 1], [iter 23600 / 35967], [train loss 2.25046], [train acc 0.14763]\n",
      "[epoch 1], [iter 23700 / 35967], [train loss 2.25050], [train acc 0.14755]\n",
      "[epoch 1], [iter 23800 / 35967], [train loss 2.25061], [train acc 0.14765]\n",
      "[epoch 1], [iter 23900 / 35967], [train loss 2.25048], [train acc 0.14749]\n",
      "[epoch 1], [iter 24000 / 35967], [train loss 2.25026], [train acc 0.14758]\n",
      "[epoch 1], [iter 24100 / 35967], [train loss 2.25013], [train acc 0.14793]\n",
      "[epoch 1], [iter 24200 / 35967], [train loss 2.25017], [train acc 0.14785]\n",
      "[epoch 1], [iter 24300 / 35967], [train loss 2.25001], [train acc 0.14786]\n",
      "[epoch 1], [iter 24400 / 35967], [train loss 2.24972], [train acc 0.14803]\n",
      "[epoch 1], [iter 24500 / 35967], [train loss 2.24952], [train acc 0.14808]\n",
      "[epoch 1], [iter 24600 / 35967], [train loss 2.24929], [train acc 0.14821]\n",
      "[epoch 1], [iter 24700 / 35967], [train loss 2.24905], [train acc 0.14806]\n",
      "[epoch 1], [iter 24800 / 35967], [train loss 2.24864], [train acc 0.14786]\n",
      "[epoch 1], [iter 24900 / 35967], [train loss 2.24861], [train acc 0.14783]\n",
      "[epoch 1], [iter 25000 / 35967], [train loss 2.24833], [train acc 0.14796]\n",
      "[epoch 1], [iter 25100 / 35967], [train loss 2.24909], [train acc 0.14773]\n",
      "[epoch 1], [iter 25200 / 35967], [train loss 2.24941], [train acc 0.14766]\n",
      "[epoch 1], [iter 25300 / 35967], [train loss 2.24905], [train acc 0.14791]\n",
      "[epoch 1], [iter 25400 / 35967], [train loss 2.24867], [train acc 0.14799]\n",
      "[epoch 1], [iter 25500 / 35967], [train loss 2.24898], [train acc 0.14788]\n",
      "[epoch 1], [iter 25600 / 35967], [train loss 2.24966], [train acc 0.14781]\n",
      "[epoch 1], [iter 25700 / 35967], [train loss 2.24976], [train acc 0.14782]\n",
      "[epoch 1], [iter 25800 / 35967], [train loss 2.24955], [train acc 0.14806]\n",
      "[epoch 1], [iter 25900 / 35967], [train loss 2.24944], [train acc 0.14807]\n",
      "[epoch 1], [iter 26000 / 35967], [train loss 2.24901], [train acc 0.14815]\n",
      "[epoch 1], [iter 26100 / 35967], [train loss 2.24907], [train acc 0.14805]\n",
      "[epoch 1], [iter 26200 / 35967], [train loss 2.24941], [train acc 0.14798]\n",
      "[epoch 1], [iter 26300 / 35967], [train loss 2.24970], [train acc 0.14821]\n",
      "[epoch 1], [iter 26400 / 35967], [train loss 2.24947], [train acc 0.14807]\n",
      "[epoch 1], [iter 26500 / 35967], [train loss 2.24976], [train acc 0.14785]\n",
      "[epoch 1], [iter 26600 / 35967], [train loss 2.24899], [train acc 0.14823]\n",
      "[epoch 1], [iter 26700 / 35967], [train loss 2.24886], [train acc 0.14828]\n",
      "[epoch 1], [iter 26800 / 35967], [train loss 2.24918], [train acc 0.14825]\n",
      "[epoch 1], [iter 26900 / 35967], [train loss 2.24922], [train acc 0.14829]\n",
      "[epoch 1], [iter 27000 / 35967], [train loss 2.24966], [train acc 0.14833]\n",
      "[epoch 1], [iter 27100 / 35967], [train loss 2.24982], [train acc 0.14841]\n",
      "[epoch 1], [iter 27200 / 35967], [train loss 2.24969], [train acc 0.14831]\n",
      "[epoch 1], [iter 27300 / 35967], [train loss 2.24952], [train acc 0.14839]\n",
      "[epoch 1], [iter 27400 / 35967], [train loss 2.24941], [train acc 0.14821]\n",
      "[epoch 1], [iter 27500 / 35967], [train loss 2.24913], [train acc 0.14836]\n",
      "[epoch 1], [iter 27600 / 35967], [train loss 2.24890], [train acc 0.14855]\n",
      "[epoch 1], [iter 27700 / 35967], [train loss 2.24859], [train acc 0.14870]\n",
      "[epoch 1], [iter 27800 / 35967], [train loss 2.24866], [train acc 0.14867]\n",
      "[epoch 1], [iter 27900 / 35967], [train loss 2.24839], [train acc 0.14871]\n",
      "[epoch 1], [iter 28000 / 35967], [train loss 2.24785], [train acc 0.14896]\n",
      "[epoch 1], [iter 28100 / 35967], [train loss 2.24804], [train acc 0.14900]\n",
      "[epoch 1], [iter 28200 / 35967], [train loss 2.24774], [train acc 0.14897]\n",
      "[epoch 1], [iter 28300 / 35967], [train loss 2.24754], [train acc 0.14894]\n",
      "[epoch 1], [iter 28400 / 35967], [train loss 2.24769], [train acc 0.14880]\n",
      "[epoch 1], [iter 28500 / 35967], [train loss 2.24774], [train acc 0.14867]\n",
      "[epoch 1], [iter 28600 / 35967], [train loss 2.24775], [train acc 0.14878]\n",
      "[epoch 1], [iter 28700 / 35967], [train loss 2.24770], [train acc 0.14875]\n",
      "[epoch 1], [iter 28800 / 35967], [train loss 2.24772], [train acc 0.14875]\n",
      "[epoch 1], [iter 28900 / 35967], [train loss 2.24747], [train acc 0.14875]\n",
      "[epoch 1], [iter 29000 / 35967], [train loss 2.24736], [train acc 0.14869]\n",
      "[epoch 1], [iter 29100 / 35967], [train loss 2.24763], [train acc 0.14863]\n",
      "[epoch 1], [iter 29200 / 35967], [train loss 2.24759], [train acc 0.14870]\n",
      "[epoch 1], [iter 29300 / 35967], [train loss 2.24732], [train acc 0.14857]\n",
      "[epoch 1], [iter 29400 / 35967], [train loss 2.24718], [train acc 0.14861]\n",
      "[epoch 1], [iter 29500 / 35967], [train loss 2.24773], [train acc 0.14854]\n",
      "[epoch 1], [iter 29600 / 35967], [train loss 2.24758], [train acc 0.14861]\n",
      "[epoch 1], [iter 29700 / 35967], [train loss 2.24776], [train acc 0.14845]\n",
      "[epoch 1], [iter 29800 / 35967], [train loss 2.24781], [train acc 0.14839]\n",
      "[epoch 1], [iter 29900 / 35967], [train loss 2.24783], [train acc 0.14843]\n",
      "[epoch 1], [iter 30000 / 35967], [train loss 2.24803], [train acc 0.14827]\n",
      "[epoch 1], [iter 30100 / 35967], [train loss 2.24769], [train acc 0.14827]\n",
      "[epoch 1], [iter 30200 / 35967], [train loss 2.24768], [train acc 0.14808]\n",
      "[epoch 1], [iter 30300 / 35967], [train loss 2.24743], [train acc 0.14812]\n",
      "[epoch 1], [iter 30400 / 35967], [train loss 2.24728], [train acc 0.14826]\n",
      "[epoch 1], [iter 30500 / 35967], [train loss 2.24710], [train acc 0.14830]\n",
      "[epoch 1], [iter 30600 / 35967], [train loss 2.24676], [train acc 0.14833]\n",
      "[epoch 1], [iter 30700 / 35967], [train loss 2.24659], [train acc 0.14831]\n",
      "[epoch 1], [iter 30800 / 35967], [train loss 2.24675], [train acc 0.14828]\n",
      "[epoch 1], [iter 30900 / 35967], [train loss 2.24682], [train acc 0.14835]\n",
      "[epoch 1], [iter 31000 / 35967], [train loss 2.24654], [train acc 0.14848]\n",
      "[epoch 1], [iter 31100 / 35967], [train loss 2.24603], [train acc 0.14865]\n",
      "[epoch 1], [iter 31200 / 35967], [train loss 2.24587], [train acc 0.14875]\n",
      "[epoch 1], [iter 31300 / 35967], [train loss 2.24603], [train acc 0.14879]\n",
      "[epoch 1], [iter 31400 / 35967], [train loss 2.24623], [train acc 0.14882]\n",
      "[epoch 1], [iter 31500 / 35967], [train loss 2.24603], [train acc 0.14902]\n",
      "[epoch 1], [iter 31600 / 35967], [train loss 2.24586], [train acc 0.14911]\n",
      "[epoch 1], [iter 31700 / 35967], [train loss 2.24616], [train acc 0.14896]\n",
      "[epoch 1], [iter 31800 / 35967], [train loss 2.24603], [train acc 0.14887]\n",
      "[epoch 1], [iter 31900 / 35967], [train loss 2.24582], [train acc 0.14884]\n",
      "[epoch 1], [iter 32000 / 35967], [train loss 2.24556], [train acc 0.14909]\n",
      "[epoch 1], [iter 32100 / 35967], [train loss 2.24553], [train acc 0.14910]\n",
      "[epoch 1], [iter 32200 / 35967], [train loss 2.24584], [train acc 0.14904]\n",
      "[epoch 1], [iter 32300 / 35967], [train loss 2.24575], [train acc 0.14916]\n",
      "[epoch 1], [iter 32400 / 35967], [train loss 2.24581], [train acc 0.14898]\n",
      "[epoch 1], [iter 32500 / 35967], [train loss 2.24550], [train acc 0.14898]\n",
      "[epoch 1], [iter 32600 / 35967], [train loss 2.24518], [train acc 0.14911]\n",
      "[epoch 1], [iter 32700 / 35967], [train loss 2.24547], [train acc 0.14902]\n",
      "[epoch 1], [iter 32800 / 35967], [train loss 2.24547], [train acc 0.14896]\n",
      "[epoch 1], [iter 32900 / 35967], [train loss 2.24532], [train acc 0.14897]\n",
      "[epoch 1], [iter 33000 / 35967], [train loss 2.24538], [train acc 0.14885]\n",
      "[epoch 1], [iter 33100 / 35967], [train loss 2.24520], [train acc 0.14882]\n",
      "[epoch 1], [iter 33200 / 35967], [train loss 2.24486], [train acc 0.14883]\n",
      "[epoch 1], [iter 33300 / 35967], [train loss 2.24499], [train acc 0.14874]\n",
      "[epoch 1], [iter 33400 / 35967], [train loss 2.24469], [train acc 0.14892]\n",
      "[epoch 1], [iter 33500 / 35967], [train loss 2.24471], [train acc 0.14890]\n",
      "[epoch 1], [iter 33600 / 35967], [train loss 2.24490], [train acc 0.14896]\n",
      "[epoch 1], [iter 33700 / 35967], [train loss 2.24522], [train acc 0.14890]\n",
      "[epoch 1], [iter 33800 / 35967], [train loss 2.24506], [train acc 0.14899]\n",
      "[epoch 1], [iter 33900 / 35967], [train loss 2.24517], [train acc 0.14897]\n",
      "[epoch 1], [iter 34000 / 35967], [train loss 2.24528], [train acc 0.14888]\n",
      "[epoch 1], [iter 34100 / 35967], [train loss 2.24535], [train acc 0.14894]\n",
      "[epoch 1], [iter 34200 / 35967], [train loss 2.24537], [train acc 0.14904]\n",
      "[epoch 1], [iter 34300 / 35967], [train loss 2.24551], [train acc 0.14910]\n",
      "[epoch 1], [iter 34400 / 35967], [train loss 2.24545], [train acc 0.14930]\n",
      "[epoch 1], [iter 34500 / 35967], [train loss 2.24575], [train acc 0.14933]\n",
      "[epoch 1], [iter 34600 / 35967], [train loss 2.24553], [train acc 0.14945]\n",
      "[epoch 1], [iter 34700 / 35967], [train loss 2.24561], [train acc 0.14945]\n",
      "[epoch 1], [iter 34800 / 35967], [train loss 2.24567], [train acc 0.14966]\n",
      "[epoch 1], [iter 34900 / 35967], [train loss 2.24584], [train acc 0.14954]\n",
      "[epoch 1], [iter 35000 / 35967], [train loss 2.24586], [train acc 0.14940]\n",
      "[epoch 1], [iter 35100 / 35967], [train loss 2.24607], [train acc 0.14943]\n",
      "[epoch 1], [iter 35200 / 35967], [train loss 2.24603], [train acc 0.14943]\n",
      "[epoch 1], [iter 35300 / 35967], [train loss 2.24589], [train acc 0.14952]\n",
      "[epoch 1], [iter 35400 / 35967], [train loss 2.24570], [train acc 0.14966]\n",
      "[epoch 1], [iter 35500 / 35967], [train loss 2.24545], [train acc 0.14983]\n",
      "[epoch 1], [iter 35600 / 35967], [train loss 2.24550], [train acc 0.14986]\n",
      "[epoch 1], [iter 35700 / 35967], [train loss 2.24548], [train acc 0.14978]\n",
      "[epoch 1], [iter 35800 / 35967], [train loss 2.24538], [train acc 0.15003]\n",
      "[epoch 1], [iter 35900 / 35967], [train loss 2.24545], [train acc 0.15003]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 3.08567], [val acc 0.01723]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 1], [val loss 3.08567], [val acc 0.01723]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 / 35967], [train loss 2.22649], [train acc 0.09000]\n",
      "[epoch 2], [iter 200 / 35967], [train loss 2.22968], [train acc 0.14000]\n",
      "[epoch 2], [iter 300 / 35967], [train loss 2.20801], [train acc 0.13667]\n",
      "[epoch 2], [iter 400 / 35967], [train loss 2.21695], [train acc 0.14000]\n",
      "[epoch 2], [iter 500 / 35967], [train loss 2.21825], [train acc 0.14800]\n",
      "[epoch 2], [iter 600 / 35967], [train loss 2.21485], [train acc 0.15167]\n",
      "[epoch 2], [iter 700 / 35967], [train loss 2.22291], [train acc 0.14714]\n",
      "[epoch 2], [iter 800 / 35967], [train loss 2.22438], [train acc 0.15125]\n",
      "[epoch 2], [iter 900 / 35967], [train loss 2.22953], [train acc 0.14556]\n",
      "[epoch 2], [iter 1000 / 35967], [train loss 2.23697], [train acc 0.14800]\n",
      "[epoch 2], [iter 1100 / 35967], [train loss 2.24262], [train acc 0.14636]\n",
      "[epoch 2], [iter 1200 / 35967], [train loss 2.23699], [train acc 0.14750]\n",
      "[epoch 2], [iter 1300 / 35967], [train loss 2.22992], [train acc 0.15308]\n",
      "[epoch 2], [iter 1400 / 35967], [train loss 2.22696], [train acc 0.15357]\n",
      "[epoch 2], [iter 1500 / 35967], [train loss 2.22214], [train acc 0.15200]\n",
      "[epoch 2], [iter 1600 / 35967], [train loss 2.22134], [train acc 0.15125]\n",
      "[epoch 2], [iter 1700 / 35967], [train loss 2.22098], [train acc 0.15059]\n",
      "[epoch 2], [iter 1800 / 35967], [train loss 2.22533], [train acc 0.14778]\n",
      "[epoch 2], [iter 1900 / 35967], [train loss 2.23034], [train acc 0.14789]\n",
      "[epoch 2], [iter 2000 / 35967], [train loss 2.23179], [train acc 0.14700]\n",
      "[epoch 2], [iter 2100 / 35967], [train loss 2.23984], [train acc 0.14571]\n",
      "[epoch 2], [iter 2200 / 35967], [train loss 2.24188], [train acc 0.14636]\n",
      "[epoch 2], [iter 2300 / 35967], [train loss 2.24026], [train acc 0.14739]\n",
      "[epoch 2], [iter 2400 / 35967], [train loss 2.23779], [train acc 0.14917]\n",
      "[epoch 2], [iter 2500 / 35967], [train loss 2.23659], [train acc 0.15040]\n",
      "[epoch 2], [iter 2600 / 35967], [train loss 2.23951], [train acc 0.14962]\n",
      "[epoch 2], [iter 2700 / 35967], [train loss 2.24298], [train acc 0.15000]\n",
      "[epoch 2], [iter 2800 / 35967], [train loss 2.24565], [train acc 0.15000]\n",
      "[epoch 2], [iter 2900 / 35967], [train loss 2.25132], [train acc 0.14862]\n",
      "[epoch 2], [iter 3000 / 35967], [train loss 2.25177], [train acc 0.14733]\n",
      "[epoch 2], [iter 3100 / 35967], [train loss 2.25217], [train acc 0.14581]\n",
      "[epoch 2], [iter 3200 / 35967], [train loss 2.25361], [train acc 0.14500]\n",
      "[epoch 2], [iter 3300 / 35967], [train loss 2.24828], [train acc 0.14697]\n",
      "[epoch 2], [iter 3400 / 35967], [train loss 2.24986], [train acc 0.14676]\n",
      "[epoch 2], [iter 3500 / 35967], [train loss 2.24484], [train acc 0.14686]\n",
      "[epoch 2], [iter 3600 / 35967], [train loss 2.24483], [train acc 0.14833]\n",
      "[epoch 2], [iter 3700 / 35967], [train loss 2.24078], [train acc 0.15027]\n",
      "[epoch 2], [iter 3800 / 35967], [train loss 2.24082], [train acc 0.15026]\n",
      "[epoch 2], [iter 3900 / 35967], [train loss 2.24165], [train acc 0.14897]\n",
      "[epoch 2], [iter 4000 / 35967], [train loss 2.24071], [train acc 0.14900]\n",
      "[epoch 2], [iter 4100 / 35967], [train loss 2.24052], [train acc 0.14829]\n",
      "[epoch 2], [iter 4200 / 35967], [train loss 2.24025], [train acc 0.14881]\n",
      "[epoch 2], [iter 4300 / 35967], [train loss 2.24113], [train acc 0.14744]\n",
      "[epoch 2], [iter 4400 / 35967], [train loss 2.24106], [train acc 0.14682]\n",
      "[epoch 2], [iter 4500 / 35967], [train loss 2.23913], [train acc 0.14578]\n",
      "[epoch 2], [iter 4600 / 35967], [train loss 2.23714], [train acc 0.14565]\n",
      "[epoch 2], [iter 4700 / 35967], [train loss 2.23888], [train acc 0.14447]\n",
      "[epoch 2], [iter 4800 / 35967], [train loss 2.23649], [train acc 0.14458]\n",
      "[epoch 2], [iter 4900 / 35967], [train loss 2.23619], [train acc 0.14612]\n",
      "[epoch 2], [iter 5000 / 35967], [train loss 2.23325], [train acc 0.14680]\n",
      "[epoch 2], [iter 5100 / 35967], [train loss 2.23293], [train acc 0.14627]\n",
      "[epoch 2], [iter 5200 / 35967], [train loss 2.23328], [train acc 0.14712]\n",
      "[epoch 2], [iter 5300 / 35967], [train loss 2.23079], [train acc 0.14717]\n",
      "[epoch 2], [iter 5400 / 35967], [train loss 2.23138], [train acc 0.14796]\n",
      "[epoch 2], [iter 5500 / 35967], [train loss 2.23162], [train acc 0.14800]\n",
      "[epoch 2], [iter 5600 / 35967], [train loss 2.23231], [train acc 0.14786]\n",
      "[epoch 2], [iter 5700 / 35967], [train loss 2.23086], [train acc 0.14947]\n",
      "[epoch 2], [iter 5800 / 35967], [train loss 2.22974], [train acc 0.14897]\n",
      "[epoch 2], [iter 5900 / 35967], [train loss 2.22977], [train acc 0.14949]\n",
      "[epoch 2], [iter 6000 / 35967], [train loss 2.22836], [train acc 0.15000]\n",
      "[epoch 2], [iter 6100 / 35967], [train loss 2.22752], [train acc 0.14984]\n",
      "[epoch 2], [iter 6200 / 35967], [train loss 2.22829], [train acc 0.14935]\n",
      "[epoch 2], [iter 6300 / 35967], [train loss 2.22669], [train acc 0.14952]\n",
      "[epoch 2], [iter 6400 / 35967], [train loss 2.22517], [train acc 0.14969]\n",
      "[epoch 2], [iter 6500 / 35967], [train loss 2.22484], [train acc 0.15031]\n",
      "[epoch 2], [iter 6600 / 35967], [train loss 2.22443], [train acc 0.15091]\n",
      "[epoch 2], [iter 6700 / 35967], [train loss 2.22453], [train acc 0.15075]\n",
      "[epoch 2], [iter 6800 / 35967], [train loss 2.22337], [train acc 0.15029]\n",
      "[epoch 2], [iter 6900 / 35967], [train loss 2.22248], [train acc 0.14986]\n",
      "[epoch 2], [iter 7000 / 35967], [train loss 2.22202], [train acc 0.15029]\n",
      "[epoch 2], [iter 7100 / 35967], [train loss 2.22293], [train acc 0.15070]\n",
      "[epoch 2], [iter 7200 / 35967], [train loss 2.22206], [train acc 0.15083]\n",
      "[epoch 2], [iter 7300 / 35967], [train loss 2.22412], [train acc 0.15014]\n",
      "[epoch 2], [iter 7400 / 35967], [train loss 2.22220], [train acc 0.15014]\n",
      "[epoch 2], [iter 7500 / 35967], [train loss 2.22306], [train acc 0.15000]\n",
      "[epoch 2], [iter 7600 / 35967], [train loss 2.22198], [train acc 0.15026]\n",
      "[epoch 2], [iter 7700 / 35967], [train loss 2.22153], [train acc 0.15078]\n",
      "[epoch 2], [iter 7800 / 35967], [train loss 2.22027], [train acc 0.15115]\n",
      "[epoch 2], [iter 7900 / 35967], [train loss 2.22087], [train acc 0.15063]\n",
      "[epoch 2], [iter 8000 / 35967], [train loss 2.21979], [train acc 0.15075]\n",
      "[epoch 2], [iter 8100 / 35967], [train loss 2.22014], [train acc 0.15086]\n",
      "[epoch 2], [iter 8200 / 35967], [train loss 2.21953], [train acc 0.15122]\n",
      "[epoch 2], [iter 8300 / 35967], [train loss 2.21979], [train acc 0.15060]\n",
      "[epoch 2], [iter 8400 / 35967], [train loss 2.21974], [train acc 0.15083]\n",
      "[epoch 2], [iter 8500 / 35967], [train loss 2.22069], [train acc 0.15118]\n",
      "[epoch 2], [iter 8600 / 35967], [train loss 2.22083], [train acc 0.15058]\n",
      "[epoch 2], [iter 8700 / 35967], [train loss 2.22162], [train acc 0.15080]\n",
      "[epoch 2], [iter 8800 / 35967], [train loss 2.22169], [train acc 0.15068]\n",
      "[epoch 2], [iter 8900 / 35967], [train loss 2.22137], [train acc 0.15067]\n",
      "[epoch 2], [iter 9000 / 35967], [train loss 2.22155], [train acc 0.15011]\n",
      "[epoch 2], [iter 9100 / 35967], [train loss 2.22055], [train acc 0.15033]\n",
      "[epoch 2], [iter 9200 / 35967], [train loss 2.22111], [train acc 0.15011]\n",
      "[epoch 2], [iter 9300 / 35967], [train loss 2.22149], [train acc 0.14978]\n",
      "[epoch 2], [iter 9400 / 35967], [train loss 2.22139], [train acc 0.14936]\n",
      "[epoch 2], [iter 9500 / 35967], [train loss 2.21964], [train acc 0.15000]\n",
      "[epoch 2], [iter 9600 / 35967], [train loss 2.22041], [train acc 0.15021]\n",
      "[epoch 2], [iter 9700 / 35967], [train loss 2.22001], [train acc 0.15031]\n",
      "[epoch 2], [iter 9800 / 35967], [train loss 2.22038], [train acc 0.15020]\n",
      "[epoch 2], [iter 9900 / 35967], [train loss 2.21972], [train acc 0.15040]\n",
      "[epoch 2], [iter 10000 / 35967], [train loss 2.21963], [train acc 0.15050]\n",
      "[epoch 2], [iter 10100 / 35967], [train loss 2.21935], [train acc 0.15069]\n",
      "[epoch 2], [iter 10200 / 35967], [train loss 2.21871], [train acc 0.15049]\n",
      "[epoch 2], [iter 10300 / 35967], [train loss 2.21898], [train acc 0.15058]\n",
      "[epoch 2], [iter 10400 / 35967], [train loss 2.21862], [train acc 0.15038]\n",
      "[epoch 2], [iter 10500 / 35967], [train loss 2.21881], [train acc 0.15105]\n",
      "[epoch 2], [iter 10600 / 35967], [train loss 2.21980], [train acc 0.15047]\n",
      "[epoch 2], [iter 10700 / 35967], [train loss 2.21962], [train acc 0.15075]\n",
      "[epoch 2], [iter 10800 / 35967], [train loss 2.21933], [train acc 0.15139]\n",
      "[epoch 2], [iter 10900 / 35967], [train loss 2.21879], [train acc 0.15110]\n",
      "[epoch 2], [iter 11000 / 35967], [train loss 2.21843], [train acc 0.15155]\n",
      "[epoch 2], [iter 11100 / 35967], [train loss 2.21855], [train acc 0.15171]\n",
      "[epoch 2], [iter 11200 / 35967], [train loss 2.21755], [train acc 0.15223]\n",
      "[epoch 2], [iter 11300 / 35967], [train loss 2.21821], [train acc 0.15248]\n",
      "[epoch 2], [iter 11400 / 35967], [train loss 2.21842], [train acc 0.15254]\n",
      "[epoch 2], [iter 11500 / 35967], [train loss 2.21823], [train acc 0.15278]\n",
      "[epoch 2], [iter 11600 / 35967], [train loss 2.21842], [train acc 0.15267]\n",
      "[epoch 2], [iter 11700 / 35967], [train loss 2.21832], [train acc 0.15256]\n",
      "[epoch 2], [iter 11800 / 35967], [train loss 2.21877], [train acc 0.15254]\n",
      "[epoch 2], [iter 11900 / 35967], [train loss 2.21939], [train acc 0.15227]\n",
      "[epoch 2], [iter 12000 / 35967], [train loss 2.22029], [train acc 0.15192]\n",
      "[epoch 2], [iter 12100 / 35967], [train loss 2.22057], [train acc 0.15182]\n",
      "[epoch 2], [iter 12200 / 35967], [train loss 2.22011], [train acc 0.15164]\n",
      "[epoch 2], [iter 12300 / 35967], [train loss 2.22024], [train acc 0.15228]\n",
      "[epoch 2], [iter 12400 / 35967], [train loss 2.22087], [train acc 0.15218]\n",
      "[epoch 2], [iter 12500 / 35967], [train loss 2.22016], [train acc 0.15232]\n",
      "[epoch 2], [iter 12600 / 35967], [train loss 2.22036], [train acc 0.15230]\n",
      "[epoch 2], [iter 12700 / 35967], [train loss 2.22011], [train acc 0.15236]\n",
      "[epoch 2], [iter 12800 / 35967], [train loss 2.22070], [train acc 0.15234]\n",
      "[epoch 2], [iter 12900 / 35967], [train loss 2.22098], [train acc 0.15217]\n",
      "[epoch 2], [iter 13000 / 35967], [train loss 2.22151], [train acc 0.15238]\n",
      "[epoch 2], [iter 13100 / 35967], [train loss 2.22260], [train acc 0.15206]\n",
      "[epoch 2], [iter 13200 / 35967], [train loss 2.22171], [train acc 0.15227]\n",
      "[epoch 2], [iter 13300 / 35967], [train loss 2.22097], [train acc 0.15233]\n",
      "[epoch 2], [iter 13400 / 35967], [train loss 2.22075], [train acc 0.15254]\n",
      "[epoch 2], [iter 13500 / 35967], [train loss 2.22046], [train acc 0.15267]\n",
      "[epoch 2], [iter 13600 / 35967], [train loss 2.22016], [train acc 0.15272]\n",
      "[epoch 2], [iter 13700 / 35967], [train loss 2.22006], [train acc 0.15248]\n",
      "[epoch 2], [iter 13800 / 35967], [train loss 2.21990], [train acc 0.15261]\n",
      "[epoch 2], [iter 13900 / 35967], [train loss 2.22007], [train acc 0.15281]\n",
      "[epoch 2], [iter 14000 / 35967], [train loss 2.21978], [train acc 0.15279]\n",
      "[epoch 2], [iter 14100 / 35967], [train loss 2.21986], [train acc 0.15270]\n",
      "[epoch 2], [iter 14200 / 35967], [train loss 2.21914], [train acc 0.15303]\n",
      "[epoch 2], [iter 14300 / 35967], [train loss 2.21909], [train acc 0.15280]\n",
      "[epoch 2], [iter 14400 / 35967], [train loss 2.21870], [train acc 0.15271]\n",
      "[epoch 2], [iter 14500 / 35967], [train loss 2.21880], [train acc 0.15290]\n",
      "[epoch 2], [iter 14600 / 35967], [train loss 2.21878], [train acc 0.15322]\n",
      "[epoch 2], [iter 14700 / 35967], [train loss 2.21886], [train acc 0.15340]\n",
      "[epoch 2], [iter 14800 / 35967], [train loss 2.21861], [train acc 0.15345]\n",
      "[epoch 2], [iter 14900 / 35967], [train loss 2.21871], [train acc 0.15356]\n",
      "[epoch 2], [iter 15000 / 35967], [train loss 2.21917], [train acc 0.15320]\n",
      "[epoch 2], [iter 15100 / 35967], [train loss 2.21984], [train acc 0.15311]\n",
      "[epoch 2], [iter 15200 / 35967], [train loss 2.21971], [train acc 0.15309]\n",
      "[epoch 2], [iter 15300 / 35967], [train loss 2.22100], [train acc 0.15301]\n",
      "[epoch 2], [iter 15400 / 35967], [train loss 2.22055], [train acc 0.15364]\n",
      "[epoch 2], [iter 15500 / 35967], [train loss 2.21967], [train acc 0.15374]\n",
      "[epoch 2], [iter 15600 / 35967], [train loss 2.21937], [train acc 0.15372]\n",
      "[epoch 2], [iter 15700 / 35967], [train loss 2.21955], [train acc 0.15389]\n",
      "[epoch 2], [iter 15800 / 35967], [train loss 2.21985], [train acc 0.15335]\n",
      "[epoch 2], [iter 15900 / 35967], [train loss 2.21935], [train acc 0.15346]\n",
      "[epoch 2], [iter 16000 / 35967], [train loss 2.21984], [train acc 0.15344]\n",
      "[epoch 2], [iter 16100 / 35967], [train loss 2.22003], [train acc 0.15354]\n",
      "[epoch 2], [iter 16200 / 35967], [train loss 2.21979], [train acc 0.15321]\n",
      "[epoch 2], [iter 16300 / 35967], [train loss 2.21968], [train acc 0.15337]\n",
      "[epoch 2], [iter 16400 / 35967], [train loss 2.21955], [train acc 0.15360]\n",
      "[epoch 2], [iter 16500 / 35967], [train loss 2.22010], [train acc 0.15364]\n",
      "[epoch 2], [iter 16600 / 35967], [train loss 2.21948], [train acc 0.15386]\n",
      "[epoch 2], [iter 16700 / 35967], [train loss 2.21945], [train acc 0.15371]\n",
      "[epoch 2], [iter 16800 / 35967], [train loss 2.21860], [train acc 0.15375]\n",
      "[epoch 2], [iter 16900 / 35967], [train loss 2.21833], [train acc 0.15402]\n",
      "[epoch 2], [iter 17000 / 35967], [train loss 2.21814], [train acc 0.15424]\n",
      "[epoch 2], [iter 17100 / 35967], [train loss 2.21838], [train acc 0.15386]\n",
      "[epoch 2], [iter 17200 / 35967], [train loss 2.21842], [train acc 0.15366]\n",
      "[epoch 2], [iter 17300 / 35967], [train loss 2.21873], [train acc 0.15341]\n",
      "[epoch 2], [iter 17400 / 35967], [train loss 2.21842], [train acc 0.15351]\n",
      "[epoch 2], [iter 17500 / 35967], [train loss 2.21867], [train acc 0.15354]\n",
      "[epoch 2], [iter 17600 / 35967], [train loss 2.21850], [train acc 0.15375]\n",
      "[epoch 2], [iter 17700 / 35967], [train loss 2.21843], [train acc 0.15395]\n",
      "[epoch 2], [iter 17800 / 35967], [train loss 2.21847], [train acc 0.15382]\n",
      "[epoch 2], [iter 17900 / 35967], [train loss 2.21890], [train acc 0.15369]\n",
      "[epoch 2], [iter 18000 / 35967], [train loss 2.21810], [train acc 0.15361]\n",
      "[epoch 2], [iter 18100 / 35967], [train loss 2.21769], [train acc 0.15376]\n",
      "[epoch 2], [iter 18200 / 35967], [train loss 2.21878], [train acc 0.15363]\n",
      "[epoch 2], [iter 18300 / 35967], [train loss 2.21842], [train acc 0.15361]\n",
      "[epoch 2], [iter 18400 / 35967], [train loss 2.21864], [train acc 0.15326]\n",
      "[epoch 2], [iter 18500 / 35967], [train loss 2.21876], [train acc 0.15292]\n",
      "[epoch 2], [iter 18600 / 35967], [train loss 2.21870], [train acc 0.15290]\n",
      "[epoch 2], [iter 18700 / 35967], [train loss 2.21880], [train acc 0.15294]\n",
      "[epoch 2], [iter 18800 / 35967], [train loss 2.21879], [train acc 0.15309]\n",
      "[epoch 2], [iter 18900 / 35967], [train loss 2.21856], [train acc 0.15339]\n",
      "[epoch 2], [iter 19000 / 35967], [train loss 2.21860], [train acc 0.15337]\n",
      "[epoch 2], [iter 19100 / 35967], [train loss 2.21867], [train acc 0.15351]\n",
      "[epoch 2], [iter 19200 / 35967], [train loss 2.21920], [train acc 0.15323]\n",
      "[epoch 2], [iter 19300 / 35967], [train loss 2.21887], [train acc 0.15347]\n",
      "[epoch 2], [iter 19400 / 35967], [train loss 2.21818], [train acc 0.15392]\n",
      "[epoch 2], [iter 19500 / 35967], [train loss 2.21734], [train acc 0.15410]\n",
      "[epoch 2], [iter 19600 / 35967], [train loss 2.21701], [train acc 0.15408]\n",
      "[epoch 2], [iter 19700 / 35967], [train loss 2.21715], [train acc 0.15421]\n",
      "[epoch 2], [iter 19800 / 35967], [train loss 2.21715], [train acc 0.15424]\n",
      "[epoch 2], [iter 19900 / 35967], [train loss 2.21712], [train acc 0.15402]\n",
      "[epoch 2], [iter 20000 / 35967], [train loss 2.21685], [train acc 0.15420]\n",
      "[epoch 2], [iter 20100 / 35967], [train loss 2.21667], [train acc 0.15433]\n",
      "[epoch 2], [iter 20200 / 35967], [train loss 2.21639], [train acc 0.15436]\n",
      "[epoch 2], [iter 20300 / 35967], [train loss 2.21608], [train acc 0.15453]\n",
      "[epoch 2], [iter 20400 / 35967], [train loss 2.21610], [train acc 0.15461]\n",
      "[epoch 2], [iter 20500 / 35967], [train loss 2.21565], [train acc 0.15502]\n",
      "[epoch 2], [iter 20600 / 35967], [train loss 2.21609], [train acc 0.15485]\n",
      "[epoch 2], [iter 20700 / 35967], [train loss 2.21616], [train acc 0.15478]\n",
      "[epoch 2], [iter 20800 / 35967], [train loss 2.21607], [train acc 0.15490]\n",
      "[epoch 2], [iter 20900 / 35967], [train loss 2.21612], [train acc 0.15488]\n",
      "[epoch 2], [iter 21000 / 35967], [train loss 2.21701], [train acc 0.15467]\n",
      "[epoch 2], [iter 21100 / 35967], [train loss 2.21694], [train acc 0.15493]\n",
      "[epoch 2], [iter 21200 / 35967], [train loss 2.21683], [train acc 0.15500]\n",
      "[epoch 2], [iter 21300 / 35967], [train loss 2.21648], [train acc 0.15507]\n",
      "[epoch 2], [iter 21400 / 35967], [train loss 2.21676], [train acc 0.15500]\n",
      "[epoch 2], [iter 21500 / 35967], [train loss 2.21678], [train acc 0.15484]\n",
      "[epoch 2], [iter 21600 / 35967], [train loss 2.21670], [train acc 0.15486]\n",
      "[epoch 2], [iter 21700 / 35967], [train loss 2.21708], [train acc 0.15475]\n",
      "[epoch 2], [iter 21800 / 35967], [train loss 2.21689], [train acc 0.15450]\n",
      "[epoch 2], [iter 21900 / 35967], [train loss 2.21681], [train acc 0.15466]\n",
      "[epoch 2], [iter 22000 / 35967], [train loss 2.21641], [train acc 0.15482]\n",
      "[epoch 2], [iter 22100 / 35967], [train loss 2.21615], [train acc 0.15493]\n",
      "[epoch 2], [iter 22200 / 35967], [train loss 2.21604], [train acc 0.15518]\n",
      "[epoch 2], [iter 22300 / 35967], [train loss 2.21612], [train acc 0.15489]\n",
      "[epoch 2], [iter 22400 / 35967], [train loss 2.21594], [train acc 0.15487]\n",
      "[epoch 2], [iter 22500 / 35967], [train loss 2.21623], [train acc 0.15462]\n",
      "[epoch 2], [iter 22600 / 35967], [train loss 2.21657], [train acc 0.15438]\n",
      "[epoch 2], [iter 22700 / 35967], [train loss 2.21645], [train acc 0.15432]\n",
      "[epoch 2], [iter 22800 / 35967], [train loss 2.21647], [train acc 0.15447]\n",
      "[epoch 2], [iter 22900 / 35967], [train loss 2.21623], [train acc 0.15467]\n",
      "[epoch 2], [iter 23000 / 35967], [train loss 2.21659], [train acc 0.15478]\n",
      "[epoch 2], [iter 23100 / 35967], [train loss 2.21654], [train acc 0.15476]\n",
      "[epoch 2], [iter 23200 / 35967], [train loss 2.21693], [train acc 0.15457]\n",
      "[epoch 2], [iter 23300 / 35967], [train loss 2.21643], [train acc 0.15459]\n",
      "[epoch 2], [iter 23400 / 35967], [train loss 2.21657], [train acc 0.15483]\n",
      "[epoch 2], [iter 23500 / 35967], [train loss 2.21633], [train acc 0.15472]\n",
      "[epoch 2], [iter 23600 / 35967], [train loss 2.21602], [train acc 0.15466]\n",
      "[epoch 2], [iter 23700 / 35967], [train loss 2.21560], [train acc 0.15494]\n",
      "[epoch 2], [iter 23800 / 35967], [train loss 2.21568], [train acc 0.15496]\n",
      "[epoch 2], [iter 23900 / 35967], [train loss 2.21597], [train acc 0.15506]\n",
      "[epoch 2], [iter 24000 / 35967], [train loss 2.21607], [train acc 0.15513]\n",
      "[epoch 2], [iter 24100 / 35967], [train loss 2.21615], [train acc 0.15531]\n",
      "[epoch 2], [iter 24200 / 35967], [train loss 2.21610], [train acc 0.15529]\n",
      "[epoch 2], [iter 24300 / 35967], [train loss 2.21646], [train acc 0.15527]\n",
      "[epoch 2], [iter 24400 / 35967], [train loss 2.21643], [train acc 0.15529]\n",
      "[epoch 2], [iter 24500 / 35967], [train loss 2.21651], [train acc 0.15514]\n",
      "[epoch 2], [iter 24600 / 35967], [train loss 2.21632], [train acc 0.15545]\n",
      "[epoch 2], [iter 24700 / 35967], [train loss 2.21614], [train acc 0.15551]\n",
      "[epoch 2], [iter 24800 / 35967], [train loss 2.21592], [train acc 0.15548]\n",
      "[epoch 2], [iter 24900 / 35967], [train loss 2.21615], [train acc 0.15550]\n",
      "[epoch 2], [iter 25000 / 35967], [train loss 2.21638], [train acc 0.15536]\n",
      "[epoch 2], [iter 25100 / 35967], [train loss 2.21657], [train acc 0.15538]\n",
      "[epoch 2], [iter 25200 / 35967], [train loss 2.21662], [train acc 0.15552]\n",
      "[epoch 2], [iter 25300 / 35967], [train loss 2.21647], [train acc 0.15545]\n",
      "[epoch 2], [iter 25400 / 35967], [train loss 2.21640], [train acc 0.15535]\n",
      "[epoch 2], [iter 25500 / 35967], [train loss 2.21600], [train acc 0.15549]\n",
      "[epoch 2], [iter 25600 / 35967], [train loss 2.21610], [train acc 0.15543]\n",
      "[epoch 2], [iter 25700 / 35967], [train loss 2.21604], [train acc 0.15533]\n",
      "[epoch 2], [iter 25800 / 35967], [train loss 2.21616], [train acc 0.15539]\n",
      "[epoch 2], [iter 25900 / 35967], [train loss 2.21619], [train acc 0.15537]\n",
      "[epoch 2], [iter 26000 / 35967], [train loss 2.21586], [train acc 0.15535]\n",
      "[epoch 2], [iter 26100 / 35967], [train loss 2.21553], [train acc 0.15567]\n",
      "[epoch 2], [iter 26200 / 35967], [train loss 2.21540], [train acc 0.15576]\n",
      "[epoch 2], [iter 26300 / 35967], [train loss 2.21541], [train acc 0.15574]\n",
      "[epoch 2], [iter 26400 / 35967], [train loss 2.21532], [train acc 0.15572]\n",
      "[epoch 2], [iter 26500 / 35967], [train loss 2.21454], [train acc 0.15604]\n",
      "[epoch 2], [iter 26600 / 35967], [train loss 2.21461], [train acc 0.15594]\n",
      "[epoch 2], [iter 26700 / 35967], [train loss 2.21496], [train acc 0.15584]\n",
      "[epoch 2], [iter 26800 / 35967], [train loss 2.21525], [train acc 0.15582]\n",
      "[epoch 2], [iter 26900 / 35967], [train loss 2.21552], [train acc 0.15587]\n",
      "[epoch 2], [iter 27000 / 35967], [train loss 2.21527], [train acc 0.15563]\n",
      "[epoch 2], [iter 27100 / 35967], [train loss 2.21499], [train acc 0.15539]\n",
      "[epoch 2], [iter 27200 / 35967], [train loss 2.21485], [train acc 0.15537]\n",
      "[epoch 2], [iter 27300 / 35967], [train loss 2.21472], [train acc 0.15553]\n",
      "[epoch 2], [iter 27400 / 35967], [train loss 2.21459], [train acc 0.15558]\n",
      "[epoch 2], [iter 27500 / 35967], [train loss 2.21449], [train acc 0.15545]\n",
      "[epoch 2], [iter 27600 / 35967], [train loss 2.21464], [train acc 0.15551]\n",
      "[epoch 2], [iter 27700 / 35967], [train loss 2.21454], [train acc 0.15534]\n",
      "[epoch 2], [iter 27800 / 35967], [train loss 2.21419], [train acc 0.15540]\n",
      "[epoch 2], [iter 27900 / 35967], [train loss 2.21387], [train acc 0.15534]\n",
      "[epoch 2], [iter 28000 / 35967], [train loss 2.21375], [train acc 0.15539]\n",
      "[epoch 2], [iter 28100 / 35967], [train loss 2.21341], [train acc 0.15541]\n",
      "[epoch 2], [iter 28200 / 35967], [train loss 2.21338], [train acc 0.15539]\n",
      "[epoch 2], [iter 28300 / 35967], [train loss 2.21313], [train acc 0.15551]\n",
      "[epoch 2], [iter 28400 / 35967], [train loss 2.21329], [train acc 0.15553]\n",
      "[epoch 2], [iter 28500 / 35967], [train loss 2.21316], [train acc 0.15572]\n",
      "[epoch 2], [iter 28600 / 35967], [train loss 2.21327], [train acc 0.15570]\n",
      "[epoch 2], [iter 28700 / 35967], [train loss 2.21330], [train acc 0.15557]\n",
      "[epoch 2], [iter 28800 / 35967], [train loss 2.21317], [train acc 0.15563]\n",
      "[epoch 2], [iter 28900 / 35967], [train loss 2.21304], [train acc 0.15567]\n",
      "[epoch 2], [iter 29000 / 35967], [train loss 2.21370], [train acc 0.15576]\n",
      "[epoch 2], [iter 29100 / 35967], [train loss 2.21343], [train acc 0.15574]\n",
      "[epoch 2], [iter 29200 / 35967], [train loss 2.21344], [train acc 0.15568]\n",
      "[epoch 2], [iter 29300 / 35967], [train loss 2.21359], [train acc 0.15553]\n",
      "[epoch 2], [iter 29400 / 35967], [train loss 2.21382], [train acc 0.15558]\n",
      "[epoch 2], [iter 29500 / 35967], [train loss 2.21432], [train acc 0.15536]\n",
      "[epoch 2], [iter 29600 / 35967], [train loss 2.21398], [train acc 0.15544]\n",
      "[epoch 2], [iter 29700 / 35967], [train loss 2.21415], [train acc 0.15545]\n",
      "[epoch 2], [iter 29800 / 35967], [train loss 2.21422], [train acc 0.15550]\n",
      "[epoch 2], [iter 29900 / 35967], [train loss 2.21383], [train acc 0.15562]\n",
      "[epoch 2], [iter 30000 / 35967], [train loss 2.21344], [train acc 0.15560]\n",
      "[epoch 2], [iter 30100 / 35967], [train loss 2.21316], [train acc 0.15568]\n",
      "[epoch 2], [iter 30200 / 35967], [train loss 2.21315], [train acc 0.15589]\n",
      "[epoch 2], [iter 30300 / 35967], [train loss 2.21324], [train acc 0.15594]\n",
      "[epoch 2], [iter 30400 / 35967], [train loss 2.21330], [train acc 0.15609]\n",
      "[epoch 2], [iter 30500 / 35967], [train loss 2.21346], [train acc 0.15607]\n",
      "[epoch 2], [iter 30600 / 35967], [train loss 2.21336], [train acc 0.15605]\n",
      "[epoch 2], [iter 30700 / 35967], [train loss 2.21311], [train acc 0.15612]\n",
      "[epoch 2], [iter 30800 / 35967], [train loss 2.21282], [train acc 0.15617]\n",
      "[epoch 2], [iter 30900 / 35967], [train loss 2.21303], [train acc 0.15605]\n",
      "[epoch 2], [iter 31000 / 35967], [train loss 2.21286], [train acc 0.15623]\n",
      "[epoch 2], [iter 31100 / 35967], [train loss 2.21277], [train acc 0.15624]\n",
      "[epoch 2], [iter 31200 / 35967], [train loss 2.21262], [train acc 0.15625]\n",
      "[epoch 2], [iter 31300 / 35967], [train loss 2.21262], [train acc 0.15649]\n",
      "[epoch 2], [iter 31400 / 35967], [train loss 2.21258], [train acc 0.15656]\n",
      "[epoch 2], [iter 31500 / 35967], [train loss 2.21272], [train acc 0.15644]\n",
      "[epoch 2], [iter 31600 / 35967], [train loss 2.21308], [train acc 0.15649]\n",
      "[epoch 2], [iter 31700 / 35967], [train loss 2.21332], [train acc 0.15662]\n",
      "[epoch 2], [iter 31800 / 35967], [train loss 2.21339], [train acc 0.15673]\n",
      "[epoch 2], [iter 31900 / 35967], [train loss 2.21347], [train acc 0.15658]\n",
      "[epoch 2], [iter 32000 / 35967], [train loss 2.21306], [train acc 0.15662]\n",
      "[epoch 2], [iter 32100 / 35967], [train loss 2.21288], [train acc 0.15664]\n",
      "[epoch 2], [iter 32200 / 35967], [train loss 2.21256], [train acc 0.15677]\n",
      "[epoch 2], [iter 32300 / 35967], [train loss 2.21224], [train acc 0.15697]\n",
      "[epoch 2], [iter 32400 / 35967], [train loss 2.21242], [train acc 0.15694]\n",
      "[epoch 2], [iter 32500 / 35967], [train loss 2.21244], [train acc 0.15680]\n",
      "[epoch 2], [iter 32600 / 35967], [train loss 2.21247], [train acc 0.15672]\n",
      "[epoch 2], [iter 32700 / 35967], [train loss 2.21267], [train acc 0.15657]\n",
      "[epoch 2], [iter 32800 / 35967], [train loss 2.21249], [train acc 0.15652]\n",
      "[epoch 2], [iter 32900 / 35967], [train loss 2.21254], [train acc 0.15644]\n",
      "[epoch 2], [iter 33000 / 35967], [train loss 2.21259], [train acc 0.15633]\n",
      "[epoch 2], [iter 33100 / 35967], [train loss 2.21251], [train acc 0.15644]\n",
      "[epoch 2], [iter 33200 / 35967], [train loss 2.21246], [train acc 0.15636]\n",
      "[epoch 2], [iter 33300 / 35967], [train loss 2.21220], [train acc 0.15637]\n",
      "[epoch 2], [iter 33400 / 35967], [train loss 2.21230], [train acc 0.15650]\n",
      "[epoch 2], [iter 33500 / 35967], [train loss 2.21205], [train acc 0.15645]\n",
      "[epoch 2], [iter 33600 / 35967], [train loss 2.21195], [train acc 0.15649]\n",
      "[epoch 2], [iter 33700 / 35967], [train loss 2.21185], [train acc 0.15650]\n",
      "[epoch 2], [iter 33800 / 35967], [train loss 2.21191], [train acc 0.15636]\n",
      "[epoch 2], [iter 33900 / 35967], [train loss 2.21156], [train acc 0.15655]\n",
      "[epoch 2], [iter 34000 / 35967], [train loss 2.21162], [train acc 0.15659]\n",
      "[epoch 2], [iter 34100 / 35967], [train loss 2.21136], [train acc 0.15674]\n",
      "[epoch 2], [iter 34200 / 35967], [train loss 2.21130], [train acc 0.15690]\n",
      "[epoch 2], [iter 34300 / 35967], [train loss 2.21150], [train acc 0.15685]\n",
      "[epoch 2], [iter 34400 / 35967], [train loss 2.21160], [train acc 0.15686]\n",
      "[epoch 2], [iter 34500 / 35967], [train loss 2.21161], [train acc 0.15704]\n",
      "[epoch 2], [iter 34600 / 35967], [train loss 2.21144], [train acc 0.15714]\n",
      "[epoch 2], [iter 34700 / 35967], [train loss 2.21129], [train acc 0.15735]\n",
      "[epoch 2], [iter 34800 / 35967], [train loss 2.21116], [train acc 0.15730]\n",
      "[epoch 2], [iter 34900 / 35967], [train loss 2.21111], [train acc 0.15742]\n",
      "[epoch 2], [iter 35000 / 35967], [train loss 2.21111], [train acc 0.15749]\n",
      "[epoch 2], [iter 35100 / 35967], [train loss 2.21091], [train acc 0.15758]\n",
      "[epoch 2], [iter 35200 / 35967], [train loss 2.21084], [train acc 0.15756]\n",
      "[epoch 2], [iter 35300 / 35967], [train loss 2.21051], [train acc 0.15768]\n",
      "[epoch 2], [iter 35400 / 35967], [train loss 2.21047], [train acc 0.15774]\n",
      "[epoch 2], [iter 35500 / 35967], [train loss 2.21032], [train acc 0.15772]\n",
      "[epoch 2], [iter 35600 / 35967], [train loss 2.21058], [train acc 0.15758]\n",
      "[epoch 2], [iter 35700 / 35967], [train loss 2.21082], [train acc 0.15762]\n",
      "[epoch 2], [iter 35800 / 35967], [train loss 2.21100], [train acc 0.15751]\n",
      "[epoch 2], [iter 35900 / 35967], [train loss 2.21109], [train acc 0.15744]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 3.35429], [val acc 0.10335]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 2], [val loss 3.35429], [val acc 0.10335]\n",
      "*****************************************************\n",
      "[epoch 3], [iter 100 / 35967], [train loss 2.14412], [train acc 0.16000]\n",
      "[epoch 3], [iter 200 / 35967], [train loss 2.21811], [train acc 0.14500]\n",
      "[epoch 3], [iter 300 / 35967], [train loss 2.18692], [train acc 0.14667]\n",
      "[epoch 3], [iter 400 / 35967], [train loss 2.17239], [train acc 0.14750]\n",
      "[epoch 3], [iter 500 / 35967], [train loss 2.18635], [train acc 0.15800]\n",
      "[epoch 3], [iter 600 / 35967], [train loss 2.18701], [train acc 0.15333]\n",
      "[epoch 3], [iter 700 / 35967], [train loss 2.18451], [train acc 0.15571]\n",
      "[epoch 3], [iter 800 / 35967], [train loss 2.18389], [train acc 0.15750]\n",
      "[epoch 3], [iter 900 / 35967], [train loss 2.17365], [train acc 0.16333]\n",
      "[epoch 3], [iter 1000 / 35967], [train loss 2.18240], [train acc 0.16100]\n",
      "[epoch 3], [iter 1100 / 35967], [train loss 2.17505], [train acc 0.16273]\n",
      "[epoch 3], [iter 1200 / 35967], [train loss 2.17928], [train acc 0.16750]\n",
      "[epoch 3], [iter 1300 / 35967], [train loss 2.18326], [train acc 0.17154]\n",
      "[epoch 3], [iter 1400 / 35967], [train loss 2.18013], [train acc 0.17286]\n",
      "[epoch 3], [iter 1500 / 35967], [train loss 2.17960], [train acc 0.17400]\n",
      "[epoch 3], [iter 1600 / 35967], [train loss 2.17517], [train acc 0.17500]\n",
      "[epoch 3], [iter 1700 / 35967], [train loss 2.18272], [train acc 0.17176]\n",
      "[epoch 3], [iter 1800 / 35967], [train loss 2.18399], [train acc 0.17389]\n",
      "[epoch 3], [iter 1900 / 35967], [train loss 2.18885], [train acc 0.16947]\n",
      "[epoch 3], [iter 2000 / 35967], [train loss 2.18901], [train acc 0.16900]\n",
      "[epoch 3], [iter 2100 / 35967], [train loss 2.18750], [train acc 0.16905]\n",
      "[epoch 3], [iter 2200 / 35967], [train loss 2.18857], [train acc 0.16955]\n",
      "[epoch 3], [iter 2300 / 35967], [train loss 2.18973], [train acc 0.17043]\n",
      "[epoch 3], [iter 2400 / 35967], [train loss 2.19175], [train acc 0.16917]\n",
      "[epoch 3], [iter 2500 / 35967], [train loss 2.19201], [train acc 0.16880]\n",
      "[epoch 3], [iter 2600 / 35967], [train loss 2.18771], [train acc 0.17077]\n",
      "[epoch 3], [iter 2700 / 35967], [train loss 2.19148], [train acc 0.16963]\n",
      "[epoch 3], [iter 2800 / 35967], [train loss 2.19279], [train acc 0.16857]\n",
      "[epoch 3], [iter 2900 / 35967], [train loss 2.19149], [train acc 0.17034]\n",
      "[epoch 3], [iter 3000 / 35967], [train loss 2.19007], [train acc 0.17033]\n",
      "[epoch 3], [iter 3100 / 35967], [train loss 2.18703], [train acc 0.17194]\n",
      "[epoch 3], [iter 3200 / 35967], [train loss 2.18940], [train acc 0.17125]\n",
      "[epoch 3], [iter 3300 / 35967], [train loss 2.18803], [train acc 0.17091]\n",
      "[epoch 3], [iter 3400 / 35967], [train loss 2.19059], [train acc 0.17118]\n",
      "[epoch 3], [iter 3500 / 35967], [train loss 2.19289], [train acc 0.17029]\n",
      "[epoch 3], [iter 3600 / 35967], [train loss 2.19469], [train acc 0.16972]\n",
      "[epoch 3], [iter 3700 / 35967], [train loss 2.19868], [train acc 0.16838]\n",
      "[epoch 3], [iter 3800 / 35967], [train loss 2.19423], [train acc 0.16947]\n",
      "[epoch 3], [iter 3900 / 35967], [train loss 2.19589], [train acc 0.16923]\n",
      "[epoch 3], [iter 4000 / 35967], [train loss 2.19381], [train acc 0.16975]\n",
      "[epoch 3], [iter 4100 / 35967], [train loss 2.19540], [train acc 0.16927]\n",
      "[epoch 3], [iter 4200 / 35967], [train loss 2.19845], [train acc 0.16810]\n",
      "[epoch 3], [iter 4300 / 35967], [train loss 2.19968], [train acc 0.16721]\n",
      "[epoch 3], [iter 4400 / 35967], [train loss 2.20013], [train acc 0.16682]\n",
      "[epoch 3], [iter 4500 / 35967], [train loss 2.19847], [train acc 0.16800]\n",
      "[epoch 3], [iter 4600 / 35967], [train loss 2.19649], [train acc 0.16761]\n",
      "[epoch 3], [iter 4700 / 35967], [train loss 2.19730], [train acc 0.16681]\n",
      "[epoch 3], [iter 4800 / 35967], [train loss 2.19549], [train acc 0.16750]\n",
      "[epoch 3], [iter 4900 / 35967], [train loss 2.19392], [train acc 0.16694]\n",
      "[epoch 3], [iter 5000 / 35967], [train loss 2.19249], [train acc 0.16740]\n",
      "[epoch 3], [iter 5100 / 35967], [train loss 2.19282], [train acc 0.16706]\n",
      "[epoch 3], [iter 5200 / 35967], [train loss 2.19181], [train acc 0.16673]\n",
      "[epoch 3], [iter 5300 / 35967], [train loss 2.19070], [train acc 0.16736]\n",
      "[epoch 3], [iter 5400 / 35967], [train loss 2.19147], [train acc 0.16685]\n",
      "[epoch 3], [iter 5500 / 35967], [train loss 2.19330], [train acc 0.16709]\n",
      "[epoch 3], [iter 5600 / 35967], [train loss 2.19180], [train acc 0.16661]\n",
      "[epoch 3], [iter 5700 / 35967], [train loss 2.19119], [train acc 0.16649]\n",
      "[epoch 3], [iter 5800 / 35967], [train loss 2.19167], [train acc 0.16672]\n",
      "[epoch 3], [iter 5900 / 35967], [train loss 2.18976], [train acc 0.16576]\n",
      "[epoch 3], [iter 6000 / 35967], [train loss 2.18812], [train acc 0.16567]\n",
      "[epoch 3], [iter 6100 / 35967], [train loss 2.18679], [train acc 0.16590]\n",
      "[epoch 3], [iter 6200 / 35967], [train loss 2.18754], [train acc 0.16581]\n",
      "[epoch 3], [iter 6300 / 35967], [train loss 2.18818], [train acc 0.16508]\n",
      "[epoch 3], [iter 6400 / 35967], [train loss 2.18857], [train acc 0.16437]\n",
      "[epoch 3], [iter 6500 / 35967], [train loss 2.18691], [train acc 0.16492]\n",
      "[epoch 3], [iter 6600 / 35967], [train loss 2.18487], [train acc 0.16591]\n",
      "[epoch 3], [iter 6700 / 35967], [train loss 2.18608], [train acc 0.16627]\n",
      "[epoch 3], [iter 6800 / 35967], [train loss 2.18557], [train acc 0.16618]\n",
      "[epoch 3], [iter 6900 / 35967], [train loss 2.18537], [train acc 0.16652]\n",
      "[epoch 3], [iter 7000 / 35967], [train loss 2.18533], [train acc 0.16700]\n",
      "[epoch 3], [iter 7100 / 35967], [train loss 2.18586], [train acc 0.16676]\n",
      "[epoch 3], [iter 7200 / 35967], [train loss 2.18635], [train acc 0.16542]\n",
      "[epoch 3], [iter 7300 / 35967], [train loss 2.18732], [train acc 0.16521]\n",
      "[epoch 3], [iter 7400 / 35967], [train loss 2.18600], [train acc 0.16568]\n",
      "[epoch 3], [iter 7500 / 35967], [train loss 2.18680], [train acc 0.16613]\n",
      "[epoch 3], [iter 7600 / 35967], [train loss 2.18774], [train acc 0.16592]\n",
      "[epoch 3], [iter 7700 / 35967], [train loss 2.18682], [train acc 0.16558]\n",
      "[epoch 3], [iter 7800 / 35967], [train loss 2.18812], [train acc 0.16551]\n",
      "[epoch 3], [iter 7900 / 35967], [train loss 2.18798], [train acc 0.16582]\n",
      "[epoch 3], [iter 8000 / 35967], [train loss 2.18943], [train acc 0.16525]\n",
      "[epoch 3], [iter 8100 / 35967], [train loss 2.18905], [train acc 0.16531]\n",
      "[epoch 3], [iter 8200 / 35967], [train loss 2.18835], [train acc 0.16598]\n",
      "[epoch 3], [iter 8300 / 35967], [train loss 2.18958], [train acc 0.16590]\n",
      "[epoch 3], [iter 8400 / 35967], [train loss 2.18908], [train acc 0.16560]\n",
      "[epoch 3], [iter 8500 / 35967], [train loss 2.18843], [train acc 0.16635]\n",
      "[epoch 3], [iter 8600 / 35967], [train loss 2.18847], [train acc 0.16651]\n",
      "[epoch 3], [iter 8700 / 35967], [train loss 2.18954], [train acc 0.16632]\n",
      "[epoch 3], [iter 8800 / 35967], [train loss 2.18919], [train acc 0.16614]\n",
      "[epoch 3], [iter 8900 / 35967], [train loss 2.19032], [train acc 0.16629]\n",
      "[epoch 3], [iter 9000 / 35967], [train loss 2.18930], [train acc 0.16644]\n",
      "[epoch 3], [iter 9100 / 35967], [train loss 2.18982], [train acc 0.16670]\n",
      "[epoch 3], [iter 9200 / 35967], [train loss 2.18794], [train acc 0.16772]\n",
      "[epoch 3], [iter 9300 / 35967], [train loss 2.18786], [train acc 0.16753]\n",
      "[epoch 3], [iter 9400 / 35967], [train loss 2.18616], [train acc 0.16851]\n",
      "[epoch 3], [iter 9500 / 35967], [train loss 2.18829], [train acc 0.16800]\n",
      "[epoch 3], [iter 9600 / 35967], [train loss 2.18797], [train acc 0.16875]\n",
      "[epoch 3], [iter 9700 / 35967], [train loss 2.18965], [train acc 0.16814]\n",
      "[epoch 3], [iter 9800 / 35967], [train loss 2.18883], [train acc 0.16857]\n",
      "[epoch 3], [iter 9900 / 35967], [train loss 2.18799], [train acc 0.16879]\n",
      "[epoch 3], [iter 10000 / 35967], [train loss 2.18856], [train acc 0.16900]\n",
      "[epoch 3], [iter 10100 / 35967], [train loss 2.18871], [train acc 0.16960]\n",
      "[epoch 3], [iter 10200 / 35967], [train loss 2.18845], [train acc 0.16990]\n",
      "[epoch 3], [iter 10300 / 35967], [train loss 2.18869], [train acc 0.16971]\n",
      "[epoch 3], [iter 10400 / 35967], [train loss 2.18848], [train acc 0.17048]\n",
      "[epoch 3], [iter 10500 / 35967], [train loss 2.18807], [train acc 0.17029]\n",
      "[epoch 3], [iter 10600 / 35967], [train loss 2.18871], [train acc 0.17000]\n",
      "[epoch 3], [iter 10700 / 35967], [train loss 2.18984], [train acc 0.16991]\n",
      "[epoch 3], [iter 10800 / 35967], [train loss 2.18940], [train acc 0.17019]\n",
      "[epoch 3], [iter 10900 / 35967], [train loss 2.18922], [train acc 0.17064]\n",
      "[epoch 3], [iter 11000 / 35967], [train loss 2.19053], [train acc 0.17018]\n",
      "[epoch 3], [iter 11100 / 35967], [train loss 2.19044], [train acc 0.16982]\n",
      "[epoch 3], [iter 11200 / 35967], [train loss 2.19050], [train acc 0.16937]\n",
      "[epoch 3], [iter 11300 / 35967], [train loss 2.19014], [train acc 0.16956]\n",
      "[epoch 3], [iter 11400 / 35967], [train loss 2.19064], [train acc 0.16904]\n",
      "[epoch 3], [iter 11500 / 35967], [train loss 2.19075], [train acc 0.16870]\n",
      "[epoch 3], [iter 11600 / 35967], [train loss 2.19136], [train acc 0.16819]\n",
      "[epoch 3], [iter 11700 / 35967], [train loss 2.19204], [train acc 0.16795]\n",
      "[epoch 3], [iter 11800 / 35967], [train loss 2.19046], [train acc 0.16839]\n",
      "[epoch 3], [iter 11900 / 35967], [train loss 2.19032], [train acc 0.16815]\n",
      "[epoch 3], [iter 12000 / 35967], [train loss 2.18904], [train acc 0.16850]\n",
      "[epoch 3], [iter 12100 / 35967], [train loss 2.18968], [train acc 0.16876]\n",
      "[epoch 3], [iter 12200 / 35967], [train loss 2.19014], [train acc 0.16844]\n",
      "[epoch 3], [iter 12300 / 35967], [train loss 2.19011], [train acc 0.16829]\n",
      "[epoch 3], [iter 12400 / 35967], [train loss 2.18990], [train acc 0.16823]\n",
      "[epoch 3], [iter 12500 / 35967], [train loss 2.19021], [train acc 0.16752]\n",
      "[epoch 3], [iter 12600 / 35967], [train loss 2.19075], [train acc 0.16706]\n",
      "[epoch 3], [iter 12700 / 35967], [train loss 2.19065], [train acc 0.16717]\n",
      "[epoch 3], [iter 12800 / 35967], [train loss 2.19209], [train acc 0.16719]\n",
      "[epoch 3], [iter 12900 / 35967], [train loss 2.19186], [train acc 0.16721]\n",
      "[epoch 3], [iter 13000 / 35967], [train loss 2.19015], [train acc 0.16808]\n",
      "[epoch 3], [iter 13100 / 35967], [train loss 2.19062], [train acc 0.16802]\n",
      "[epoch 3], [iter 13200 / 35967], [train loss 2.19035], [train acc 0.16818]\n",
      "[epoch 3], [iter 13300 / 35967], [train loss 2.19113], [train acc 0.16797]\n",
      "[epoch 3], [iter 13400 / 35967], [train loss 2.19065], [train acc 0.16828]\n",
      "[epoch 3], [iter 13500 / 35967], [train loss 2.19000], [train acc 0.16800]\n",
      "[epoch 3], [iter 13600 / 35967], [train loss 2.18993], [train acc 0.16794]\n",
      "[epoch 3], [iter 13700 / 35967], [train loss 2.18903], [train acc 0.16810]\n",
      "[epoch 3], [iter 13800 / 35967], [train loss 2.18870], [train acc 0.16833]\n",
      "[epoch 3], [iter 13900 / 35967], [train loss 2.18869], [train acc 0.16842]\n",
      "[epoch 3], [iter 14000 / 35967], [train loss 2.18874], [train acc 0.16871]\n",
      "[epoch 3], [iter 14100 / 35967], [train loss 2.18907], [train acc 0.16865]\n",
      "[epoch 3], [iter 14200 / 35967], [train loss 2.18890], [train acc 0.16803]\n",
      "[epoch 3], [iter 14300 / 35967], [train loss 2.18826], [train acc 0.16811]\n",
      "[epoch 3], [iter 14400 / 35967], [train loss 2.18823], [train acc 0.16833]\n",
      "[epoch 3], [iter 14500 / 35967], [train loss 2.18731], [train acc 0.16848]\n",
      "[epoch 3], [iter 14600 / 35967], [train loss 2.18706], [train acc 0.16870]\n",
      "[epoch 3], [iter 14700 / 35967], [train loss 2.18650], [train acc 0.16878]\n",
      "[epoch 3], [iter 14800 / 35967], [train loss 2.18666], [train acc 0.16872]\n",
      "[epoch 3], [iter 14900 / 35967], [train loss 2.18660], [train acc 0.16852]\n",
      "[epoch 3], [iter 15000 / 35967], [train loss 2.18703], [train acc 0.16860]\n",
      "[epoch 3], [iter 15100 / 35967], [train loss 2.18748], [train acc 0.16894]\n",
      "[epoch 3], [iter 15200 / 35967], [train loss 2.18754], [train acc 0.16901]\n",
      "[epoch 3], [iter 15300 / 35967], [train loss 2.18707], [train acc 0.16908]\n",
      "[epoch 3], [iter 15400 / 35967], [train loss 2.18715], [train acc 0.16942]\n",
      "[epoch 3], [iter 15500 / 35967], [train loss 2.18698], [train acc 0.16948]\n",
      "[epoch 3], [iter 15600 / 35967], [train loss 2.18698], [train acc 0.16923]\n",
      "[epoch 3], [iter 15700 / 35967], [train loss 2.18617], [train acc 0.16949]\n",
      "[epoch 3], [iter 15800 / 35967], [train loss 2.18697], [train acc 0.16918]\n",
      "[epoch 3], [iter 15900 / 35967], [train loss 2.18688], [train acc 0.16925]\n",
      "[epoch 3], [iter 16000 / 35967], [train loss 2.18633], [train acc 0.16931]\n",
      "[epoch 3], [iter 16100 / 35967], [train loss 2.18690], [train acc 0.16932]\n",
      "[epoch 3], [iter 16200 / 35967], [train loss 2.18683], [train acc 0.16944]\n",
      "[epoch 3], [iter 16300 / 35967], [train loss 2.18639], [train acc 0.16951]\n",
      "[epoch 3], [iter 16400 / 35967], [train loss 2.18673], [train acc 0.16933]\n",
      "[epoch 3], [iter 16500 / 35967], [train loss 2.18655], [train acc 0.16915]\n",
      "[epoch 3], [iter 16600 / 35967], [train loss 2.18598], [train acc 0.16934]\n",
      "[epoch 3], [iter 16700 / 35967], [train loss 2.18687], [train acc 0.16946]\n",
      "[epoch 3], [iter 16800 / 35967], [train loss 2.18706], [train acc 0.16964]\n",
      "[epoch 3], [iter 16900 / 35967], [train loss 2.18748], [train acc 0.16905]\n",
      "[epoch 3], [iter 17000 / 35967], [train loss 2.18723], [train acc 0.16912]\n",
      "[epoch 3], [iter 17100 / 35967], [train loss 2.18718], [train acc 0.16889]\n",
      "[epoch 3], [iter 17200 / 35967], [train loss 2.18792], [train acc 0.16878]\n",
      "[epoch 3], [iter 17300 / 35967], [train loss 2.18789], [train acc 0.16890]\n",
      "[epoch 3], [iter 17400 / 35967], [train loss 2.18768], [train acc 0.16908]\n",
      "[epoch 3], [iter 17500 / 35967], [train loss 2.18792], [train acc 0.16903]\n",
      "[epoch 3], [iter 17600 / 35967], [train loss 2.18753], [train acc 0.16898]\n",
      "[epoch 3], [iter 17700 / 35967], [train loss 2.18740], [train acc 0.16887]\n",
      "[epoch 3], [iter 17800 / 35967], [train loss 2.18760], [train acc 0.16888]\n",
      "[epoch 3], [iter 17900 / 35967], [train loss 2.18802], [train acc 0.16872]\n",
      "[epoch 3], [iter 18000 / 35967], [train loss 2.18762], [train acc 0.16889]\n",
      "[epoch 3], [iter 18100 / 35967], [train loss 2.18766], [train acc 0.16923]\n",
      "[epoch 3], [iter 18200 / 35967], [train loss 2.18762], [train acc 0.16918]\n",
      "[epoch 3], [iter 18300 / 35967], [train loss 2.18867], [train acc 0.16918]\n",
      "[epoch 3], [iter 18400 / 35967], [train loss 2.18893], [train acc 0.16929]\n",
      "[epoch 3], [iter 18500 / 35967], [train loss 2.18900], [train acc 0.16919]\n",
      "[epoch 3], [iter 18600 / 35967], [train loss 2.18861], [train acc 0.16919]\n",
      "[epoch 3], [iter 18700 / 35967], [train loss 2.18879], [train acc 0.16925]\n",
      "[epoch 3], [iter 18800 / 35967], [train loss 2.18889], [train acc 0.16920]\n",
      "[epoch 3], [iter 18900 / 35967], [train loss 2.18914], [train acc 0.16884]\n",
      "[epoch 3], [iter 19000 / 35967], [train loss 2.18886], [train acc 0.16879]\n",
      "[epoch 3], [iter 19100 / 35967], [train loss 2.18861], [train acc 0.16895]\n",
      "[epoch 3], [iter 19200 / 35967], [train loss 2.18856], [train acc 0.16885]\n",
      "[epoch 3], [iter 19300 / 35967], [train loss 2.18839], [train acc 0.16891]\n",
      "[epoch 3], [iter 19400 / 35967], [train loss 2.18865], [train acc 0.16876]\n",
      "[epoch 3], [iter 19500 / 35967], [train loss 2.18888], [train acc 0.16836]\n",
      "[epoch 3], [iter 19600 / 35967], [train loss 2.18845], [train acc 0.16857]\n",
      "[epoch 3], [iter 19700 / 35967], [train loss 2.18841], [train acc 0.16843]\n",
      "[epoch 3], [iter 19800 / 35967], [train loss 2.18799], [train acc 0.16859]\n",
      "[epoch 3], [iter 19900 / 35967], [train loss 2.18795], [train acc 0.16874]\n",
      "[epoch 3], [iter 20000 / 35967], [train loss 2.18772], [train acc 0.16890]\n",
      "[epoch 3], [iter 20100 / 35967], [train loss 2.18789], [train acc 0.16871]\n",
      "[epoch 3], [iter 20200 / 35967], [train loss 2.18756], [train acc 0.16886]\n",
      "[epoch 3], [iter 20300 / 35967], [train loss 2.18726], [train acc 0.16901]\n",
      "[epoch 3], [iter 20400 / 35967], [train loss 2.18726], [train acc 0.16882]\n",
      "[epoch 3], [iter 20500 / 35967], [train loss 2.18712], [train acc 0.16873]\n",
      "[epoch 3], [iter 20600 / 35967], [train loss 2.18738], [train acc 0.16908]\n",
      "[epoch 3], [iter 20700 / 35967], [train loss 2.18696], [train acc 0.16923]\n",
      "[epoch 3], [iter 20800 / 35967], [train loss 2.18727], [train acc 0.16904]\n",
      "[epoch 3], [iter 20900 / 35967], [train loss 2.18691], [train acc 0.16938]\n",
      "[epoch 3], [iter 21000 / 35967], [train loss 2.18677], [train acc 0.16948]\n",
      "[epoch 3], [iter 21100 / 35967], [train loss 2.18676], [train acc 0.16957]\n",
      "[epoch 3], [iter 21200 / 35967], [train loss 2.18726], [train acc 0.16948]\n",
      "[epoch 3], [iter 21300 / 35967], [train loss 2.18713], [train acc 0.16948]\n",
      "[epoch 3], [iter 21400 / 35967], [train loss 2.18752], [train acc 0.16963]\n",
      "[epoch 3], [iter 21500 / 35967], [train loss 2.18774], [train acc 0.16958]\n",
      "[epoch 3], [iter 21600 / 35967], [train loss 2.18779], [train acc 0.16972]\n",
      "[epoch 3], [iter 21700 / 35967], [train loss 2.18820], [train acc 0.17005]\n",
      "[epoch 3], [iter 21800 / 35967], [train loss 2.18873], [train acc 0.17000]\n",
      "[epoch 3], [iter 21900 / 35967], [train loss 2.18919], [train acc 0.16991]\n",
      "[epoch 3], [iter 22000 / 35967], [train loss 2.18903], [train acc 0.16986]\n",
      "[epoch 3], [iter 22100 / 35967], [train loss 2.18891], [train acc 0.16977]\n",
      "[epoch 3], [iter 22200 / 35967], [train loss 2.18876], [train acc 0.16991]\n",
      "[epoch 3], [iter 22300 / 35967], [train loss 2.18863], [train acc 0.16987]\n",
      "[epoch 3], [iter 22400 / 35967], [train loss 2.18869], [train acc 0.16987]\n",
      "[epoch 3], [iter 22500 / 35967], [train loss 2.18834], [train acc 0.17004]\n",
      "[epoch 3], [iter 22600 / 35967], [train loss 2.18815], [train acc 0.17009]\n",
      "[epoch 3], [iter 22700 / 35967], [train loss 2.18818], [train acc 0.16991]\n",
      "[epoch 3], [iter 22800 / 35967], [train loss 2.18779], [train acc 0.16996]\n",
      "[epoch 3], [iter 22900 / 35967], [train loss 2.18776], [train acc 0.17009]\n",
      "[epoch 3], [iter 23000 / 35967], [train loss 2.18789], [train acc 0.17022]\n",
      "[epoch 3], [iter 23100 / 35967], [train loss 2.18793], [train acc 0.17013]\n",
      "[epoch 3], [iter 23200 / 35967], [train loss 2.18852], [train acc 0.17013]\n",
      "[epoch 3], [iter 23300 / 35967], [train loss 2.18860], [train acc 0.17030]\n",
      "[epoch 3], [iter 23400 / 35967], [train loss 2.18831], [train acc 0.17056]\n",
      "[epoch 3], [iter 23500 / 35967], [train loss 2.18851], [train acc 0.17051]\n",
      "[epoch 3], [iter 23600 / 35967], [train loss 2.18860], [train acc 0.17034]\n",
      "[epoch 3], [iter 23700 / 35967], [train loss 2.18849], [train acc 0.17017]\n",
      "[epoch 3], [iter 23800 / 35967], [train loss 2.18904], [train acc 0.17004]\n",
      "[epoch 3], [iter 23900 / 35967], [train loss 2.18892], [train acc 0.16996]\n",
      "[epoch 3], [iter 24000 / 35967], [train loss 2.18886], [train acc 0.16983]\n",
      "[epoch 3], [iter 24100 / 35967], [train loss 2.18858], [train acc 0.17004]\n",
      "[epoch 3], [iter 24200 / 35967], [train loss 2.18864], [train acc 0.17017]\n",
      "[epoch 3], [iter 24300 / 35967], [train loss 2.18862], [train acc 0.17016]\n",
      "[epoch 3], [iter 24400 / 35967], [train loss 2.18890], [train acc 0.17037]\n",
      "[epoch 3], [iter 24500 / 35967], [train loss 2.18900], [train acc 0.17033]\n",
      "[epoch 3], [iter 24600 / 35967], [train loss 2.18883], [train acc 0.17028]\n",
      "[epoch 3], [iter 24700 / 35967], [train loss 2.18897], [train acc 0.17028]\n",
      "[epoch 3], [iter 24800 / 35967], [train loss 2.18935], [train acc 0.17044]\n",
      "[epoch 3], [iter 24900 / 35967], [train loss 2.18926], [train acc 0.17040]\n",
      "[epoch 3], [iter 25000 / 35967], [train loss 2.18884], [train acc 0.17052]\n",
      "[epoch 3], [iter 25100 / 35967], [train loss 2.18851], [train acc 0.17056]\n",
      "[epoch 3], [iter 25200 / 35967], [train loss 2.18840], [train acc 0.17063]\n",
      "[epoch 3], [iter 25300 / 35967], [train loss 2.18901], [train acc 0.17071]\n",
      "[epoch 3], [iter 25400 / 35967], [train loss 2.18888], [train acc 0.17067]\n",
      "[epoch 3], [iter 25500 / 35967], [train loss 2.18866], [train acc 0.17055]\n",
      "[epoch 3], [iter 25600 / 35967], [train loss 2.18904], [train acc 0.17027]\n",
      "[epoch 3], [iter 25700 / 35967], [train loss 2.18873], [train acc 0.17043]\n",
      "[epoch 3], [iter 25800 / 35967], [train loss 2.18911], [train acc 0.17035]\n",
      "[epoch 3], [iter 25900 / 35967], [train loss 2.18884], [train acc 0.17069]\n",
      "[epoch 3], [iter 26000 / 35967], [train loss 2.18905], [train acc 0.17062]\n",
      "[epoch 3], [iter 26100 / 35967], [train loss 2.18931], [train acc 0.17065]\n",
      "[epoch 3], [iter 26200 / 35967], [train loss 2.18975], [train acc 0.17061]\n",
      "[epoch 3], [iter 26300 / 35967], [train loss 2.19012], [train acc 0.17042]\n",
      "[epoch 3], [iter 26400 / 35967], [train loss 2.18974], [train acc 0.17034]\n",
      "[epoch 3], [iter 26500 / 35967], [train loss 2.19027], [train acc 0.17019]\n",
      "[epoch 3], [iter 26600 / 35967], [train loss 2.19037], [train acc 0.17011]\n",
      "[epoch 3], [iter 26700 / 35967], [train loss 2.19049], [train acc 0.16993]\n",
      "[epoch 3], [iter 26800 / 35967], [train loss 2.19073], [train acc 0.16989]\n",
      "[epoch 3], [iter 26900 / 35967], [train loss 2.19094], [train acc 0.16967]\n",
      "[epoch 3], [iter 27000 / 35967], [train loss 2.19105], [train acc 0.16963]\n",
      "[epoch 3], [iter 27100 / 35967], [train loss 2.19069], [train acc 0.16974]\n",
      "[epoch 3], [iter 27200 / 35967], [train loss 2.19101], [train acc 0.16963]\n",
      "[epoch 3], [iter 27300 / 35967], [train loss 2.19124], [train acc 0.16952]\n",
      "[epoch 3], [iter 27400 / 35967], [train loss 2.19102], [train acc 0.16967]\n",
      "[epoch 3], [iter 27500 / 35967], [train loss 2.19087], [train acc 0.16971]\n",
      "[epoch 3], [iter 27600 / 35967], [train loss 2.19087], [train acc 0.16960]\n",
      "[epoch 3], [iter 27700 / 35967], [train loss 2.19103], [train acc 0.16960]\n",
      "[epoch 3], [iter 27800 / 35967], [train loss 2.19080], [train acc 0.16939]\n",
      "[epoch 3], [iter 27900 / 35967], [train loss 2.19057], [train acc 0.16953]\n",
      "[epoch 3], [iter 28000 / 35967], [train loss 2.19055], [train acc 0.16946]\n",
      "[epoch 3], [iter 28100 / 35967], [train loss 2.19073], [train acc 0.16943]\n",
      "[epoch 3], [iter 28200 / 35967], [train loss 2.19033], [train acc 0.16933]\n",
      "[epoch 3], [iter 28300 / 35967], [train loss 2.18988], [train acc 0.16929]\n",
      "[epoch 3], [iter 28400 / 35967], [train loss 2.19006], [train acc 0.16923]\n",
      "[epoch 3], [iter 28500 / 35967], [train loss 2.18983], [train acc 0.16926]\n",
      "[epoch 3], [iter 28600 / 35967], [train loss 2.19017], [train acc 0.16937]\n",
      "[epoch 3], [iter 28700 / 35967], [train loss 2.19063], [train acc 0.16923]\n",
      "[epoch 3], [iter 28800 / 35967], [train loss 2.19057], [train acc 0.16920]\n",
      "[epoch 3], [iter 28900 / 35967], [train loss 2.19030], [train acc 0.16962]\n",
      "[epoch 3], [iter 29000 / 35967], [train loss 2.19018], [train acc 0.16952]\n",
      "[epoch 3], [iter 29100 / 35967], [train loss 2.19029], [train acc 0.16945]\n",
      "[epoch 3], [iter 29200 / 35967], [train loss 2.19040], [train acc 0.16935]\n",
      "[epoch 3], [iter 29300 / 35967], [train loss 2.19101], [train acc 0.16922]\n",
      "[epoch 3], [iter 29400 / 35967], [train loss 2.19107], [train acc 0.16915]\n",
      "[epoch 3], [iter 29500 / 35967], [train loss 2.19103], [train acc 0.16946]\n",
      "[epoch 3], [iter 29600 / 35967], [train loss 2.19072], [train acc 0.16970]\n",
      "[epoch 3], [iter 29700 / 35967], [train loss 2.19077], [train acc 0.16966]\n",
      "[epoch 3], [iter 29800 / 35967], [train loss 2.19092], [train acc 0.16993]\n",
      "[epoch 3], [iter 29900 / 35967], [train loss 2.19103], [train acc 0.16983]\n",
      "[epoch 3], [iter 30000 / 35967], [train loss 2.19161], [train acc 0.16963]\n",
      "[epoch 3], [iter 30100 / 35967], [train loss 2.19177], [train acc 0.16970]\n",
      "[epoch 3], [iter 30200 / 35967], [train loss 2.19186], [train acc 0.16967]\n",
      "[epoch 3], [iter 30300 / 35967], [train loss 2.19177], [train acc 0.16964]\n",
      "[epoch 3], [iter 30400 / 35967], [train loss 2.19166], [train acc 0.16964]\n",
      "[epoch 3], [iter 30500 / 35967], [train loss 2.19176], [train acc 0.16938]\n",
      "[epoch 3], [iter 30600 / 35967], [train loss 2.19230], [train acc 0.16928]\n",
      "[epoch 3], [iter 30700 / 35967], [train loss 2.19202], [train acc 0.16925]\n",
      "[epoch 3], [iter 30800 / 35967], [train loss 2.19157], [train acc 0.16958]\n",
      "[epoch 3], [iter 30900 / 35967], [train loss 2.19183], [train acc 0.16948]\n",
      "[epoch 3], [iter 31000 / 35967], [train loss 2.19163], [train acc 0.16952]\n",
      "[epoch 3], [iter 31100 / 35967], [train loss 2.19168], [train acc 0.16949]\n",
      "[epoch 3], [iter 31200 / 35967], [train loss 2.19150], [train acc 0.16949]\n",
      "[epoch 3], [iter 31300 / 35967], [train loss 2.19157], [train acc 0.16930]\n",
      "[epoch 3], [iter 31400 / 35967], [train loss 2.19164], [train acc 0.16930]\n",
      "[epoch 3], [iter 31500 / 35967], [train loss 2.19199], [train acc 0.16962]\n",
      "[epoch 3], [iter 31600 / 35967], [train loss 2.19237], [train acc 0.16962]\n",
      "[epoch 3], [iter 31700 / 35967], [train loss 2.19206], [train acc 0.16956]\n",
      "[epoch 3], [iter 31800 / 35967], [train loss 2.19175], [train acc 0.16943]\n",
      "[epoch 3], [iter 31900 / 35967], [train loss 2.19191], [train acc 0.16940]\n",
      "[epoch 3], [iter 32000 / 35967], [train loss 2.19208], [train acc 0.16937]\n",
      "[epoch 3], [iter 32100 / 35967], [train loss 2.19205], [train acc 0.16938]\n",
      "[epoch 3], [iter 32200 / 35967], [train loss 2.19198], [train acc 0.16919]\n",
      "[epoch 3], [iter 32300 / 35967], [train loss 2.19179], [train acc 0.16926]\n",
      "[epoch 3], [iter 32400 / 35967], [train loss 2.19218], [train acc 0.16917]\n",
      "[epoch 3], [iter 32500 / 35967], [train loss 2.19207], [train acc 0.16932]\n",
      "[epoch 3], [iter 32600 / 35967], [train loss 2.19211], [train acc 0.16942]\n",
      "[epoch 3], [iter 32700 / 35967], [train loss 2.19212], [train acc 0.16936]\n",
      "[epoch 3], [iter 32800 / 35967], [train loss 2.19196], [train acc 0.16939]\n",
      "[epoch 3], [iter 32900 / 35967], [train loss 2.19213], [train acc 0.16936]\n",
      "[epoch 3], [iter 33000 / 35967], [train loss 2.19212], [train acc 0.16924]\n",
      "[epoch 3], [iter 33100 / 35967], [train loss 2.19165], [train acc 0.16952]\n",
      "[epoch 3], [iter 33200 / 35967], [train loss 2.19152], [train acc 0.16955]\n",
      "[epoch 3], [iter 33300 / 35967], [train loss 2.19157], [train acc 0.16955]\n",
      "[epoch 3], [iter 33400 / 35967], [train loss 2.19141], [train acc 0.16964]\n",
      "[epoch 3], [iter 33500 / 35967], [train loss 2.19127], [train acc 0.16982]\n",
      "[epoch 3], [iter 33600 / 35967], [train loss 2.19114], [train acc 0.16955]\n",
      "[epoch 3], [iter 33700 / 35967], [train loss 2.19118], [train acc 0.16961]\n",
      "[epoch 3], [iter 33800 / 35967], [train loss 2.19075], [train acc 0.16973]\n",
      "[epoch 3], [iter 33900 / 35967], [train loss 2.19104], [train acc 0.16976]\n",
      "[epoch 3], [iter 34000 / 35967], [train loss 2.19077], [train acc 0.16985]\n",
      "[epoch 3], [iter 34100 / 35967], [train loss 2.19069], [train acc 0.16979]\n",
      "[epoch 3], [iter 34200 / 35967], [train loss 2.19073], [train acc 0.16988]\n",
      "[epoch 3], [iter 34300 / 35967], [train loss 2.19030], [train acc 0.16991]\n",
      "[epoch 3], [iter 34400 / 35967], [train loss 2.19026], [train acc 0.16988]\n",
      "[epoch 3], [iter 34500 / 35967], [train loss 2.19003], [train acc 0.16994]\n",
      "[epoch 3], [iter 34600 / 35967], [train loss 2.19005], [train acc 0.17012]\n",
      "[epoch 3], [iter 34700 / 35967], [train loss 2.19010], [train acc 0.16997]\n",
      "[epoch 3], [iter 34800 / 35967], [train loss 2.19035], [train acc 0.17000]\n",
      "[epoch 3], [iter 34900 / 35967], [train loss 2.19020], [train acc 0.17014]\n",
      "[epoch 3], [iter 35000 / 35967], [train loss 2.19038], [train acc 0.17006]\n",
      "[epoch 3], [iter 35100 / 35967], [train loss 2.19067], [train acc 0.16983]\n",
      "[epoch 3], [iter 35200 / 35967], [train loss 2.19067], [train acc 0.16980]\n",
      "[epoch 3], [iter 35300 / 35967], [train loss 2.19058], [train acc 0.16994]\n",
      "[epoch 3], [iter 35400 / 35967], [train loss 2.19030], [train acc 0.16992]\n",
      "[epoch 3], [iter 35500 / 35967], [train loss 2.18993], [train acc 0.17008]\n",
      "[epoch 3], [iter 35600 / 35967], [train loss 2.18992], [train acc 0.17008]\n",
      "[epoch 3], [iter 35700 / 35967], [train loss 2.18984], [train acc 0.17008]\n",
      "[epoch 3], [iter 35800 / 35967], [train loss 2.18996], [train acc 0.16994]\n",
      "[epoch 3], [iter 35900 / 35967], [train loss 2.18997], [train acc 0.16994]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 3.50054], [val acc 0.21759]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 3], [val loss 3.50054], [val acc 0.21759]\n",
      "*****************************************************\n",
      "[epoch 4], [iter 100 / 35967], [train loss 2.13534], [train acc 0.22000]\n",
      "[epoch 4], [iter 200 / 35967], [train loss 2.12690], [train acc 0.21500]\n",
      "[epoch 4], [iter 300 / 35967], [train loss 2.13864], [train acc 0.21000]\n",
      "[epoch 4], [iter 400 / 35967], [train loss 2.13121], [train acc 0.20750]\n",
      "[epoch 4], [iter 500 / 35967], [train loss 2.12243], [train acc 0.19800]\n",
      "[epoch 4], [iter 600 / 35967], [train loss 2.13959], [train acc 0.19500]\n",
      "[epoch 4], [iter 700 / 35967], [train loss 2.14068], [train acc 0.19143]\n",
      "[epoch 4], [iter 800 / 35967], [train loss 2.14243], [train acc 0.17875]\n",
      "[epoch 4], [iter 900 / 35967], [train loss 2.14340], [train acc 0.17667]\n",
      "[epoch 4], [iter 1000 / 35967], [train loss 2.15822], [train acc 0.17000]\n",
      "[epoch 4], [iter 1100 / 35967], [train loss 2.16234], [train acc 0.17091]\n",
      "[epoch 4], [iter 1200 / 35967], [train loss 2.15377], [train acc 0.17250]\n",
      "[epoch 4], [iter 1300 / 35967], [train loss 2.14615], [train acc 0.17308]\n",
      "[epoch 4], [iter 1400 / 35967], [train loss 2.14350], [train acc 0.17500]\n",
      "[epoch 4], [iter 1500 / 35967], [train loss 2.14723], [train acc 0.17200]\n",
      "[epoch 4], [iter 1600 / 35967], [train loss 2.15826], [train acc 0.16937]\n",
      "[epoch 4], [iter 1700 / 35967], [train loss 2.15437], [train acc 0.17353]\n",
      "[epoch 4], [iter 1800 / 35967], [train loss 2.15602], [train acc 0.17389]\n",
      "[epoch 4], [iter 1900 / 35967], [train loss 2.15673], [train acc 0.17211]\n",
      "[epoch 4], [iter 2000 / 35967], [train loss 2.15955], [train acc 0.17000]\n",
      "[epoch 4], [iter 2100 / 35967], [train loss 2.15447], [train acc 0.17048]\n",
      "[epoch 4], [iter 2200 / 35967], [train loss 2.16153], [train acc 0.17273]\n",
      "[epoch 4], [iter 2300 / 35967], [train loss 2.16288], [train acc 0.17174]\n",
      "[epoch 4], [iter 2400 / 35967], [train loss 2.16115], [train acc 0.17375]\n",
      "[epoch 4], [iter 2500 / 35967], [train loss 2.16061], [train acc 0.17520]\n",
      "[epoch 4], [iter 2600 / 35967], [train loss 2.15821], [train acc 0.17385]\n",
      "[epoch 4], [iter 2700 / 35967], [train loss 2.15700], [train acc 0.17185]\n",
      "[epoch 4], [iter 2800 / 35967], [train loss 2.16177], [train acc 0.17071]\n",
      "[epoch 4], [iter 2900 / 35967], [train loss 2.15890], [train acc 0.17310]\n",
      "[epoch 4], [iter 3000 / 35967], [train loss 2.15809], [train acc 0.17433]\n",
      "[epoch 4], [iter 3100 / 35967], [train loss 2.16134], [train acc 0.17323]\n",
      "[epoch 4], [iter 3200 / 35967], [train loss 2.16358], [train acc 0.17375]\n",
      "[epoch 4], [iter 3300 / 35967], [train loss 2.16819], [train acc 0.17364]\n",
      "[epoch 4], [iter 3400 / 35967], [train loss 2.16762], [train acc 0.17206]\n",
      "[epoch 4], [iter 3500 / 35967], [train loss 2.16414], [train acc 0.17200]\n",
      "[epoch 4], [iter 3600 / 35967], [train loss 2.16449], [train acc 0.17222]\n",
      "[epoch 4], [iter 3700 / 35967], [train loss 2.16335], [train acc 0.17243]\n",
      "[epoch 4], [iter 3800 / 35967], [train loss 2.16132], [train acc 0.17237]\n",
      "[epoch 4], [iter 3900 / 35967], [train loss 2.15903], [train acc 0.17333]\n",
      "[epoch 4], [iter 4000 / 35967], [train loss 2.15947], [train acc 0.17375]\n",
      "[epoch 4], [iter 4100 / 35967], [train loss 2.15918], [train acc 0.17341]\n",
      "[epoch 4], [iter 4200 / 35967], [train loss 2.15993], [train acc 0.17286]\n",
      "[epoch 4], [iter 4300 / 35967], [train loss 2.16070], [train acc 0.17209]\n",
      "[epoch 4], [iter 4400 / 35967], [train loss 2.16178], [train acc 0.17250]\n",
      "[epoch 4], [iter 4500 / 35967], [train loss 2.16410], [train acc 0.17156]\n",
      "[epoch 4], [iter 4600 / 35967], [train loss 2.16698], [train acc 0.17239]\n",
      "[epoch 4], [iter 4700 / 35967], [train loss 2.16926], [train acc 0.17213]\n",
      "[epoch 4], [iter 4800 / 35967], [train loss 2.17048], [train acc 0.17146]\n",
      "[epoch 4], [iter 4900 / 35967], [train loss 2.17039], [train acc 0.17061]\n",
      "[epoch 4], [iter 5000 / 35967], [train loss 2.16950], [train acc 0.17160]\n",
      "[epoch 4], [iter 5100 / 35967], [train loss 2.17278], [train acc 0.17157]\n",
      "[epoch 4], [iter 5200 / 35967], [train loss 2.17334], [train acc 0.17154]\n",
      "[epoch 4], [iter 5300 / 35967], [train loss 2.17295], [train acc 0.17132]\n",
      "[epoch 4], [iter 5400 / 35967], [train loss 2.17221], [train acc 0.17185]\n",
      "[epoch 4], [iter 5500 / 35967], [train loss 2.17148], [train acc 0.17255]\n",
      "[epoch 4], [iter 5600 / 35967], [train loss 2.17192], [train acc 0.17268]\n",
      "[epoch 4], [iter 5700 / 35967], [train loss 2.17203], [train acc 0.17228]\n",
      "[epoch 4], [iter 5800 / 35967], [train loss 2.17316], [train acc 0.17207]\n",
      "[epoch 4], [iter 5900 / 35967], [train loss 2.17267], [train acc 0.17271]\n",
      "[epoch 4], [iter 6000 / 35967], [train loss 2.17216], [train acc 0.17150]\n",
      "[epoch 4], [iter 6100 / 35967], [train loss 2.16991], [train acc 0.17148]\n",
      "[epoch 4], [iter 6200 / 35967], [train loss 2.16947], [train acc 0.17177]\n",
      "[epoch 4], [iter 6300 / 35967], [train loss 2.17010], [train acc 0.17175]\n",
      "[epoch 4], [iter 6400 / 35967], [train loss 2.17108], [train acc 0.17203]\n",
      "[epoch 4], [iter 6500 / 35967], [train loss 2.16969], [train acc 0.17308]\n",
      "[epoch 4], [iter 6600 / 35967], [train loss 2.16839], [train acc 0.17485]\n",
      "[epoch 4], [iter 6700 / 35967], [train loss 2.16842], [train acc 0.17433]\n",
      "[epoch 4], [iter 6800 / 35967], [train loss 2.16874], [train acc 0.17441]\n",
      "[epoch 4], [iter 6900 / 35967], [train loss 2.16703], [train acc 0.17406]\n",
      "[epoch 4], [iter 7000 / 35967], [train loss 2.16767], [train acc 0.17486]\n",
      "[epoch 4], [iter 7100 / 35967], [train loss 2.16722], [train acc 0.17563]\n",
      "[epoch 4], [iter 7200 / 35967], [train loss 2.16881], [train acc 0.17528]\n",
      "[epoch 4], [iter 7300 / 35967], [train loss 2.16979], [train acc 0.17562]\n",
      "[epoch 4], [iter 7400 / 35967], [train loss 2.17011], [train acc 0.17554]\n",
      "[epoch 4], [iter 7500 / 35967], [train loss 2.16979], [train acc 0.17587]\n",
      "[epoch 4], [iter 7600 / 35967], [train loss 2.16934], [train acc 0.17579]\n",
      "[epoch 4], [iter 7700 / 35967], [train loss 2.16930], [train acc 0.17558]\n",
      "[epoch 4], [iter 7800 / 35967], [train loss 2.16891], [train acc 0.17551]\n",
      "[epoch 4], [iter 7900 / 35967], [train loss 2.16932], [train acc 0.17481]\n",
      "[epoch 4], [iter 8000 / 35967], [train loss 2.16842], [train acc 0.17538]\n",
      "[epoch 4], [iter 8100 / 35967], [train loss 2.16876], [train acc 0.17481]\n",
      "[epoch 4], [iter 8200 / 35967], [train loss 2.16804], [train acc 0.17476]\n",
      "[epoch 4], [iter 8300 / 35967], [train loss 2.16949], [train acc 0.17506]\n",
      "[epoch 4], [iter 8400 / 35967], [train loss 2.16939], [train acc 0.17500]\n",
      "[epoch 4], [iter 8500 / 35967], [train loss 2.16849], [train acc 0.17494]\n",
      "[epoch 4], [iter 8600 / 35967], [train loss 2.16845], [train acc 0.17523]\n",
      "[epoch 4], [iter 8700 / 35967], [train loss 2.16897], [train acc 0.17517]\n",
      "[epoch 4], [iter 8800 / 35967], [train loss 2.16793], [train acc 0.17523]\n",
      "[epoch 4], [iter 8900 / 35967], [train loss 2.16883], [train acc 0.17483]\n",
      "[epoch 4], [iter 9000 / 35967], [train loss 2.16809], [train acc 0.17456]\n",
      "[epoch 4], [iter 9100 / 35967], [train loss 2.16811], [train acc 0.17462]\n",
      "[epoch 4], [iter 9200 / 35967], [train loss 2.16799], [train acc 0.17500]\n",
      "[epoch 4], [iter 9300 / 35967], [train loss 2.16839], [train acc 0.17462]\n",
      "[epoch 4], [iter 9400 / 35967], [train loss 2.16666], [train acc 0.17532]\n",
      "[epoch 4], [iter 9500 / 35967], [train loss 2.16677], [train acc 0.17442]\n",
      "[epoch 4], [iter 9600 / 35967], [train loss 2.16598], [train acc 0.17427]\n",
      "[epoch 4], [iter 9700 / 35967], [train loss 2.16686], [train acc 0.17402]\n",
      "[epoch 4], [iter 9800 / 35967], [train loss 2.16732], [train acc 0.17388]\n",
      "[epoch 4], [iter 9900 / 35967], [train loss 2.16767], [train acc 0.17394]\n",
      "[epoch 4], [iter 10000 / 35967], [train loss 2.16664], [train acc 0.17440]\n",
      "[epoch 4], [iter 10100 / 35967], [train loss 2.16704], [train acc 0.17446]\n",
      "[epoch 4], [iter 10200 / 35967], [train loss 2.16775], [train acc 0.17422]\n",
      "[epoch 4], [iter 10300 / 35967], [train loss 2.16719], [train acc 0.17427]\n",
      "[epoch 4], [iter 10400 / 35967], [train loss 2.16686], [train acc 0.17452]\n",
      "[epoch 4], [iter 10500 / 35967], [train loss 2.16657], [train acc 0.17486]\n",
      "[epoch 4], [iter 10600 / 35967], [train loss 2.16571], [train acc 0.17481]\n",
      "[epoch 4], [iter 10700 / 35967], [train loss 2.16603], [train acc 0.17486]\n",
      "[epoch 4], [iter 10800 / 35967], [train loss 2.16743], [train acc 0.17472]\n",
      "[epoch 4], [iter 10900 / 35967], [train loss 2.16742], [train acc 0.17422]\n",
      "[epoch 4], [iter 11000 / 35967], [train loss 2.16717], [train acc 0.17455]\n",
      "[epoch 4], [iter 11100 / 35967], [train loss 2.16634], [train acc 0.17486]\n",
      "[epoch 4], [iter 11200 / 35967], [train loss 2.16612], [train acc 0.17473]\n",
      "[epoch 4], [iter 11300 / 35967], [train loss 2.16557], [train acc 0.17487]\n",
      "[epoch 4], [iter 11400 / 35967], [train loss 2.16522], [train acc 0.17500]\n",
      "[epoch 4], [iter 11500 / 35967], [train loss 2.16519], [train acc 0.17522]\n",
      "[epoch 4], [iter 11600 / 35967], [train loss 2.16581], [train acc 0.17509]\n",
      "[epoch 4], [iter 11700 / 35967], [train loss 2.16708], [train acc 0.17504]\n",
      "[epoch 4], [iter 11800 / 35967], [train loss 2.16684], [train acc 0.17508]\n",
      "[epoch 4], [iter 11900 / 35967], [train loss 2.16704], [train acc 0.17504]\n",
      "[epoch 4], [iter 12000 / 35967], [train loss 2.16719], [train acc 0.17508]\n",
      "[epoch 4], [iter 12100 / 35967], [train loss 2.16714], [train acc 0.17479]\n",
      "[epoch 4], [iter 12200 / 35967], [train loss 2.16718], [train acc 0.17467]\n",
      "[epoch 4], [iter 12300 / 35967], [train loss 2.16705], [train acc 0.17480]\n",
      "[epoch 4], [iter 12400 / 35967], [train loss 2.16691], [train acc 0.17476]\n",
      "[epoch 4], [iter 12500 / 35967], [train loss 2.16746], [train acc 0.17456]\n",
      "[epoch 4], [iter 12600 / 35967], [train loss 2.16742], [train acc 0.17444]\n",
      "[epoch 4], [iter 12700 / 35967], [train loss 2.16790], [train acc 0.17465]\n",
      "[epoch 4], [iter 12800 / 35967], [train loss 2.16726], [train acc 0.17445]\n",
      "[epoch 4], [iter 12900 / 35967], [train loss 2.16742], [train acc 0.17434]\n",
      "[epoch 4], [iter 13000 / 35967], [train loss 2.16747], [train acc 0.17392]\n",
      "[epoch 4], [iter 13100 / 35967], [train loss 2.16678], [train acc 0.17382]\n",
      "[epoch 4], [iter 13200 / 35967], [train loss 2.16631], [train acc 0.17394]\n",
      "[epoch 4], [iter 13300 / 35967], [train loss 2.16594], [train acc 0.17383]\n",
      "[epoch 4], [iter 13400 / 35967], [train loss 2.16515], [train acc 0.17410]\n",
      "[epoch 4], [iter 13500 / 35967], [train loss 2.16584], [train acc 0.17378]\n",
      "[epoch 4], [iter 13600 / 35967], [train loss 2.16651], [train acc 0.17324]\n",
      "[epoch 4], [iter 13700 / 35967], [train loss 2.16577], [train acc 0.17343]\n",
      "[epoch 4], [iter 13800 / 35967], [train loss 2.16544], [train acc 0.17312]\n",
      "[epoch 4], [iter 13900 / 35967], [train loss 2.16527], [train acc 0.17317]\n",
      "[epoch 4], [iter 14000 / 35967], [train loss 2.16438], [train acc 0.17307]\n",
      "[epoch 4], [iter 14100 / 35967], [train loss 2.16504], [train acc 0.17270]\n",
      "[epoch 4], [iter 14200 / 35967], [train loss 2.16570], [train acc 0.17268]\n",
      "[epoch 4], [iter 14300 / 35967], [train loss 2.16652], [train acc 0.17238]\n",
      "[epoch 4], [iter 14400 / 35967], [train loss 2.16596], [train acc 0.17292]\n",
      "[epoch 4], [iter 14500 / 35967], [train loss 2.16622], [train acc 0.17290]\n",
      "[epoch 4], [iter 14600 / 35967], [train loss 2.16584], [train acc 0.17281]\n",
      "[epoch 4], [iter 14700 / 35967], [train loss 2.16545], [train acc 0.17293]\n",
      "[epoch 4], [iter 14800 / 35967], [train loss 2.16597], [train acc 0.17297]\n",
      "[epoch 4], [iter 14900 / 35967], [train loss 2.16609], [train acc 0.17295]\n",
      "[epoch 4], [iter 15000 / 35967], [train loss 2.16661], [train acc 0.17293]\n",
      "[epoch 4], [iter 15100 / 35967], [train loss 2.16625], [train acc 0.17285]\n",
      "[epoch 4], [iter 15200 / 35967], [train loss 2.16607], [train acc 0.17283]\n",
      "[epoch 4], [iter 15300 / 35967], [train loss 2.16611], [train acc 0.17275]\n",
      "[epoch 4], [iter 15400 / 35967], [train loss 2.16622], [train acc 0.17253]\n",
      "[epoch 4], [iter 15500 / 35967], [train loss 2.16603], [train acc 0.17252]\n",
      "[epoch 4], [iter 15600 / 35967], [train loss 2.16611], [train acc 0.17288]\n",
      "[epoch 4], [iter 15700 / 35967], [train loss 2.16560], [train acc 0.17318]\n",
      "[epoch 4], [iter 15800 / 35967], [train loss 2.16552], [train acc 0.17335]\n",
      "[epoch 4], [iter 15900 / 35967], [train loss 2.16634], [train acc 0.17302]\n",
      "[epoch 4], [iter 16000 / 35967], [train loss 2.16708], [train acc 0.17288]\n",
      "[epoch 4], [iter 16100 / 35967], [train loss 2.16672], [train acc 0.17267]\n",
      "[epoch 4], [iter 16200 / 35967], [train loss 2.16653], [train acc 0.17265]\n",
      "[epoch 4], [iter 16300 / 35967], [train loss 2.16674], [train acc 0.17258]\n",
      "[epoch 4], [iter 16400 / 35967], [train loss 2.16678], [train acc 0.17280]\n",
      "[epoch 4], [iter 16500 / 35967], [train loss 2.16619], [train acc 0.17297]\n",
      "[epoch 4], [iter 16600 / 35967], [train loss 2.16654], [train acc 0.17277]\n",
      "[epoch 4], [iter 16700 / 35967], [train loss 2.16671], [train acc 0.17287]\n",
      "[epoch 4], [iter 16800 / 35967], [train loss 2.16665], [train acc 0.17298]\n",
      "[epoch 4], [iter 16900 / 35967], [train loss 2.16661], [train acc 0.17290]\n",
      "[epoch 4], [iter 17000 / 35967], [train loss 2.16665], [train acc 0.17294]\n",
      "[epoch 4], [iter 17100 / 35967], [train loss 2.16665], [train acc 0.17257]\n",
      "[epoch 4], [iter 17200 / 35967], [train loss 2.16598], [train acc 0.17308]\n",
      "[epoch 4], [iter 17300 / 35967], [train loss 2.16539], [train acc 0.17324]\n",
      "[epoch 4], [iter 17400 / 35967], [train loss 2.16523], [train acc 0.17328]\n",
      "[epoch 4], [iter 17500 / 35967], [train loss 2.16469], [train acc 0.17326]\n",
      "[epoch 4], [iter 17600 / 35967], [train loss 2.16481], [train acc 0.17301]\n",
      "[epoch 4], [iter 17700 / 35967], [train loss 2.16446], [train acc 0.17316]\n",
      "[epoch 4], [iter 17800 / 35967], [train loss 2.16397], [train acc 0.17343]\n",
      "[epoch 4], [iter 17900 / 35967], [train loss 2.16371], [train acc 0.17358]\n",
      "[epoch 4], [iter 18000 / 35967], [train loss 2.16443], [train acc 0.17356]\n",
      "[epoch 4], [iter 18100 / 35967], [train loss 2.16438], [train acc 0.17348]\n",
      "[epoch 4], [iter 18200 / 35967], [train loss 2.16456], [train acc 0.17335]\n",
      "[epoch 4], [iter 18300 / 35967], [train loss 2.16458], [train acc 0.17350]\n",
      "[epoch 4], [iter 18400 / 35967], [train loss 2.16470], [train acc 0.17321]\n",
      "[epoch 4], [iter 18500 / 35967], [train loss 2.16447], [train acc 0.17319]\n",
      "[epoch 4], [iter 18600 / 35967], [train loss 2.16424], [train acc 0.17323]\n",
      "[epoch 4], [iter 18700 / 35967], [train loss 2.16429], [train acc 0.17321]\n",
      "[epoch 4], [iter 18800 / 35967], [train loss 2.16387], [train acc 0.17340]\n",
      "[epoch 4], [iter 18900 / 35967], [train loss 2.16399], [train acc 0.17354]\n",
      "[epoch 4], [iter 19000 / 35967], [train loss 2.16441], [train acc 0.17337]\n",
      "[epoch 4], [iter 19100 / 35967], [train loss 2.16431], [train acc 0.17319]\n",
      "[epoch 4], [iter 19200 / 35967], [train loss 2.16475], [train acc 0.17313]\n",
      "[epoch 4], [iter 19300 / 35967], [train loss 2.16450], [train acc 0.17321]\n",
      "[epoch 4], [iter 19400 / 35967], [train loss 2.16458], [train acc 0.17335]\n",
      "[epoch 4], [iter 19500 / 35967], [train loss 2.16505], [train acc 0.17318]\n",
      "[epoch 4], [iter 19600 / 35967], [train loss 2.16510], [train acc 0.17276]\n",
      "[epoch 4], [iter 19700 / 35967], [train loss 2.16468], [train acc 0.17279]\n",
      "[epoch 4], [iter 19800 / 35967], [train loss 2.16507], [train acc 0.17258]\n",
      "[epoch 4], [iter 19900 / 35967], [train loss 2.16538], [train acc 0.17281]\n",
      "[epoch 4], [iter 20000 / 35967], [train loss 2.16520], [train acc 0.17280]\n",
      "[epoch 4], [iter 20100 / 35967], [train loss 2.16574], [train acc 0.17289]\n",
      "[epoch 4], [iter 20200 / 35967], [train loss 2.16638], [train acc 0.17287]\n",
      "[epoch 4], [iter 20300 / 35967], [train loss 2.16632], [train acc 0.17251]\n",
      "[epoch 4], [iter 20400 / 35967], [train loss 2.16620], [train acc 0.17255]\n",
      "[epoch 4], [iter 20500 / 35967], [train loss 2.16602], [train acc 0.17302]\n",
      "[epoch 4], [iter 20600 / 35967], [train loss 2.16608], [train acc 0.17291]\n",
      "[epoch 4], [iter 20700 / 35967], [train loss 2.16604], [train acc 0.17333]\n",
      "[epoch 4], [iter 20800 / 35967], [train loss 2.16585], [train acc 0.17337]\n",
      "[epoch 4], [iter 20900 / 35967], [train loss 2.16594], [train acc 0.17325]\n",
      "[epoch 4], [iter 21000 / 35967], [train loss 2.16563], [train acc 0.17348]\n",
      "[epoch 4], [iter 21100 / 35967], [train loss 2.16498], [train acc 0.17365]\n",
      "[epoch 4], [iter 21200 / 35967], [train loss 2.16505], [train acc 0.17387]\n",
      "[epoch 4], [iter 21300 / 35967], [train loss 2.16492], [train acc 0.17390]\n",
      "[epoch 4], [iter 21400 / 35967], [train loss 2.16542], [train acc 0.17369]\n",
      "[epoch 4], [iter 21500 / 35967], [train loss 2.16601], [train acc 0.17358]\n",
      "[epoch 4], [iter 21600 / 35967], [train loss 2.16545], [train acc 0.17394]\n",
      "[epoch 4], [iter 21700 / 35967], [train loss 2.16565], [train acc 0.17387]\n",
      "[epoch 4], [iter 21800 / 35967], [train loss 2.16553], [train acc 0.17385]\n",
      "[epoch 4], [iter 21900 / 35967], [train loss 2.16569], [train acc 0.17393]\n",
      "[epoch 4], [iter 22000 / 35967], [train loss 2.16566], [train acc 0.17391]\n",
      "[epoch 4], [iter 22100 / 35967], [train loss 2.16548], [train acc 0.17385]\n",
      "[epoch 4], [iter 22200 / 35967], [train loss 2.16547], [train acc 0.17392]\n",
      "[epoch 4], [iter 22300 / 35967], [train loss 2.16582], [train acc 0.17377]\n",
      "[epoch 4], [iter 22400 / 35967], [train loss 2.16597], [train acc 0.17411]\n",
      "[epoch 4], [iter 22500 / 35967], [train loss 2.16608], [train acc 0.17404]\n",
      "[epoch 4], [iter 22600 / 35967], [train loss 2.16628], [train acc 0.17389]\n",
      "[epoch 4], [iter 22700 / 35967], [train loss 2.16646], [train acc 0.17348]\n",
      "[epoch 4], [iter 22800 / 35967], [train loss 2.16739], [train acc 0.17311]\n",
      "[epoch 4], [iter 22900 / 35967], [train loss 2.16763], [train acc 0.17297]\n",
      "[epoch 4], [iter 23000 / 35967], [train loss 2.16750], [train acc 0.17278]\n",
      "[epoch 4], [iter 23100 / 35967], [train loss 2.16698], [train acc 0.17290]\n",
      "[epoch 4], [iter 23200 / 35967], [train loss 2.16678], [train acc 0.17310]\n",
      "[epoch 4], [iter 23300 / 35967], [train loss 2.16721], [train acc 0.17288]\n",
      "[epoch 4], [iter 23400 / 35967], [train loss 2.16729], [train acc 0.17278]\n",
      "[epoch 4], [iter 23500 / 35967], [train loss 2.16710], [train acc 0.17251]\n",
      "[epoch 4], [iter 23600 / 35967], [train loss 2.16714], [train acc 0.17237]\n",
      "[epoch 4], [iter 23700 / 35967], [train loss 2.16687], [train acc 0.17249]\n",
      "[epoch 4], [iter 23800 / 35967], [train loss 2.16710], [train acc 0.17239]\n",
      "[epoch 4], [iter 23900 / 35967], [train loss 2.16708], [train acc 0.17230]\n",
      "[epoch 4], [iter 24000 / 35967], [train loss 2.16743], [train acc 0.17233]\n",
      "[epoch 4], [iter 24100 / 35967], [train loss 2.16731], [train acc 0.17257]\n",
      "[epoch 4], [iter 24200 / 35967], [train loss 2.16745], [train acc 0.17240]\n",
      "[epoch 4], [iter 24300 / 35967], [train loss 2.16745], [train acc 0.17251]\n",
      "[epoch 4], [iter 24400 / 35967], [train loss 2.16749], [train acc 0.17238]\n",
      "[epoch 4], [iter 24500 / 35967], [train loss 2.16761], [train acc 0.17224]\n",
      "[epoch 4], [iter 24600 / 35967], [train loss 2.16789], [train acc 0.17224]\n",
      "[epoch 4], [iter 24700 / 35967], [train loss 2.16786], [train acc 0.17219]\n",
      "[epoch 4], [iter 24800 / 35967], [train loss 2.16772], [train acc 0.17230]\n",
      "[epoch 4], [iter 24900 / 35967], [train loss 2.16762], [train acc 0.17241]\n",
      "[epoch 4], [iter 25000 / 35967], [train loss 2.16762], [train acc 0.17220]\n",
      "[epoch 4], [iter 25100 / 35967], [train loss 2.16789], [train acc 0.17215]\n",
      "[epoch 4], [iter 25200 / 35967], [train loss 2.16759], [train acc 0.17250]\n",
      "[epoch 4], [iter 25300 / 35967], [train loss 2.16774], [train acc 0.17237]\n",
      "[epoch 4], [iter 25400 / 35967], [train loss 2.16792], [train acc 0.17248]\n",
      "[epoch 4], [iter 25500 / 35967], [train loss 2.16766], [train acc 0.17278]\n",
      "[epoch 4], [iter 25600 / 35967], [train loss 2.16814], [train acc 0.17270]\n",
      "[epoch 4], [iter 25700 / 35967], [train loss 2.16824], [train acc 0.17268]\n",
      "[epoch 4], [iter 25800 / 35967], [train loss 2.16814], [train acc 0.17256]\n",
      "[epoch 4], [iter 25900 / 35967], [train loss 2.16821], [train acc 0.17247]\n",
      "[epoch 4], [iter 26000 / 35967], [train loss 2.16803], [train acc 0.17246]\n",
      "[epoch 4], [iter 26100 / 35967], [train loss 2.16788], [train acc 0.17245]\n",
      "[epoch 4], [iter 26200 / 35967], [train loss 2.16790], [train acc 0.17256]\n",
      "[epoch 4], [iter 26300 / 35967], [train loss 2.16759], [train acc 0.17262]\n",
      "[epoch 4], [iter 26400 / 35967], [train loss 2.16763], [train acc 0.17250]\n",
      "[epoch 4], [iter 26500 / 35967], [train loss 2.16752], [train acc 0.17272]\n",
      "[epoch 4], [iter 26600 / 35967], [train loss 2.16744], [train acc 0.17289]\n",
      "[epoch 4], [iter 26700 / 35967], [train loss 2.16777], [train acc 0.17292]\n",
      "[epoch 4], [iter 26800 / 35967], [train loss 2.16805], [train acc 0.17265]\n",
      "[epoch 4], [iter 26900 / 35967], [train loss 2.16797], [train acc 0.17268]\n",
      "[epoch 4], [iter 27000 / 35967], [train loss 2.16801], [train acc 0.17259]\n",
      "[epoch 4], [iter 27100 / 35967], [train loss 2.16783], [train acc 0.17277]\n",
      "[epoch 4], [iter 27200 / 35967], [train loss 2.16810], [train acc 0.17276]\n",
      "[epoch 4], [iter 27300 / 35967], [train loss 2.16844], [train acc 0.17245]\n",
      "[epoch 4], [iter 27400 / 35967], [train loss 2.16872], [train acc 0.17241]\n",
      "[epoch 4], [iter 27500 / 35967], [train loss 2.16855], [train acc 0.17247]\n",
      "[epoch 4], [iter 27600 / 35967], [train loss 2.16846], [train acc 0.17228]\n",
      "[epoch 4], [iter 27700 / 35967], [train loss 2.16853], [train acc 0.17206]\n",
      "[epoch 4], [iter 27800 / 35967], [train loss 2.16863], [train acc 0.17212]\n",
      "[epoch 4], [iter 27900 / 35967], [train loss 2.16856], [train acc 0.17233]\n",
      "[epoch 4], [iter 28000 / 35967], [train loss 2.16857], [train acc 0.17232]\n",
      "[epoch 4], [iter 28100 / 35967], [train loss 2.16838], [train acc 0.17228]\n",
      "[epoch 4], [iter 28200 / 35967], [train loss 2.16819], [train acc 0.17223]\n",
      "[epoch 4], [iter 28300 / 35967], [train loss 2.16784], [train acc 0.17226]\n",
      "[epoch 4], [iter 28400 / 35967], [train loss 2.16823], [train acc 0.17208]\n",
      "[epoch 4], [iter 28500 / 35967], [train loss 2.16815], [train acc 0.17204]\n",
      "[epoch 4], [iter 28600 / 35967], [train loss 2.16778], [train acc 0.17238]\n",
      "[epoch 4], [iter 28700 / 35967], [train loss 2.16792], [train acc 0.17220]\n",
      "[epoch 4], [iter 28800 / 35967], [train loss 2.16754], [train acc 0.17243]\n",
      "[epoch 4], [iter 28900 / 35967], [train loss 2.16756], [train acc 0.17235]\n",
      "[epoch 4], [iter 29000 / 35967], [train loss 2.16774], [train acc 0.17238]\n",
      "[epoch 4], [iter 29100 / 35967], [train loss 2.16775], [train acc 0.17230]\n",
      "[epoch 4], [iter 29200 / 35967], [train loss 2.16794], [train acc 0.17229]\n",
      "[epoch 4], [iter 29300 / 35967], [train loss 2.16805], [train acc 0.17218]\n",
      "[epoch 4], [iter 29400 / 35967], [train loss 2.16790], [train acc 0.17231]\n",
      "[epoch 4], [iter 29500 / 35967], [train loss 2.16757], [train acc 0.17231]\n",
      "[epoch 4], [iter 29600 / 35967], [train loss 2.16714], [train acc 0.17250]\n",
      "[epoch 4], [iter 29700 / 35967], [train loss 2.16673], [train acc 0.17256]\n",
      "[epoch 4], [iter 29800 / 35967], [train loss 2.16674], [train acc 0.17262]\n",
      "[epoch 4], [iter 29900 / 35967], [train loss 2.16642], [train acc 0.17291]\n",
      "[epoch 4], [iter 30000 / 35967], [train loss 2.16623], [train acc 0.17297]\n",
      "[epoch 4], [iter 30100 / 35967], [train loss 2.16600], [train acc 0.17316]\n",
      "[epoch 4], [iter 30200 / 35967], [train loss 2.16591], [train acc 0.17328]\n",
      "[epoch 4], [iter 30300 / 35967], [train loss 2.16579], [train acc 0.17320]\n",
      "[epoch 4], [iter 30400 / 35967], [train loss 2.16578], [train acc 0.17313]\n",
      "[epoch 4], [iter 30500 / 35967], [train loss 2.16557], [train acc 0.17315]\n",
      "[epoch 4], [iter 30600 / 35967], [train loss 2.16571], [train acc 0.17320]\n",
      "[epoch 4], [iter 30700 / 35967], [train loss 2.16515], [train acc 0.17336]\n",
      "[epoch 4], [iter 30800 / 35967], [train loss 2.16515], [train acc 0.17347]\n",
      "[epoch 4], [iter 30900 / 35967], [train loss 2.16502], [train acc 0.17350]\n",
      "[epoch 4], [iter 31000 / 35967], [train loss 2.16470], [train acc 0.17358]\n",
      "[epoch 4], [iter 31100 / 35967], [train loss 2.16443], [train acc 0.17376]\n",
      "[epoch 4], [iter 31200 / 35967], [train loss 2.16477], [train acc 0.17365]\n",
      "[epoch 4], [iter 31300 / 35967], [train loss 2.16467], [train acc 0.17358]\n",
      "[epoch 4], [iter 31400 / 35967], [train loss 2.16437], [train acc 0.17366]\n",
      "[epoch 4], [iter 31500 / 35967], [train loss 2.16432], [train acc 0.17368]\n",
      "[epoch 4], [iter 31600 / 35967], [train loss 2.16436], [train acc 0.17354]\n",
      "[epoch 4], [iter 31700 / 35967], [train loss 2.16432], [train acc 0.17360]\n",
      "[epoch 4], [iter 31800 / 35967], [train loss 2.16415], [train acc 0.17365]\n",
      "[epoch 4], [iter 31900 / 35967], [train loss 2.16409], [train acc 0.17376]\n",
      "[epoch 4], [iter 32000 / 35967], [train loss 2.16439], [train acc 0.17378]\n",
      "[epoch 4], [iter 32100 / 35967], [train loss 2.16460], [train acc 0.17389]\n",
      "[epoch 4], [iter 32200 / 35967], [train loss 2.16452], [train acc 0.17388]\n",
      "[epoch 4], [iter 32300 / 35967], [train loss 2.16477], [train acc 0.17387]\n",
      "[epoch 4], [iter 32400 / 35967], [train loss 2.16468], [train acc 0.17410]\n",
      "[epoch 4], [iter 32500 / 35967], [train loss 2.16479], [train acc 0.17406]\n",
      "[epoch 4], [iter 32600 / 35967], [train loss 2.16461], [train acc 0.17414]\n",
      "[epoch 4], [iter 32700 / 35967], [train loss 2.16443], [train acc 0.17413]\n",
      "[epoch 4], [iter 32800 / 35967], [train loss 2.16452], [train acc 0.17421]\n",
      "[epoch 4], [iter 32900 / 35967], [train loss 2.16434], [train acc 0.17441]\n",
      "[epoch 4], [iter 33000 / 35967], [train loss 2.16422], [train acc 0.17452]\n",
      "[epoch 4], [iter 33100 / 35967], [train loss 2.16410], [train acc 0.17453]\n",
      "[epoch 4], [iter 33200 / 35967], [train loss 2.16418], [train acc 0.17455]\n",
      "[epoch 4], [iter 33300 / 35967], [train loss 2.16483], [train acc 0.17459]\n",
      "[epoch 4], [iter 33400 / 35967], [train loss 2.16481], [train acc 0.17452]\n",
      "[epoch 4], [iter 33500 / 35967], [train loss 2.16470], [train acc 0.17442]\n",
      "[epoch 4], [iter 33600 / 35967], [train loss 2.16474], [train acc 0.17443]\n",
      "[epoch 4], [iter 33700 / 35967], [train loss 2.16489], [train acc 0.17448]\n",
      "[epoch 4], [iter 33800 / 35967], [train loss 2.16488], [train acc 0.17456]\n",
      "[epoch 4], [iter 33900 / 35967], [train loss 2.16448], [train acc 0.17466]\n",
      "[epoch 4], [iter 34000 / 35967], [train loss 2.16454], [train acc 0.17474]\n",
      "[epoch 4], [iter 34100 / 35967], [train loss 2.16479], [train acc 0.17493]\n",
      "[epoch 4], [iter 34200 / 35967], [train loss 2.16491], [train acc 0.17512]\n",
      "[epoch 4], [iter 34300 / 35967], [train loss 2.16504], [train acc 0.17496]\n",
      "[epoch 4], [iter 34400 / 35967], [train loss 2.16471], [train acc 0.17500]\n",
      "[epoch 4], [iter 34500 / 35967], [train loss 2.16447], [train acc 0.17510]\n",
      "[epoch 4], [iter 34600 / 35967], [train loss 2.16444], [train acc 0.17491]\n",
      "[epoch 4], [iter 34700 / 35967], [train loss 2.16401], [train acc 0.17493]\n",
      "[epoch 4], [iter 34800 / 35967], [train loss 2.16410], [train acc 0.17489]\n",
      "[epoch 4], [iter 34900 / 35967], [train loss 2.16414], [train acc 0.17496]\n",
      "[epoch 4], [iter 35000 / 35967], [train loss 2.16405], [train acc 0.17509]\n",
      "[epoch 4], [iter 35100 / 35967], [train loss 2.16376], [train acc 0.17510]\n",
      "[epoch 4], [iter 35200 / 35967], [train loss 2.16389], [train acc 0.17503]\n",
      "[epoch 4], [iter 35300 / 35967], [train loss 2.16374], [train acc 0.17513]\n",
      "[epoch 4], [iter 35400 / 35967], [train loss 2.16392], [train acc 0.17500]\n",
      "[epoch 4], [iter 35500 / 35967], [train loss 2.16393], [train acc 0.17504]\n",
      "[epoch 4], [iter 35600 / 35967], [train loss 2.16390], [train acc 0.17489]\n",
      "[epoch 4], [iter 35700 / 35967], [train loss 2.16384], [train acc 0.17496]\n",
      "[epoch 4], [iter 35800 / 35967], [train loss 2.16404], [train acc 0.17483]\n",
      "[epoch 4], [iter 35900 / 35967], [train loss 2.16366], [train acc 0.17504]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 5.26351], [val acc 0.15050]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 35967], [train loss 2.11060], [train acc 0.18000]\n",
      "[epoch 5], [iter 200 / 35967], [train loss 2.14551], [train acc 0.18000]\n",
      "[epoch 5], [iter 300 / 35967], [train loss 2.15113], [train acc 0.16333]\n",
      "[epoch 5], [iter 400 / 35967], [train loss 2.14104], [train acc 0.17500]\n",
      "[epoch 5], [iter 500 / 35967], [train loss 2.13478], [train acc 0.17400]\n",
      "[epoch 5], [iter 600 / 35967], [train loss 2.15345], [train acc 0.17500]\n",
      "[epoch 5], [iter 700 / 35967], [train loss 2.13119], [train acc 0.17857]\n",
      "[epoch 5], [iter 800 / 35967], [train loss 2.14271], [train acc 0.18125]\n",
      "[epoch 5], [iter 900 / 35967], [train loss 2.13461], [train acc 0.17667]\n",
      "[epoch 5], [iter 1000 / 35967], [train loss 2.15149], [train acc 0.17300]\n",
      "[epoch 5], [iter 1100 / 35967], [train loss 2.15293], [train acc 0.16636]\n",
      "[epoch 5], [iter 1200 / 35967], [train loss 2.13905], [train acc 0.16917]\n",
      "[epoch 5], [iter 1300 / 35967], [train loss 2.15130], [train acc 0.16692]\n",
      "[epoch 5], [iter 1400 / 35967], [train loss 2.15062], [train acc 0.16643]\n",
      "[epoch 5], [iter 1500 / 35967], [train loss 2.14884], [train acc 0.17067]\n",
      "[epoch 5], [iter 1600 / 35967], [train loss 2.14973], [train acc 0.17000]\n",
      "[epoch 5], [iter 1700 / 35967], [train loss 2.15629], [train acc 0.16647]\n",
      "[epoch 5], [iter 1800 / 35967], [train loss 2.15515], [train acc 0.16944]\n",
      "[epoch 5], [iter 1900 / 35967], [train loss 2.15302], [train acc 0.17158]\n",
      "[epoch 5], [iter 2000 / 35967], [train loss 2.15440], [train acc 0.17150]\n",
      "[epoch 5], [iter 2100 / 35967], [train loss 2.15014], [train acc 0.17524]\n",
      "[epoch 5], [iter 2200 / 35967], [train loss 2.14708], [train acc 0.17545]\n",
      "[epoch 5], [iter 2300 / 35967], [train loss 2.14478], [train acc 0.17696]\n",
      "[epoch 5], [iter 2400 / 35967], [train loss 2.14542], [train acc 0.17625]\n",
      "[epoch 5], [iter 2500 / 35967], [train loss 2.14746], [train acc 0.17640]\n",
      "[epoch 5], [iter 2600 / 35967], [train loss 2.14846], [train acc 0.17462]\n",
      "[epoch 5], [iter 2700 / 35967], [train loss 2.14980], [train acc 0.17296]\n",
      "[epoch 5], [iter 2800 / 35967], [train loss 2.14781], [train acc 0.17179]\n",
      "[epoch 5], [iter 2900 / 35967], [train loss 2.14546], [train acc 0.17448]\n",
      "[epoch 5], [iter 3000 / 35967], [train loss 2.14921], [train acc 0.17333]\n",
      "[epoch 5], [iter 3100 / 35967], [train loss 2.14882], [train acc 0.17419]\n",
      "[epoch 5], [iter 3200 / 35967], [train loss 2.14971], [train acc 0.17406]\n",
      "[epoch 5], [iter 3300 / 35967], [train loss 2.14726], [train acc 0.17394]\n",
      "[epoch 5], [iter 3400 / 35967], [train loss 2.14771], [train acc 0.17441]\n",
      "[epoch 5], [iter 3500 / 35967], [train loss 2.14590], [train acc 0.17657]\n",
      "[epoch 5], [iter 3600 / 35967], [train loss 2.14467], [train acc 0.17694]\n",
      "[epoch 5], [iter 3700 / 35967], [train loss 2.14257], [train acc 0.17892]\n",
      "[epoch 5], [iter 3800 / 35967], [train loss 2.14052], [train acc 0.17974]\n",
      "[epoch 5], [iter 3900 / 35967], [train loss 2.13951], [train acc 0.18000]\n",
      "[epoch 5], [iter 4000 / 35967], [train loss 2.13809], [train acc 0.18050]\n",
      "[epoch 5], [iter 4100 / 35967], [train loss 2.14086], [train acc 0.17878]\n",
      "[epoch 5], [iter 4200 / 35967], [train loss 2.13815], [train acc 0.18048]\n",
      "[epoch 5], [iter 4300 / 35967], [train loss 2.13775], [train acc 0.17977]\n",
      "[epoch 5], [iter 4400 / 35967], [train loss 2.13884], [train acc 0.18000]\n",
      "[epoch 5], [iter 4500 / 35967], [train loss 2.13730], [train acc 0.18133]\n",
      "[epoch 5], [iter 4600 / 35967], [train loss 2.13852], [train acc 0.18174]\n",
      "[epoch 5], [iter 4700 / 35967], [train loss 2.13826], [train acc 0.18106]\n",
      "[epoch 5], [iter 4800 / 35967], [train loss 2.13757], [train acc 0.18188]\n",
      "[epoch 5], [iter 4900 / 35967], [train loss 2.13668], [train acc 0.18265]\n",
      "[epoch 5], [iter 5000 / 35967], [train loss 2.13701], [train acc 0.18240]\n",
      "[epoch 5], [iter 5100 / 35967], [train loss 2.13671], [train acc 0.18196]\n",
      "[epoch 5], [iter 5200 / 35967], [train loss 2.13901], [train acc 0.18231]\n",
      "[epoch 5], [iter 5300 / 35967], [train loss 2.13883], [train acc 0.18264]\n",
      "[epoch 5], [iter 5400 / 35967], [train loss 2.13667], [train acc 0.18241]\n",
      "[epoch 5], [iter 5500 / 35967], [train loss 2.13712], [train acc 0.18255]\n",
      "[epoch 5], [iter 5600 / 35967], [train loss 2.13767], [train acc 0.18268]\n",
      "[epoch 5], [iter 5700 / 35967], [train loss 2.13605], [train acc 0.18211]\n",
      "[epoch 5], [iter 5800 / 35967], [train loss 2.13576], [train acc 0.18103]\n",
      "[epoch 5], [iter 5900 / 35967], [train loss 2.13641], [train acc 0.18017]\n",
      "[epoch 5], [iter 6000 / 35967], [train loss 2.13701], [train acc 0.18000]\n",
      "[epoch 5], [iter 6100 / 35967], [train loss 2.13792], [train acc 0.18016]\n",
      "[epoch 5], [iter 6200 / 35967], [train loss 2.13714], [train acc 0.18081]\n",
      "[epoch 5], [iter 6300 / 35967], [train loss 2.13903], [train acc 0.18175]\n",
      "[epoch 5], [iter 6400 / 35967], [train loss 2.14045], [train acc 0.18203]\n",
      "[epoch 5], [iter 6500 / 35967], [train loss 2.14257], [train acc 0.18123]\n",
      "[epoch 5], [iter 6600 / 35967], [train loss 2.14366], [train acc 0.18091]\n",
      "[epoch 5], [iter 6700 / 35967], [train loss 2.14484], [train acc 0.18090]\n",
      "[epoch 5], [iter 6800 / 35967], [train loss 2.14625], [train acc 0.18000]\n",
      "[epoch 5], [iter 6900 / 35967], [train loss 2.14631], [train acc 0.18029]\n",
      "[epoch 5], [iter 7000 / 35967], [train loss 2.14615], [train acc 0.17986]\n",
      "[epoch 5], [iter 7100 / 35967], [train loss 2.14452], [train acc 0.17986]\n",
      "[epoch 5], [iter 7200 / 35967], [train loss 2.14339], [train acc 0.18056]\n",
      "[epoch 5], [iter 7300 / 35967], [train loss 2.14346], [train acc 0.18082]\n",
      "[epoch 5], [iter 7400 / 35967], [train loss 2.14233], [train acc 0.18095]\n",
      "[epoch 5], [iter 7500 / 35967], [train loss 2.14181], [train acc 0.18107]\n",
      "[epoch 5], [iter 7600 / 35967], [train loss 2.13959], [train acc 0.18158]\n",
      "[epoch 5], [iter 7700 / 35967], [train loss 2.14086], [train acc 0.18117]\n",
      "[epoch 5], [iter 7800 / 35967], [train loss 2.13949], [train acc 0.18179]\n",
      "[epoch 5], [iter 7900 / 35967], [train loss 2.13953], [train acc 0.18190]\n",
      "[epoch 5], [iter 8000 / 35967], [train loss 2.13885], [train acc 0.18200]\n",
      "[epoch 5], [iter 8100 / 35967], [train loss 2.13946], [train acc 0.18173]\n",
      "[epoch 5], [iter 8200 / 35967], [train loss 2.13926], [train acc 0.18134]\n",
      "[epoch 5], [iter 8300 / 35967], [train loss 2.13911], [train acc 0.18133]\n",
      "[epoch 5], [iter 8400 / 35967], [train loss 2.13915], [train acc 0.18202]\n",
      "[epoch 5], [iter 8500 / 35967], [train loss 2.14052], [train acc 0.18188]\n",
      "[epoch 5], [iter 8600 / 35967], [train loss 2.14054], [train acc 0.18174]\n",
      "[epoch 5], [iter 8700 / 35967], [train loss 2.14090], [train acc 0.18184]\n",
      "[epoch 5], [iter 8800 / 35967], [train loss 2.14065], [train acc 0.18193]\n",
      "[epoch 5], [iter 8900 / 35967], [train loss 2.14145], [train acc 0.18202]\n",
      "[epoch 5], [iter 9000 / 35967], [train loss 2.14155], [train acc 0.18233]\n",
      "[epoch 5], [iter 9100 / 35967], [train loss 2.14148], [train acc 0.18264]\n",
      "[epoch 5], [iter 9200 / 35967], [train loss 2.14049], [train acc 0.18217]\n",
      "[epoch 5], [iter 9300 / 35967], [train loss 2.14060], [train acc 0.18237]\n",
      "[epoch 5], [iter 9400 / 35967], [train loss 2.14141], [train acc 0.18223]\n",
      "[epoch 5], [iter 9500 / 35967], [train loss 2.14137], [train acc 0.18200]\n",
      "[epoch 5], [iter 9600 / 35967], [train loss 2.14165], [train acc 0.18250]\n",
      "[epoch 5], [iter 9700 / 35967], [train loss 2.14184], [train acc 0.18247]\n",
      "[epoch 5], [iter 9800 / 35967], [train loss 2.14221], [train acc 0.18214]\n",
      "[epoch 5], [iter 9900 / 35967], [train loss 2.14213], [train acc 0.18182]\n",
      "[epoch 5], [iter 10000 / 35967], [train loss 2.14229], [train acc 0.18140]\n",
      "[epoch 5], [iter 10100 / 35967], [train loss 2.14215], [train acc 0.18129]\n",
      "[epoch 5], [iter 10200 / 35967], [train loss 2.14187], [train acc 0.18127]\n",
      "[epoch 5], [iter 10300 / 35967], [train loss 2.14220], [train acc 0.18107]\n",
      "[epoch 5], [iter 10400 / 35967], [train loss 2.14280], [train acc 0.18067]\n",
      "[epoch 5], [iter 10500 / 35967], [train loss 2.14273], [train acc 0.18057]\n",
      "[epoch 5], [iter 10600 / 35967], [train loss 2.14180], [train acc 0.18085]\n",
      "[epoch 5], [iter 10700 / 35967], [train loss 2.14120], [train acc 0.18131]\n",
      "[epoch 5], [iter 10800 / 35967], [train loss 2.14170], [train acc 0.18139]\n",
      "[epoch 5], [iter 10900 / 35967], [train loss 2.14184], [train acc 0.18156]\n",
      "[epoch 5], [iter 11000 / 35967], [train loss 2.14216], [train acc 0.18182]\n",
      "[epoch 5], [iter 11100 / 35967], [train loss 2.14133], [train acc 0.18189]\n",
      "[epoch 5], [iter 11200 / 35967], [train loss 2.14197], [train acc 0.18134]\n",
      "[epoch 5], [iter 11300 / 35967], [train loss 2.14162], [train acc 0.18133]\n",
      "[epoch 5], [iter 11400 / 35967], [train loss 2.14161], [train acc 0.18140]\n",
      "[epoch 5], [iter 11500 / 35967], [train loss 2.14192], [train acc 0.18139]\n",
      "[epoch 5], [iter 11600 / 35967], [train loss 2.14201], [train acc 0.18147]\n",
      "[epoch 5], [iter 11700 / 35967], [train loss 2.14264], [train acc 0.18120]\n",
      "[epoch 5], [iter 11800 / 35967], [train loss 2.14152], [train acc 0.18169]\n",
      "[epoch 5], [iter 11900 / 35967], [train loss 2.14136], [train acc 0.18176]\n",
      "[epoch 5], [iter 12000 / 35967], [train loss 2.14171], [train acc 0.18175]\n",
      "[epoch 5], [iter 12100 / 35967], [train loss 2.14180], [train acc 0.18157]\n",
      "[epoch 5], [iter 12200 / 35967], [train loss 2.14156], [train acc 0.18164]\n",
      "[epoch 5], [iter 12300 / 35967], [train loss 2.14241], [train acc 0.18154]\n",
      "[epoch 5], [iter 12400 / 35967], [train loss 2.14221], [train acc 0.18169]\n",
      "[epoch 5], [iter 12500 / 35967], [train loss 2.14185], [train acc 0.18160]\n",
      "[epoch 5], [iter 12600 / 35967], [train loss 2.14211], [train acc 0.18135]\n",
      "[epoch 5], [iter 12700 / 35967], [train loss 2.14198], [train acc 0.18134]\n",
      "[epoch 5], [iter 12800 / 35967], [train loss 2.14155], [train acc 0.18109]\n",
      "[epoch 5], [iter 12900 / 35967], [train loss 2.14126], [train acc 0.18093]\n",
      "[epoch 5], [iter 13000 / 35967], [train loss 2.14088], [train acc 0.18085]\n",
      "[epoch 5], [iter 13100 / 35967], [train loss 2.14145], [train acc 0.18053]\n",
      "[epoch 5], [iter 13200 / 35967], [train loss 2.14261], [train acc 0.18030]\n",
      "[epoch 5], [iter 13300 / 35967], [train loss 2.14286], [train acc 0.18015]\n",
      "[epoch 5], [iter 13400 / 35967], [train loss 2.14322], [train acc 0.18052]\n",
      "[epoch 5], [iter 13500 / 35967], [train loss 2.14309], [train acc 0.18074]\n",
      "[epoch 5], [iter 13600 / 35967], [train loss 2.14271], [train acc 0.18140]\n",
      "[epoch 5], [iter 13700 / 35967], [train loss 2.14214], [train acc 0.18153]\n",
      "[epoch 5], [iter 13800 / 35967], [train loss 2.14214], [train acc 0.18159]\n",
      "[epoch 5], [iter 13900 / 35967], [train loss 2.14209], [train acc 0.18165]\n",
      "[epoch 5], [iter 14000 / 35967], [train loss 2.14196], [train acc 0.18179]\n",
      "[epoch 5], [iter 14100 / 35967], [train loss 2.14289], [train acc 0.18142]\n",
      "[epoch 5], [iter 14200 / 35967], [train loss 2.14343], [train acc 0.18134]\n",
      "[epoch 5], [iter 14300 / 35967], [train loss 2.14383], [train acc 0.18126]\n",
      "[epoch 5], [iter 14400 / 35967], [train loss 2.14385], [train acc 0.18125]\n",
      "[epoch 5], [iter 14500 / 35967], [train loss 2.14399], [train acc 0.18103]\n",
      "[epoch 5], [iter 14600 / 35967], [train loss 2.14326], [train acc 0.18123]\n",
      "[epoch 5], [iter 14700 / 35967], [train loss 2.14280], [train acc 0.18122]\n",
      "[epoch 5], [iter 14800 / 35967], [train loss 2.14392], [train acc 0.18142]\n",
      "[epoch 5], [iter 14900 / 35967], [train loss 2.14426], [train acc 0.18148]\n",
      "[epoch 5], [iter 15000 / 35967], [train loss 2.14369], [train acc 0.18140]\n",
      "[epoch 5], [iter 15100 / 35967], [train loss 2.14351], [train acc 0.18119]\n",
      "[epoch 5], [iter 15200 / 35967], [train loss 2.14341], [train acc 0.18138]\n",
      "[epoch 5], [iter 15300 / 35967], [train loss 2.14334], [train acc 0.18163]\n",
      "[epoch 5], [iter 15400 / 35967], [train loss 2.14350], [train acc 0.18182]\n",
      "[epoch 5], [iter 15500 / 35967], [train loss 2.14377], [train acc 0.18181]\n",
      "[epoch 5], [iter 15600 / 35967], [train loss 2.14450], [train acc 0.18147]\n",
      "[epoch 5], [iter 15700 / 35967], [train loss 2.14458], [train acc 0.18140]\n",
      "[epoch 5], [iter 15800 / 35967], [train loss 2.14522], [train acc 0.18127]\n",
      "[epoch 5], [iter 15900 / 35967], [train loss 2.14543], [train acc 0.18113]\n",
      "[epoch 5], [iter 16000 / 35967], [train loss 2.14450], [train acc 0.18150]\n",
      "[epoch 5], [iter 16100 / 35967], [train loss 2.14434], [train acc 0.18118]\n",
      "[epoch 5], [iter 16200 / 35967], [train loss 2.14434], [train acc 0.18123]\n",
      "[epoch 5], [iter 16300 / 35967], [train loss 2.14438], [train acc 0.18117]\n",
      "[epoch 5], [iter 16400 / 35967], [train loss 2.14412], [train acc 0.18091]\n",
      "[epoch 5], [iter 16500 / 35967], [train loss 2.14399], [train acc 0.18139]\n",
      "[epoch 5], [iter 16600 / 35967], [train loss 2.14356], [train acc 0.18175]\n",
      "[epoch 5], [iter 16700 / 35967], [train loss 2.14371], [train acc 0.18180]\n",
      "[epoch 5], [iter 16800 / 35967], [train loss 2.14422], [train acc 0.18149]\n",
      "[epoch 5], [iter 16900 / 35967], [train loss 2.14407], [train acc 0.18160]\n",
      "[epoch 5], [iter 17000 / 35967], [train loss 2.14435], [train acc 0.18159]\n",
      "[epoch 5], [iter 17100 / 35967], [train loss 2.14386], [train acc 0.18175]\n",
      "[epoch 5], [iter 17200 / 35967], [train loss 2.14306], [train acc 0.18209]\n",
      "[epoch 5], [iter 17300 / 35967], [train loss 2.14312], [train acc 0.18191]\n",
      "[epoch 5], [iter 17400 / 35967], [train loss 2.14316], [train acc 0.18195]\n",
      "[epoch 5], [iter 17500 / 35967], [train loss 2.14300], [train acc 0.18194]\n",
      "[epoch 5], [iter 17600 / 35967], [train loss 2.14253], [train acc 0.18205]\n",
      "[epoch 5], [iter 17700 / 35967], [train loss 2.14244], [train acc 0.18181]\n",
      "[epoch 5], [iter 17800 / 35967], [train loss 2.14219], [train acc 0.18163]\n",
      "[epoch 5], [iter 17900 / 35967], [train loss 2.14178], [train acc 0.18173]\n",
      "[epoch 5], [iter 18000 / 35967], [train loss 2.14176], [train acc 0.18178]\n",
      "[epoch 5], [iter 18100 / 35967], [train loss 2.14195], [train acc 0.18188]\n",
      "[epoch 5], [iter 18200 / 35967], [train loss 2.14170], [train acc 0.18203]\n",
      "[epoch 5], [iter 18300 / 35967], [train loss 2.14195], [train acc 0.18208]\n",
      "[epoch 5], [iter 18400 / 35967], [train loss 2.14273], [train acc 0.18196]\n",
      "[epoch 5], [iter 18500 / 35967], [train loss 2.14261], [train acc 0.18200]\n",
      "[epoch 5], [iter 18600 / 35967], [train loss 2.14197], [train acc 0.18242]\n",
      "[epoch 5], [iter 18700 / 35967], [train loss 2.14209], [train acc 0.18246]\n",
      "[epoch 5], [iter 18800 / 35967], [train loss 2.14189], [train acc 0.18261]\n",
      "[epoch 5], [iter 18900 / 35967], [train loss 2.14150], [train acc 0.18286]\n",
      "[epoch 5], [iter 19000 / 35967], [train loss 2.14199], [train acc 0.18258]\n",
      "[epoch 5], [iter 19100 / 35967], [train loss 2.14198], [train acc 0.18257]\n",
      "[epoch 5], [iter 19200 / 35967], [train loss 2.14215], [train acc 0.18276]\n",
      "[epoch 5], [iter 19300 / 35967], [train loss 2.14216], [train acc 0.18259]\n",
      "[epoch 5], [iter 19400 / 35967], [train loss 2.14207], [train acc 0.18247]\n",
      "[epoch 5], [iter 19500 / 35967], [train loss 2.14190], [train acc 0.18256]\n",
      "[epoch 5], [iter 19600 / 35967], [train loss 2.14212], [train acc 0.18270]\n",
      "[epoch 5], [iter 19700 / 35967], [train loss 2.14192], [train acc 0.18284]\n",
      "[epoch 5], [iter 19800 / 35967], [train loss 2.14222], [train acc 0.18268]\n",
      "[epoch 5], [iter 19900 / 35967], [train loss 2.14211], [train acc 0.18276]\n",
      "[epoch 5], [iter 20000 / 35967], [train loss 2.14180], [train acc 0.18280]\n",
      "[epoch 5], [iter 20100 / 35967], [train loss 2.14191], [train acc 0.18289]\n",
      "[epoch 5], [iter 20200 / 35967], [train loss 2.14192], [train acc 0.18282]\n",
      "[epoch 5], [iter 20300 / 35967], [train loss 2.14190], [train acc 0.18300]\n",
      "[epoch 5], [iter 20400 / 35967], [train loss 2.14231], [train acc 0.18328]\n",
      "[epoch 5], [iter 20500 / 35967], [train loss 2.14277], [train acc 0.18322]\n",
      "[epoch 5], [iter 20600 / 35967], [train loss 2.14292], [train acc 0.18316]\n",
      "[epoch 5], [iter 20700 / 35967], [train loss 2.14341], [train acc 0.18280]\n",
      "[epoch 5], [iter 20800 / 35967], [train loss 2.14366], [train acc 0.18279]\n",
      "[epoch 5], [iter 20900 / 35967], [train loss 2.14355], [train acc 0.18249]\n",
      "[epoch 5], [iter 21000 / 35967], [train loss 2.14344], [train acc 0.18257]\n",
      "[epoch 5], [iter 21100 / 35967], [train loss 2.14398], [train acc 0.18246]\n",
      "[epoch 5], [iter 21200 / 35967], [train loss 2.14393], [train acc 0.18241]\n",
      "[epoch 5], [iter 21300 / 35967], [train loss 2.14320], [train acc 0.18263]\n",
      "[epoch 5], [iter 21400 / 35967], [train loss 2.14296], [train acc 0.18262]\n",
      "[epoch 5], [iter 21500 / 35967], [train loss 2.14336], [train acc 0.18247]\n",
      "[epoch 5], [iter 21600 / 35967], [train loss 2.14354], [train acc 0.18245]\n",
      "[epoch 5], [iter 21700 / 35967], [train loss 2.14349], [train acc 0.18267]\n",
      "[epoch 5], [iter 21800 / 35967], [train loss 2.14364], [train acc 0.18261]\n",
      "[epoch 5], [iter 21900 / 35967], [train loss 2.14353], [train acc 0.18242]\n",
      "[epoch 5], [iter 22000 / 35967], [train loss 2.14343], [train acc 0.18236]\n",
      "[epoch 5], [iter 22100 / 35967], [train loss 2.14394], [train acc 0.18217]\n",
      "[epoch 5], [iter 22200 / 35967], [train loss 2.14395], [train acc 0.18212]\n",
      "[epoch 5], [iter 22300 / 35967], [train loss 2.14409], [train acc 0.18211]\n",
      "[epoch 5], [iter 22400 / 35967], [train loss 2.14354], [train acc 0.18254]\n",
      "[epoch 5], [iter 22500 / 35967], [train loss 2.14333], [train acc 0.18262]\n",
      "[epoch 5], [iter 22600 / 35967], [train loss 2.14339], [train acc 0.18257]\n",
      "[epoch 5], [iter 22700 / 35967], [train loss 2.14274], [train acc 0.18295]\n",
      "[epoch 5], [iter 22800 / 35967], [train loss 2.14296], [train acc 0.18303]\n",
      "[epoch 5], [iter 22900 / 35967], [train loss 2.14296], [train acc 0.18293]\n",
      "[epoch 5], [iter 23000 / 35967], [train loss 2.14225], [train acc 0.18339]\n",
      "[epoch 5], [iter 23100 / 35967], [train loss 2.14244], [train acc 0.18333]\n",
      "[epoch 5], [iter 23200 / 35967], [train loss 2.14258], [train acc 0.18315]\n",
      "[epoch 5], [iter 23300 / 35967], [train loss 2.14195], [train acc 0.18348]\n",
      "[epoch 5], [iter 23400 / 35967], [train loss 2.14288], [train acc 0.18321]\n",
      "[epoch 5], [iter 23500 / 35967], [train loss 2.14306], [train acc 0.18315]\n",
      "[epoch 5], [iter 23600 / 35967], [train loss 2.14295], [train acc 0.18326]\n",
      "[epoch 5], [iter 23700 / 35967], [train loss 2.14308], [train acc 0.18304]\n",
      "[epoch 5], [iter 23800 / 35967], [train loss 2.14268], [train acc 0.18319]\n",
      "[epoch 5], [iter 23900 / 35967], [train loss 2.14271], [train acc 0.18322]\n",
      "[epoch 5], [iter 24000 / 35967], [train loss 2.14324], [train acc 0.18317]\n",
      "[epoch 5], [iter 24100 / 35967], [train loss 2.14338], [train acc 0.18307]\n",
      "[epoch 5], [iter 24200 / 35967], [train loss 2.14397], [train acc 0.18322]\n",
      "[epoch 5], [iter 24300 / 35967], [train loss 2.14430], [train acc 0.18317]\n",
      "[epoch 5], [iter 24400 / 35967], [train loss 2.14391], [train acc 0.18328]\n",
      "[epoch 5], [iter 24500 / 35967], [train loss 2.14384], [train acc 0.18318]\n",
      "[epoch 5], [iter 24600 / 35967], [train loss 2.14385], [train acc 0.18301]\n",
      "[epoch 5], [iter 24700 / 35967], [train loss 2.14406], [train acc 0.18287]\n",
      "[epoch 5], [iter 24800 / 35967], [train loss 2.14404], [train acc 0.18302]\n",
      "[epoch 5], [iter 24900 / 35967], [train loss 2.14391], [train acc 0.18297]\n",
      "[epoch 5], [iter 25000 / 35967], [train loss 2.14373], [train acc 0.18300]\n",
      "[epoch 5], [iter 25100 / 35967], [train loss 2.14366], [train acc 0.18311]\n",
      "[epoch 5], [iter 25200 / 35967], [train loss 2.14368], [train acc 0.18282]\n",
      "[epoch 5], [iter 25300 / 35967], [train loss 2.14397], [train acc 0.18273]\n",
      "[epoch 5], [iter 25400 / 35967], [train loss 2.14369], [train acc 0.18272]\n",
      "[epoch 5], [iter 25500 / 35967], [train loss 2.14386], [train acc 0.18275]\n",
      "[epoch 5], [iter 25600 / 35967], [train loss 2.14418], [train acc 0.18273]\n",
      "[epoch 5], [iter 25700 / 35967], [train loss 2.14396], [train acc 0.18284]\n",
      "[epoch 5], [iter 25800 / 35967], [train loss 2.14386], [train acc 0.18287]\n",
      "[epoch 5], [iter 25900 / 35967], [train loss 2.14378], [train acc 0.18290]\n",
      "[epoch 5], [iter 26000 / 35967], [train loss 2.14364], [train acc 0.18281]\n",
      "[epoch 5], [iter 26100 / 35967], [train loss 2.14308], [train acc 0.18295]\n",
      "[epoch 5], [iter 26200 / 35967], [train loss 2.14299], [train acc 0.18294]\n",
      "[epoch 5], [iter 26300 / 35967], [train loss 2.14323], [train acc 0.18281]\n",
      "[epoch 5], [iter 26400 / 35967], [train loss 2.14342], [train acc 0.18303]\n",
      "[epoch 5], [iter 26500 / 35967], [train loss 2.14349], [train acc 0.18294]\n",
      "[epoch 5], [iter 26600 / 35967], [train loss 2.14376], [train acc 0.18282]\n",
      "[epoch 5], [iter 26700 / 35967], [train loss 2.14371], [train acc 0.18273]\n",
      "[epoch 5], [iter 26800 / 35967], [train loss 2.14379], [train acc 0.18254]\n",
      "[epoch 5], [iter 26900 / 35967], [train loss 2.14361], [train acc 0.18249]\n",
      "[epoch 5], [iter 27000 / 35967], [train loss 2.14369], [train acc 0.18230]\n",
      "[epoch 5], [iter 27100 / 35967], [train loss 2.14385], [train acc 0.18225]\n",
      "[epoch 5], [iter 27200 / 35967], [train loss 2.14410], [train acc 0.18228]\n",
      "[epoch 5], [iter 27300 / 35967], [train loss 2.14387], [train acc 0.18231]\n",
      "[epoch 5], [iter 27400 / 35967], [train loss 2.14414], [train acc 0.18204]\n",
      "[epoch 5], [iter 27500 / 35967], [train loss 2.14451], [train acc 0.18196]\n",
      "[epoch 5], [iter 27600 / 35967], [train loss 2.14438], [train acc 0.18203]\n",
      "[epoch 5], [iter 27700 / 35967], [train loss 2.14414], [train acc 0.18224]\n",
      "[epoch 5], [iter 27800 / 35967], [train loss 2.14476], [train acc 0.18209]\n",
      "[epoch 5], [iter 27900 / 35967], [train loss 2.14463], [train acc 0.18208]\n",
      "[epoch 5], [iter 28000 / 35967], [train loss 2.14463], [train acc 0.18196]\n",
      "[epoch 5], [iter 28100 / 35967], [train loss 2.14496], [train acc 0.18181]\n",
      "[epoch 5], [iter 28200 / 35967], [train loss 2.14479], [train acc 0.18191]\n",
      "[epoch 5], [iter 28300 / 35967], [train loss 2.14468], [train acc 0.18191]\n",
      "[epoch 5], [iter 28400 / 35967], [train loss 2.14428], [train acc 0.18208]\n",
      "[epoch 5], [iter 28500 / 35967], [train loss 2.14428], [train acc 0.18204]\n",
      "[epoch 5], [iter 28600 / 35967], [train loss 2.14422], [train acc 0.18224]\n",
      "[epoch 5], [iter 28700 / 35967], [train loss 2.14446], [train acc 0.18206]\n",
      "[epoch 5], [iter 28800 / 35967], [train loss 2.14480], [train acc 0.18194]\n",
      "[epoch 5], [iter 28900 / 35967], [train loss 2.14455], [train acc 0.18208]\n",
      "[epoch 5], [iter 29000 / 35967], [train loss 2.14435], [train acc 0.18221]\n",
      "[epoch 5], [iter 29100 / 35967], [train loss 2.14439], [train acc 0.18230]\n",
      "[epoch 5], [iter 29200 / 35967], [train loss 2.14444], [train acc 0.18226]\n",
      "[epoch 5], [iter 29300 / 35967], [train loss 2.14448], [train acc 0.18232]\n",
      "[epoch 5], [iter 29400 / 35967], [train loss 2.14411], [train acc 0.18238]\n",
      "[epoch 5], [iter 29500 / 35967], [train loss 2.14439], [train acc 0.18234]\n",
      "[epoch 5], [iter 29600 / 35967], [train loss 2.14464], [train acc 0.18230]\n",
      "[epoch 5], [iter 29700 / 35967], [train loss 2.14498], [train acc 0.18236]\n",
      "[epoch 5], [iter 29800 / 35967], [train loss 2.14493], [train acc 0.18235]\n",
      "[epoch 5], [iter 29900 / 35967], [train loss 2.14472], [train acc 0.18234]\n",
      "[epoch 5], [iter 30000 / 35967], [train loss 2.14477], [train acc 0.18237]\n",
      "[epoch 5], [iter 30100 / 35967], [train loss 2.14453], [train acc 0.18252]\n",
      "[epoch 5], [iter 30200 / 35967], [train loss 2.14452], [train acc 0.18245]\n",
      "[epoch 5], [iter 30300 / 35967], [train loss 2.14495], [train acc 0.18218]\n",
      "[epoch 5], [iter 30400 / 35967], [train loss 2.14488], [train acc 0.18224]\n",
      "[epoch 5], [iter 30500 / 35967], [train loss 2.14522], [train acc 0.18210]\n",
      "[epoch 5], [iter 30600 / 35967], [train loss 2.14524], [train acc 0.18219]\n",
      "[epoch 5], [iter 30700 / 35967], [train loss 2.14512], [train acc 0.18235]\n",
      "[epoch 5], [iter 30800 / 35967], [train loss 2.14508], [train acc 0.18234]\n",
      "[epoch 5], [iter 30900 / 35967], [train loss 2.14505], [train acc 0.18239]\n",
      "[epoch 5], [iter 31000 / 35967], [train loss 2.14476], [train acc 0.18271]\n",
      "[epoch 5], [iter 31100 / 35967], [train loss 2.14451], [train acc 0.18293]\n",
      "[epoch 5], [iter 31200 / 35967], [train loss 2.14455], [train acc 0.18276]\n",
      "[epoch 5], [iter 31300 / 35967], [train loss 2.14442], [train acc 0.18275]\n",
      "[epoch 5], [iter 31400 / 35967], [train loss 2.14396], [train acc 0.18283]\n",
      "[epoch 5], [iter 31500 / 35967], [train loss 2.14400], [train acc 0.18286]\n",
      "[epoch 5], [iter 31600 / 35967], [train loss 2.14401], [train acc 0.18285]\n",
      "[epoch 5], [iter 31700 / 35967], [train loss 2.14401], [train acc 0.18281]\n",
      "[epoch 5], [iter 31800 / 35967], [train loss 2.14424], [train acc 0.18274]\n",
      "[epoch 5], [iter 31900 / 35967], [train loss 2.14449], [train acc 0.18263]\n",
      "[epoch 5], [iter 32000 / 35967], [train loss 2.14463], [train acc 0.18256]\n",
      "[epoch 5], [iter 32100 / 35967], [train loss 2.14450], [train acc 0.18249]\n",
      "[epoch 5], [iter 32200 / 35967], [train loss 2.14461], [train acc 0.18239]\n",
      "[epoch 5], [iter 32300 / 35967], [train loss 2.14450], [train acc 0.18254]\n",
      "[epoch 5], [iter 32400 / 35967], [train loss 2.14446], [train acc 0.18259]\n",
      "[epoch 5], [iter 32500 / 35967], [train loss 2.14457], [train acc 0.18268]\n",
      "[epoch 5], [iter 32600 / 35967], [train loss 2.14438], [train acc 0.18267]\n",
      "[epoch 5], [iter 32700 / 35967], [train loss 2.14425], [train acc 0.18297]\n",
      "[epoch 5], [iter 32800 / 35967], [train loss 2.14451], [train acc 0.18280]\n",
      "[epoch 5], [iter 32900 / 35967], [train loss 2.14493], [train acc 0.18255]\n",
      "[epoch 5], [iter 33000 / 35967], [train loss 2.14498], [train acc 0.18255]\n",
      "[epoch 5], [iter 33100 / 35967], [train loss 2.14468], [train acc 0.18269]\n",
      "[epoch 5], [iter 33200 / 35967], [train loss 2.14443], [train acc 0.18289]\n",
      "[epoch 5], [iter 33300 / 35967], [train loss 2.14477], [train acc 0.18282]\n",
      "[epoch 5], [iter 33400 / 35967], [train loss 2.14504], [train acc 0.18263]\n",
      "[epoch 5], [iter 33500 / 35967], [train loss 2.14485], [train acc 0.18257]\n",
      "[epoch 5], [iter 33600 / 35967], [train loss 2.14470], [train acc 0.18253]\n",
      "[epoch 5], [iter 33700 / 35967], [train loss 2.14509], [train acc 0.18252]\n",
      "[epoch 5], [iter 33800 / 35967], [train loss 2.14532], [train acc 0.18243]\n",
      "[epoch 5], [iter 33900 / 35967], [train loss 2.14564], [train acc 0.18227]\n",
      "[epoch 5], [iter 34000 / 35967], [train loss 2.14566], [train acc 0.18226]\n",
      "[epoch 5], [iter 34100 / 35967], [train loss 2.14559], [train acc 0.18217]\n",
      "[epoch 5], [iter 34200 / 35967], [train loss 2.14545], [train acc 0.18216]\n",
      "[epoch 5], [iter 34300 / 35967], [train loss 2.14533], [train acc 0.18222]\n",
      "[epoch 5], [iter 34400 / 35967], [train loss 2.14517], [train acc 0.18230]\n",
      "[epoch 5], [iter 34500 / 35967], [train loss 2.14505], [train acc 0.18238]\n",
      "[epoch 5], [iter 34600 / 35967], [train loss 2.14509], [train acc 0.18237]\n",
      "[epoch 5], [iter 34700 / 35967], [train loss 2.14556], [train acc 0.18222]\n",
      "[epoch 5], [iter 34800 / 35967], [train loss 2.14528], [train acc 0.18221]\n",
      "[epoch 5], [iter 34900 / 35967], [train loss 2.14467], [train acc 0.18238]\n",
      "[epoch 5], [iter 35000 / 35967], [train loss 2.14510], [train acc 0.18223]\n",
      "[epoch 5], [iter 35100 / 35967], [train loss 2.14496], [train acc 0.18217]\n",
      "[epoch 5], [iter 35200 / 35967], [train loss 2.14493], [train acc 0.18219]\n",
      "[epoch 5], [iter 35300 / 35967], [train loss 2.14479], [train acc 0.18221]\n",
      "[epoch 5], [iter 35400 / 35967], [train loss 2.14473], [train acc 0.18206]\n",
      "[epoch 5], [iter 35500 / 35967], [train loss 2.14474], [train acc 0.18192]\n",
      "[epoch 5], [iter 35600 / 35967], [train loss 2.14491], [train acc 0.18197]\n",
      "[epoch 5], [iter 35700 / 35967], [train loss 2.14477], [train acc 0.18210]\n",
      "[epoch 5], [iter 35800 / 35967], [train loss 2.14460], [train acc 0.18215]\n",
      "[epoch 5], [iter 35900 / 35967], [train loss 2.14446], [train acc 0.18206]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 9.18184], [val acc 0.03717]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [iter 100 / 35967], [train loss 2.15182], [train acc 0.19000]\n",
      "[epoch 6], [iter 200 / 35967], [train loss 2.13538], [train acc 0.20500]\n",
      "[epoch 6], [iter 300 / 35967], [train loss 2.13637], [train acc 0.20333]\n",
      "[epoch 6], [iter 400 / 35967], [train loss 2.14282], [train acc 0.21250]\n",
      "[epoch 6], [iter 500 / 35967], [train loss 2.14617], [train acc 0.20200]\n",
      "[epoch 6], [iter 600 / 35967], [train loss 2.12868], [train acc 0.20333]\n",
      "[epoch 6], [iter 700 / 35967], [train loss 2.14019], [train acc 0.19429]\n",
      "[epoch 6], [iter 800 / 35967], [train loss 2.14617], [train acc 0.19250]\n",
      "[epoch 6], [iter 900 / 35967], [train loss 2.14174], [train acc 0.19667]\n",
      "[epoch 6], [iter 1000 / 35967], [train loss 2.14014], [train acc 0.19400]\n",
      "[epoch 6], [iter 1100 / 35967], [train loss 2.13747], [train acc 0.19182]\n",
      "[epoch 6], [iter 1200 / 35967], [train loss 2.13074], [train acc 0.19500]\n",
      "[epoch 6], [iter 1300 / 35967], [train loss 2.14130], [train acc 0.19385]\n",
      "[epoch 6], [iter 1400 / 35967], [train loss 2.13156], [train acc 0.19286]\n",
      "[epoch 6], [iter 1500 / 35967], [train loss 2.13261], [train acc 0.19267]\n",
      "[epoch 6], [iter 1600 / 35967], [train loss 2.12358], [train acc 0.19375]\n",
      "[epoch 6], [iter 1700 / 35967], [train loss 2.12116], [train acc 0.19471]\n",
      "[epoch 6], [iter 1800 / 35967], [train loss 2.12462], [train acc 0.19167]\n",
      "[epoch 6], [iter 1900 / 35967], [train loss 2.12568], [train acc 0.19211]\n",
      "[epoch 6], [iter 2000 / 35967], [train loss 2.12442], [train acc 0.19100]\n",
      "[epoch 6], [iter 2100 / 35967], [train loss 2.13023], [train acc 0.19000]\n",
      "[epoch 6], [iter 2200 / 35967], [train loss 2.12737], [train acc 0.19091]\n",
      "[epoch 6], [iter 2300 / 35967], [train loss 2.12662], [train acc 0.19087]\n",
      "[epoch 6], [iter 2400 / 35967], [train loss 2.12409], [train acc 0.19000]\n",
      "[epoch 6], [iter 2500 / 35967], [train loss 2.12520], [train acc 0.19040]\n",
      "[epoch 6], [iter 2600 / 35967], [train loss 2.12678], [train acc 0.18846]\n",
      "[epoch 6], [iter 2700 / 35967], [train loss 2.12357], [train acc 0.18852]\n",
      "[epoch 6], [iter 2800 / 35967], [train loss 2.12243], [train acc 0.18857]\n",
      "[epoch 6], [iter 2900 / 35967], [train loss 2.12577], [train acc 0.18793]\n",
      "[epoch 6], [iter 3000 / 35967], [train loss 2.12557], [train acc 0.18533]\n",
      "[epoch 6], [iter 3100 / 35967], [train loss 2.12721], [train acc 0.18581]\n",
      "[epoch 6], [iter 3200 / 35967], [train loss 2.12659], [train acc 0.18625]\n",
      "[epoch 6], [iter 3300 / 35967], [train loss 2.12547], [train acc 0.18727]\n",
      "[epoch 6], [iter 3400 / 35967], [train loss 2.12053], [train acc 0.18941]\n",
      "[epoch 6], [iter 3500 / 35967], [train loss 2.11903], [train acc 0.18971]\n",
      "[epoch 6], [iter 3600 / 35967], [train loss 2.11913], [train acc 0.18944]\n",
      "[epoch 6], [iter 3700 / 35967], [train loss 2.11700], [train acc 0.19000]\n",
      "[epoch 6], [iter 3800 / 35967], [train loss 2.11863], [train acc 0.18947]\n",
      "[epoch 6], [iter 3900 / 35967], [train loss 2.12077], [train acc 0.19026]\n",
      "[epoch 6], [iter 4000 / 35967], [train loss 2.12087], [train acc 0.19050]\n",
      "[epoch 6], [iter 4100 / 35967], [train loss 2.12430], [train acc 0.18902]\n",
      "[epoch 6], [iter 4200 / 35967], [train loss 2.12338], [train acc 0.18952]\n",
      "[epoch 6], [iter 4300 / 35967], [train loss 2.12513], [train acc 0.18884]\n",
      "[epoch 6], [iter 4400 / 35967], [train loss 2.12321], [train acc 0.18864]\n",
      "[epoch 6], [iter 4500 / 35967], [train loss 2.12419], [train acc 0.18778]\n",
      "[epoch 6], [iter 4600 / 35967], [train loss 2.12556], [train acc 0.18826]\n",
      "[epoch 6], [iter 4700 / 35967], [train loss 2.12457], [train acc 0.18872]\n",
      "[epoch 6], [iter 4800 / 35967], [train loss 2.12547], [train acc 0.18812]\n",
      "[epoch 6], [iter 4900 / 35967], [train loss 2.12501], [train acc 0.18796]\n",
      "[epoch 6], [iter 5000 / 35967], [train loss 2.12420], [train acc 0.18840]\n",
      "[epoch 6], [iter 5100 / 35967], [train loss 2.12634], [train acc 0.18667]\n",
      "[epoch 6], [iter 5200 / 35967], [train loss 2.12692], [train acc 0.18750]\n",
      "[epoch 6], [iter 5300 / 35967], [train loss 2.12644], [train acc 0.18717]\n",
      "[epoch 6], [iter 5400 / 35967], [train loss 2.12743], [train acc 0.18667]\n",
      "[epoch 6], [iter 5500 / 35967], [train loss 2.12618], [train acc 0.18800]\n",
      "[epoch 6], [iter 5600 / 35967], [train loss 2.12514], [train acc 0.18768]\n",
      "[epoch 6], [iter 5700 / 35967], [train loss 2.12544], [train acc 0.18754]\n",
      "[epoch 6], [iter 5800 / 35967], [train loss 2.12663], [train acc 0.18707]\n",
      "[epoch 6], [iter 5900 / 35967], [train loss 2.12853], [train acc 0.18627]\n",
      "[epoch 6], [iter 6000 / 35967], [train loss 2.12843], [train acc 0.18717]\n",
      "[epoch 6], [iter 6100 / 35967], [train loss 2.12846], [train acc 0.18754]\n",
      "[epoch 6], [iter 6200 / 35967], [train loss 2.12884], [train acc 0.18774]\n",
      "[epoch 6], [iter 6300 / 35967], [train loss 2.13021], [train acc 0.18683]\n",
      "[epoch 6], [iter 6400 / 35967], [train loss 2.12957], [train acc 0.18703]\n",
      "[epoch 6], [iter 6500 / 35967], [train loss 2.12870], [train acc 0.18754]\n",
      "[epoch 6], [iter 6600 / 35967], [train loss 2.13200], [train acc 0.18682]\n",
      "[epoch 6], [iter 6700 / 35967], [train loss 2.13311], [train acc 0.18687]\n",
      "[epoch 6], [iter 6800 / 35967], [train loss 2.13545], [train acc 0.18632]\n",
      "[epoch 6], [iter 6900 / 35967], [train loss 2.13763], [train acc 0.18565]\n",
      "[epoch 6], [iter 7000 / 35967], [train loss 2.13686], [train acc 0.18557]\n",
      "[epoch 6], [iter 7100 / 35967], [train loss 2.13816], [train acc 0.18521]\n",
      "[epoch 6], [iter 7200 / 35967], [train loss 2.13902], [train acc 0.18472]\n",
      "[epoch 6], [iter 7300 / 35967], [train loss 2.13895], [train acc 0.18479]\n",
      "[epoch 6], [iter 7400 / 35967], [train loss 2.14067], [train acc 0.18486]\n",
      "[epoch 6], [iter 7500 / 35967], [train loss 2.14092], [train acc 0.18467]\n",
      "[epoch 6], [iter 7600 / 35967], [train loss 2.13953], [train acc 0.18461]\n",
      "[epoch 6], [iter 7700 / 35967], [train loss 2.13913], [train acc 0.18416]\n",
      "[epoch 6], [iter 7800 / 35967], [train loss 2.13951], [train acc 0.18397]\n",
      "[epoch 6], [iter 7900 / 35967], [train loss 2.14010], [train acc 0.18367]\n",
      "[epoch 6], [iter 8000 / 35967], [train loss 2.14151], [train acc 0.18363]\n",
      "[epoch 6], [iter 8100 / 35967], [train loss 2.14100], [train acc 0.18346]\n",
      "[epoch 6], [iter 8200 / 35967], [train loss 2.14011], [train acc 0.18366]\n",
      "[epoch 6], [iter 8300 / 35967], [train loss 2.13916], [train acc 0.18325]\n",
      "[epoch 6], [iter 8400 / 35967], [train loss 2.13821], [train acc 0.18333]\n",
      "[epoch 6], [iter 8500 / 35967], [train loss 2.13751], [train acc 0.18306]\n",
      "[epoch 6], [iter 8600 / 35967], [train loss 2.13654], [train acc 0.18360]\n",
      "[epoch 6], [iter 8700 / 35967], [train loss 2.13651], [train acc 0.18333]\n",
      "[epoch 6], [iter 8800 / 35967], [train loss 2.13674], [train acc 0.18375]\n",
      "[epoch 6], [iter 8900 / 35967], [train loss 2.13564], [train acc 0.18371]\n",
      "[epoch 6], [iter 9000 / 35967], [train loss 2.13523], [train acc 0.18322]\n",
      "[epoch 6], [iter 9100 / 35967], [train loss 2.13433], [train acc 0.18341]\n",
      "[epoch 6], [iter 9200 / 35967], [train loss 2.13362], [train acc 0.18337]\n",
      "[epoch 6], [iter 9300 / 35967], [train loss 2.13335], [train acc 0.18323]\n",
      "[epoch 6], [iter 9400 / 35967], [train loss 2.13318], [train acc 0.18309]\n",
      "[epoch 6], [iter 9500 / 35967], [train loss 2.13402], [train acc 0.18337]\n",
      "[epoch 6], [iter 9600 / 35967], [train loss 2.13437], [train acc 0.18313]\n",
      "[epoch 6], [iter 9700 / 35967], [train loss 2.13377], [train acc 0.18309]\n",
      "[epoch 6], [iter 9800 / 35967], [train loss 2.13249], [train acc 0.18316]\n",
      "[epoch 6], [iter 9900 / 35967], [train loss 2.13210], [train acc 0.18323]\n",
      "[epoch 6], [iter 10000 / 35967], [train loss 2.13237], [train acc 0.18340]\n",
      "[epoch 6], [iter 10100 / 35967], [train loss 2.13113], [train acc 0.18416]\n",
      "[epoch 6], [iter 10200 / 35967], [train loss 2.13034], [train acc 0.18422]\n",
      "[epoch 6], [iter 10300 / 35967], [train loss 2.12940], [train acc 0.18505]\n",
      "[epoch 6], [iter 10400 / 35967], [train loss 2.12994], [train acc 0.18519]\n",
      "[epoch 6], [iter 10500 / 35967], [train loss 2.12997], [train acc 0.18514]\n",
      "[epoch 6], [iter 10600 / 35967], [train loss 2.12972], [train acc 0.18500]\n",
      "[epoch 6], [iter 10700 / 35967], [train loss 2.12884], [train acc 0.18505]\n",
      "[epoch 6], [iter 10800 / 35967], [train loss 2.12863], [train acc 0.18528]\n",
      "[epoch 6], [iter 10900 / 35967], [train loss 2.12739], [train acc 0.18651]\n",
      "[epoch 6], [iter 11000 / 35967], [train loss 2.12899], [train acc 0.18636]\n",
      "[epoch 6], [iter 11100 / 35967], [train loss 2.12881], [train acc 0.18676]\n",
      "[epoch 6], [iter 11200 / 35967], [train loss 2.12812], [train acc 0.18688]\n",
      "[epoch 6], [iter 11300 / 35967], [train loss 2.12802], [train acc 0.18681]\n",
      "[epoch 6], [iter 11400 / 35967], [train loss 2.12819], [train acc 0.18667]\n",
      "[epoch 6], [iter 11500 / 35967], [train loss 2.12825], [train acc 0.18643]\n",
      "[epoch 6], [iter 11600 / 35967], [train loss 2.12728], [train acc 0.18664]\n",
      "[epoch 6], [iter 11700 / 35967], [train loss 2.12724], [train acc 0.18658]\n",
      "[epoch 6], [iter 11800 / 35967], [train loss 2.12838], [train acc 0.18627]\n",
      "[epoch 6], [iter 11900 / 35967], [train loss 2.12883], [train acc 0.18597]\n",
      "[epoch 6], [iter 12000 / 35967], [train loss 2.12857], [train acc 0.18617]\n",
      "[epoch 6], [iter 12100 / 35967], [train loss 2.12898], [train acc 0.18595]\n",
      "[epoch 6], [iter 12200 / 35967], [train loss 2.12978], [train acc 0.18566]\n",
      "[epoch 6], [iter 12300 / 35967], [train loss 2.13009], [train acc 0.18577]\n",
      "[epoch 6], [iter 12400 / 35967], [train loss 2.12914], [train acc 0.18589]\n",
      "[epoch 6], [iter 12500 / 35967], [train loss 2.12936], [train acc 0.18584]\n",
      "[epoch 6], [iter 12600 / 35967], [train loss 2.13025], [train acc 0.18540]\n",
      "[epoch 6], [iter 12700 / 35967], [train loss 2.13040], [train acc 0.18488]\n",
      "[epoch 6], [iter 12800 / 35967], [train loss 2.13066], [train acc 0.18492]\n",
      "[epoch 6], [iter 12900 / 35967], [train loss 2.13141], [train acc 0.18442]\n",
      "[epoch 6], [iter 13000 / 35967], [train loss 2.13129], [train acc 0.18438]\n",
      "[epoch 6], [iter 13100 / 35967], [train loss 2.13103], [train acc 0.18443]\n",
      "[epoch 6], [iter 13200 / 35967], [train loss 2.13100], [train acc 0.18432]\n",
      "[epoch 6], [iter 13300 / 35967], [train loss 2.13082], [train acc 0.18436]\n",
      "[epoch 6], [iter 13400 / 35967], [train loss 2.13193], [train acc 0.18410]\n",
      "[epoch 6], [iter 13500 / 35967], [train loss 2.13225], [train acc 0.18356]\n",
      "[epoch 6], [iter 13600 / 35967], [train loss 2.13203], [train acc 0.18397]\n",
      "[epoch 6], [iter 13700 / 35967], [train loss 2.13138], [train acc 0.18445]\n",
      "[epoch 6], [iter 13800 / 35967], [train loss 2.13176], [train acc 0.18413]\n",
      "[epoch 6], [iter 13900 / 35967], [train loss 2.13135], [train acc 0.18410]\n",
      "[epoch 6], [iter 14000 / 35967], [train loss 2.13198], [train acc 0.18386]\n",
      "[epoch 6], [iter 14100 / 35967], [train loss 2.13191], [train acc 0.18426]\n",
      "[epoch 6], [iter 14200 / 35967], [train loss 2.13228], [train acc 0.18408]\n",
      "[epoch 6], [iter 14300 / 35967], [train loss 2.13301], [train acc 0.18448]\n",
      "[epoch 6], [iter 14400 / 35967], [train loss 2.13308], [train acc 0.18472]\n",
      "[epoch 6], [iter 14500 / 35967], [train loss 2.13323], [train acc 0.18462]\n",
      "[epoch 6], [iter 14600 / 35967], [train loss 2.13403], [train acc 0.18418]\n",
      "[epoch 6], [iter 14700 / 35967], [train loss 2.13448], [train acc 0.18388]\n",
      "[epoch 6], [iter 14800 / 35967], [train loss 2.13468], [train acc 0.18412]\n",
      "[epoch 6], [iter 14900 / 35967], [train loss 2.13481], [train acc 0.18403]\n",
      "[epoch 6], [iter 15000 / 35967], [train loss 2.13443], [train acc 0.18387]\n",
      "[epoch 6], [iter 15100 / 35967], [train loss 2.13482], [train acc 0.18371]\n",
      "[epoch 6], [iter 15200 / 35967], [train loss 2.13495], [train acc 0.18342]\n",
      "[epoch 6], [iter 15300 / 35967], [train loss 2.13501], [train acc 0.18333]\n",
      "[epoch 6], [iter 15400 / 35967], [train loss 2.13534], [train acc 0.18325]\n",
      "[epoch 6], [iter 15500 / 35967], [train loss 2.13463], [train acc 0.18329]\n",
      "[epoch 6], [iter 15600 / 35967], [train loss 2.13405], [train acc 0.18346]\n",
      "[epoch 6], [iter 15700 / 35967], [train loss 2.13504], [train acc 0.18306]\n",
      "[epoch 6], [iter 15800 / 35967], [train loss 2.13510], [train acc 0.18316]\n",
      "[epoch 6], [iter 15900 / 35967], [train loss 2.13451], [train acc 0.18327]\n",
      "[epoch 6], [iter 16000 / 35967], [train loss 2.13441], [train acc 0.18313]\n",
      "[epoch 6], [iter 16100 / 35967], [train loss 2.13444], [train acc 0.18329]\n",
      "[epoch 6], [iter 16200 / 35967], [train loss 2.13443], [train acc 0.18340]\n",
      "[epoch 6], [iter 16300 / 35967], [train loss 2.13414], [train acc 0.18337]\n",
      "[epoch 6], [iter 16400 / 35967], [train loss 2.13438], [train acc 0.18360]\n",
      "[epoch 6], [iter 16500 / 35967], [train loss 2.13437], [train acc 0.18364]\n",
      "[epoch 6], [iter 16600 / 35967], [train loss 2.13525], [train acc 0.18361]\n",
      "[epoch 6], [iter 16700 / 35967], [train loss 2.13521], [train acc 0.18371]\n",
      "[epoch 6], [iter 16800 / 35967], [train loss 2.13513], [train acc 0.18399]\n",
      "[epoch 6], [iter 16900 / 35967], [train loss 2.13587], [train acc 0.18361]\n",
      "[epoch 6], [iter 17000 / 35967], [train loss 2.13560], [train acc 0.18406]\n",
      "[epoch 6], [iter 17100 / 35967], [train loss 2.13527], [train acc 0.18433]\n",
      "[epoch 6], [iter 17200 / 35967], [train loss 2.13456], [train acc 0.18448]\n",
      "[epoch 6], [iter 17300 / 35967], [train loss 2.13464], [train acc 0.18416]\n",
      "[epoch 6], [iter 17400 / 35967], [train loss 2.13418], [train acc 0.18431]\n",
      "[epoch 6], [iter 17500 / 35967], [train loss 2.13393], [train acc 0.18446]\n",
      "[epoch 6], [iter 17600 / 35967], [train loss 2.13445], [train acc 0.18432]\n",
      "[epoch 6], [iter 17700 / 35967], [train loss 2.13453], [train acc 0.18429]\n",
      "[epoch 6], [iter 17800 / 35967], [train loss 2.13420], [train acc 0.18404]\n",
      "[epoch 6], [iter 17900 / 35967], [train loss 2.13290], [train acc 0.18464]\n",
      "[epoch 6], [iter 18000 / 35967], [train loss 2.13303], [train acc 0.18456]\n",
      "[epoch 6], [iter 18100 / 35967], [train loss 2.13241], [train acc 0.18492]\n",
      "[epoch 6], [iter 18200 / 35967], [train loss 2.13174], [train acc 0.18495]\n",
      "[epoch 6], [iter 18300 / 35967], [train loss 2.13166], [train acc 0.18514]\n",
      "[epoch 6], [iter 18400 / 35967], [train loss 2.13216], [train acc 0.18489]\n",
      "[epoch 6], [iter 18500 / 35967], [train loss 2.13193], [train acc 0.18486]\n",
      "[epoch 6], [iter 18600 / 35967], [train loss 2.13151], [train acc 0.18495]\n",
      "[epoch 6], [iter 18700 / 35967], [train loss 2.13188], [train acc 0.18508]\n",
      "[epoch 6], [iter 18800 / 35967], [train loss 2.13113], [train acc 0.18543]\n",
      "[epoch 6], [iter 18900 / 35967], [train loss 2.13126], [train acc 0.18534]\n",
      "[epoch 6], [iter 19000 / 35967], [train loss 2.13080], [train acc 0.18516]\n",
      "[epoch 6], [iter 19100 / 35967], [train loss 2.13042], [train acc 0.18534]\n",
      "[epoch 6], [iter 19200 / 35967], [train loss 2.13062], [train acc 0.18552]\n",
      "[epoch 6], [iter 19300 / 35967], [train loss 2.13110], [train acc 0.18549]\n",
      "[epoch 6], [iter 19400 / 35967], [train loss 2.13079], [train acc 0.18557]\n",
      "[epoch 6], [iter 19500 / 35967], [train loss 2.13087], [train acc 0.18538]\n",
      "[epoch 6], [iter 19600 / 35967], [train loss 2.13121], [train acc 0.18520]\n",
      "[epoch 6], [iter 19700 / 35967], [train loss 2.13082], [train acc 0.18543]\n",
      "[epoch 6], [iter 19800 / 35967], [train loss 2.13049], [train acc 0.18566]\n",
      "[epoch 6], [iter 19900 / 35967], [train loss 2.13070], [train acc 0.18528]\n",
      "[epoch 6], [iter 20000 / 35967], [train loss 2.13099], [train acc 0.18525]\n",
      "[epoch 6], [iter 20100 / 35967], [train loss 2.13042], [train acc 0.18577]\n",
      "[epoch 6], [iter 20200 / 35967], [train loss 2.13024], [train acc 0.18574]\n",
      "[epoch 6], [iter 20300 / 35967], [train loss 2.13032], [train acc 0.18562]\n",
      "[epoch 6], [iter 20400 / 35967], [train loss 2.13023], [train acc 0.18578]\n",
      "[epoch 6], [iter 20500 / 35967], [train loss 2.12949], [train acc 0.18620]\n",
      "[epoch 6], [iter 20600 / 35967], [train loss 2.12934], [train acc 0.18626]\n",
      "[epoch 6], [iter 20700 / 35967], [train loss 2.12971], [train acc 0.18594]\n",
      "[epoch 6], [iter 20800 / 35967], [train loss 2.13033], [train acc 0.18596]\n",
      "[epoch 6], [iter 20900 / 35967], [train loss 2.13041], [train acc 0.18589]\n",
      "[epoch 6], [iter 21000 / 35967], [train loss 2.13054], [train acc 0.18562]\n",
      "[epoch 6], [iter 21100 / 35967], [train loss 2.13011], [train acc 0.18583]\n",
      "[epoch 6], [iter 21200 / 35967], [train loss 2.13059], [train acc 0.18561]\n",
      "[epoch 6], [iter 21300 / 35967], [train loss 2.13107], [train acc 0.18573]\n",
      "[epoch 6], [iter 21400 / 35967], [train loss 2.13100], [train acc 0.18584]\n",
      "[epoch 6], [iter 21500 / 35967], [train loss 2.13122], [train acc 0.18591]\n",
      "[epoch 6], [iter 21600 / 35967], [train loss 2.13155], [train acc 0.18583]\n",
      "[epoch 6], [iter 21700 / 35967], [train loss 2.13156], [train acc 0.18590]\n",
      "[epoch 6], [iter 21800 / 35967], [train loss 2.13130], [train acc 0.18583]\n",
      "[epoch 6], [iter 21900 / 35967], [train loss 2.13118], [train acc 0.18584]\n",
      "[epoch 6], [iter 22000 / 35967], [train loss 2.13142], [train acc 0.18586]\n",
      "[epoch 6], [iter 22100 / 35967], [train loss 2.13145], [train acc 0.18593]\n",
      "[epoch 6], [iter 22200 / 35967], [train loss 2.13212], [train acc 0.18572]\n",
      "[epoch 6], [iter 22300 / 35967], [train loss 2.13213], [train acc 0.18565]\n",
      "[epoch 6], [iter 22400 / 35967], [train loss 2.13230], [train acc 0.18576]\n",
      "[epoch 6], [iter 22500 / 35967], [train loss 2.13187], [train acc 0.18596]\n",
      "[epoch 6], [iter 22600 / 35967], [train loss 2.13189], [train acc 0.18597]\n",
      "[epoch 6], [iter 22700 / 35967], [train loss 2.13154], [train acc 0.18621]\n",
      "[epoch 6], [iter 22800 / 35967], [train loss 2.13152], [train acc 0.18623]\n",
      "[epoch 6], [iter 22900 / 35967], [train loss 2.13169], [train acc 0.18646]\n",
      "[epoch 6], [iter 23000 / 35967], [train loss 2.13182], [train acc 0.18622]\n",
      "[epoch 6], [iter 23100 / 35967], [train loss 2.13226], [train acc 0.18606]\n",
      "[epoch 6], [iter 23200 / 35967], [train loss 2.13218], [train acc 0.18642]\n",
      "[epoch 6], [iter 23300 / 35967], [train loss 2.13174], [train acc 0.18661]\n",
      "[epoch 6], [iter 23400 / 35967], [train loss 2.13151], [train acc 0.18654]\n",
      "[epoch 6], [iter 23500 / 35967], [train loss 2.13197], [train acc 0.18651]\n",
      "[epoch 6], [iter 23600 / 35967], [train loss 2.13214], [train acc 0.18657]\n",
      "[epoch 6], [iter 23700 / 35967], [train loss 2.13175], [train acc 0.18662]\n",
      "[epoch 6], [iter 23800 / 35967], [train loss 2.13201], [train acc 0.18676]\n",
      "[epoch 6], [iter 23900 / 35967], [train loss 2.13182], [train acc 0.18678]\n",
      "[epoch 6], [iter 24000 / 35967], [train loss 2.13142], [train acc 0.18692]\n",
      "[epoch 6], [iter 24100 / 35967], [train loss 2.13117], [train acc 0.18689]\n",
      "[epoch 6], [iter 24200 / 35967], [train loss 2.13185], [train acc 0.18682]\n",
      "[epoch 6], [iter 24300 / 35967], [train loss 2.13168], [train acc 0.18663]\n",
      "[epoch 6], [iter 24400 / 35967], [train loss 2.13130], [train acc 0.18672]\n",
      "[epoch 6], [iter 24500 / 35967], [train loss 2.13153], [train acc 0.18706]\n",
      "[epoch 6], [iter 24600 / 35967], [train loss 2.13171], [train acc 0.18715]\n",
      "[epoch 6], [iter 24700 / 35967], [train loss 2.13151], [train acc 0.18696]\n",
      "[epoch 6], [iter 24800 / 35967], [train loss 2.13150], [train acc 0.18690]\n",
      "[epoch 6], [iter 24900 / 35967], [train loss 2.13154], [train acc 0.18707]\n",
      "[epoch 6], [iter 25000 / 35967], [train loss 2.13142], [train acc 0.18700]\n",
      "[epoch 6], [iter 25100 / 35967], [train loss 2.13106], [train acc 0.18709]\n",
      "[epoch 6], [iter 25200 / 35967], [train loss 2.13099], [train acc 0.18698]\n",
      "[epoch 6], [iter 25300 / 35967], [train loss 2.13064], [train acc 0.18704]\n",
      "[epoch 6], [iter 25400 / 35967], [train loss 2.13058], [train acc 0.18717]\n",
      "[epoch 6], [iter 25500 / 35967], [train loss 2.13097], [train acc 0.18698]\n",
      "[epoch 6], [iter 25600 / 35967], [train loss 2.13029], [train acc 0.18703]\n",
      "[epoch 6], [iter 25700 / 35967], [train loss 2.13015], [train acc 0.18708]\n",
      "[epoch 6], [iter 25800 / 35967], [train loss 2.12973], [train acc 0.18725]\n",
      "[epoch 6], [iter 25900 / 35967], [train loss 2.12949], [train acc 0.18741]\n",
      "[epoch 6], [iter 26000 / 35967], [train loss 2.12953], [train acc 0.18742]\n",
      "[epoch 6], [iter 26100 / 35967], [train loss 2.12972], [train acc 0.18751]\n",
      "[epoch 6], [iter 26200 / 35967], [train loss 2.12971], [train acc 0.18740]\n",
      "[epoch 6], [iter 26300 / 35967], [train loss 2.12953], [train acc 0.18779]\n",
      "[epoch 6], [iter 26400 / 35967], [train loss 2.12949], [train acc 0.18773]\n",
      "[epoch 6], [iter 26500 / 35967], [train loss 2.12976], [train acc 0.18758]\n",
      "[epoch 6], [iter 26600 / 35967], [train loss 2.12959], [train acc 0.18756]\n",
      "[epoch 6], [iter 26700 / 35967], [train loss 2.12936], [train acc 0.18742]\n",
      "[epoch 6], [iter 26800 / 35967], [train loss 2.12997], [train acc 0.18716]\n",
      "[epoch 6], [iter 26900 / 35967], [train loss 2.13008], [train acc 0.18691]\n",
      "[epoch 6], [iter 27000 / 35967], [train loss 2.12993], [train acc 0.18696]\n",
      "[epoch 6], [iter 27100 / 35967], [train loss 2.13018], [train acc 0.18716]\n",
      "[epoch 6], [iter 27200 / 35967], [train loss 2.13019], [train acc 0.18735]\n",
      "[epoch 6], [iter 27300 / 35967], [train loss 2.13032], [train acc 0.18766]\n",
      "[epoch 6], [iter 27400 / 35967], [train loss 2.13019], [train acc 0.18788]\n",
      "[epoch 6], [iter 27500 / 35967], [train loss 2.13032], [train acc 0.18829]\n",
      "[epoch 6], [iter 27600 / 35967], [train loss 2.13075], [train acc 0.18830]\n",
      "[epoch 6], [iter 27700 / 35967], [train loss 2.13058], [train acc 0.18848]\n",
      "[epoch 6], [iter 27800 / 35967], [train loss 2.13101], [train acc 0.18831]\n",
      "[epoch 6], [iter 27900 / 35967], [train loss 2.13063], [train acc 0.18849]\n",
      "[epoch 6], [iter 28000 / 35967], [train loss 2.13055], [train acc 0.18857]\n",
      "[epoch 6], [iter 28100 / 35967], [train loss 2.13020], [train acc 0.18865]\n",
      "[epoch 6], [iter 28200 / 35967], [train loss 2.13036], [train acc 0.18890]\n",
      "[epoch 6], [iter 28300 / 35967], [train loss 2.13043], [train acc 0.18894]\n",
      "[epoch 6], [iter 28400 / 35967], [train loss 2.13039], [train acc 0.18908]\n",
      "[epoch 6], [iter 28500 / 35967], [train loss 2.13008], [train acc 0.18916]\n",
      "[epoch 6], [iter 28600 / 35967], [train loss 2.13056], [train acc 0.18909]\n",
      "[epoch 6], [iter 28700 / 35967], [train loss 2.13088], [train acc 0.18913]\n",
      "[epoch 6], [iter 28800 / 35967], [train loss 2.13098], [train acc 0.18910]\n",
      "[epoch 6], [iter 28900 / 35967], [train loss 2.13115], [train acc 0.18900]\n",
      "[epoch 6], [iter 29000 / 35967], [train loss 2.13108], [train acc 0.18897]\n",
      "[epoch 6], [iter 29100 / 35967], [train loss 2.13084], [train acc 0.18914]\n",
      "[epoch 6], [iter 29200 / 35967], [train loss 2.13049], [train acc 0.18928]\n",
      "[epoch 6], [iter 29300 / 35967], [train loss 2.13058], [train acc 0.18918]\n",
      "[epoch 6], [iter 29400 / 35967], [train loss 2.13016], [train acc 0.18929]\n",
      "[epoch 6], [iter 29500 / 35967], [train loss 2.13040], [train acc 0.18902]\n",
      "[epoch 6], [iter 29600 / 35967], [train loss 2.13064], [train acc 0.18905]\n",
      "[epoch 6], [iter 29700 / 35967], [train loss 2.13058], [train acc 0.18909]\n",
      "[epoch 6], [iter 29800 / 35967], [train loss 2.13073], [train acc 0.18930]\n",
      "[epoch 6], [iter 29900 / 35967], [train loss 2.13060], [train acc 0.18930]\n",
      "[epoch 6], [iter 30000 / 35967], [train loss 2.13082], [train acc 0.18920]\n",
      "[epoch 6], [iter 30100 / 35967], [train loss 2.13068], [train acc 0.18914]\n",
      "[epoch 6], [iter 30200 / 35967], [train loss 2.13055], [train acc 0.18930]\n",
      "[epoch 6], [iter 30300 / 35967], [train loss 2.13036], [train acc 0.18944]\n",
      "[epoch 6], [iter 30400 / 35967], [train loss 2.13008], [train acc 0.18951]\n",
      "[epoch 6], [iter 30500 / 35967], [train loss 2.13028], [train acc 0.18961]\n",
      "[epoch 6], [iter 30600 / 35967], [train loss 2.13061], [train acc 0.18964]\n",
      "[epoch 6], [iter 30700 / 35967], [train loss 2.13056], [train acc 0.18971]\n",
      "[epoch 6], [iter 30800 / 35967], [train loss 2.13079], [train acc 0.18971]\n",
      "[epoch 6], [iter 30900 / 35967], [train loss 2.13079], [train acc 0.18968]\n",
      "[epoch 6], [iter 31000 / 35967], [train loss 2.13070], [train acc 0.18974]\n",
      "[epoch 6], [iter 31100 / 35967], [train loss 2.13106], [train acc 0.18961]\n",
      "[epoch 6], [iter 31200 / 35967], [train loss 2.13122], [train acc 0.18955]\n",
      "[epoch 6], [iter 31300 / 35967], [train loss 2.13114], [train acc 0.18946]\n",
      "[epoch 6], [iter 31400 / 35967], [train loss 2.13115], [train acc 0.18933]\n",
      "[epoch 6], [iter 31500 / 35967], [train loss 2.13151], [train acc 0.18921]\n",
      "[epoch 6], [iter 31600 / 35967], [train loss 2.13178], [train acc 0.18915]\n",
      "[epoch 6], [iter 31700 / 35967], [train loss 2.13195], [train acc 0.18912]\n",
      "[epoch 6], [iter 31800 / 35967], [train loss 2.13161], [train acc 0.18934]\n",
      "[epoch 6], [iter 31900 / 35967], [train loss 2.13211], [train acc 0.18922]\n",
      "[epoch 6], [iter 32000 / 35967], [train loss 2.13174], [train acc 0.18925]\n",
      "[epoch 6], [iter 32100 / 35967], [train loss 2.13186], [train acc 0.18919]\n",
      "[epoch 6], [iter 32200 / 35967], [train loss 2.13188], [train acc 0.18919]\n",
      "[epoch 6], [iter 32300 / 35967], [train loss 2.13212], [train acc 0.18920]\n",
      "[epoch 6], [iter 32400 / 35967], [train loss 2.13210], [train acc 0.18932]\n",
      "[epoch 6], [iter 32500 / 35967], [train loss 2.13232], [train acc 0.18935]\n",
      "[epoch 6], [iter 32600 / 35967], [train loss 2.13233], [train acc 0.18933]\n",
      "[epoch 6], [iter 32700 / 35967], [train loss 2.13226], [train acc 0.18933]\n",
      "[epoch 6], [iter 32800 / 35967], [train loss 2.13233], [train acc 0.18921]\n",
      "[epoch 6], [iter 32900 / 35967], [train loss 2.13256], [train acc 0.18915]\n",
      "[epoch 6], [iter 33000 / 35967], [train loss 2.13264], [train acc 0.18912]\n",
      "[epoch 6], [iter 33100 / 35967], [train loss 2.13284], [train acc 0.18903]\n",
      "[epoch 6], [iter 33200 / 35967], [train loss 2.13281], [train acc 0.18895]\n",
      "[epoch 6], [iter 33300 / 35967], [train loss 2.13252], [train acc 0.18892]\n",
      "[epoch 6], [iter 33400 / 35967], [train loss 2.13249], [train acc 0.18886]\n",
      "[epoch 6], [iter 33500 / 35967], [train loss 2.13240], [train acc 0.18884]\n",
      "[epoch 6], [iter 33600 / 35967], [train loss 2.13251], [train acc 0.18878]\n",
      "[epoch 6], [iter 33700 / 35967], [train loss 2.13226], [train acc 0.18881]\n",
      "[epoch 6], [iter 33800 / 35967], [train loss 2.13258], [train acc 0.18870]\n",
      "[epoch 6], [iter 33900 / 35967], [train loss 2.13266], [train acc 0.18873]\n",
      "[epoch 6], [iter 34000 / 35967], [train loss 2.13258], [train acc 0.18871]\n",
      "[epoch 6], [iter 34100 / 35967], [train loss 2.13264], [train acc 0.18883]\n",
      "[epoch 6], [iter 34200 / 35967], [train loss 2.13278], [train acc 0.18880]\n",
      "[epoch 6], [iter 34300 / 35967], [train loss 2.13297], [train acc 0.18875]\n",
      "[epoch 6], [iter 34400 / 35967], [train loss 2.13290], [train acc 0.18881]\n",
      "[epoch 6], [iter 34500 / 35967], [train loss 2.13278], [train acc 0.18867]\n",
      "[epoch 6], [iter 34600 / 35967], [train loss 2.13296], [train acc 0.18861]\n",
      "[epoch 6], [iter 34700 / 35967], [train loss 2.13291], [train acc 0.18879]\n",
      "[epoch 6], [iter 34800 / 35967], [train loss 2.13295], [train acc 0.18879]\n",
      "[epoch 6], [iter 34900 / 35967], [train loss 2.13329], [train acc 0.18868]\n",
      "[epoch 6], [iter 35000 / 35967], [train loss 2.13332], [train acc 0.18877]\n",
      "[epoch 6], [iter 35100 / 35967], [train loss 2.13373], [train acc 0.18866]\n",
      "[epoch 6], [iter 35200 / 35967], [train loss 2.13395], [train acc 0.18849]\n",
      "[epoch 6], [iter 35300 / 35967], [train loss 2.13373], [train acc 0.18856]\n",
      "[epoch 6], [iter 35400 / 35967], [train loss 2.13387], [train acc 0.18853]\n",
      "[epoch 6], [iter 35500 / 35967], [train loss 2.13408], [train acc 0.18842]\n",
      "[epoch 6], [iter 35600 / 35967], [train loss 2.13388], [train acc 0.18854]\n",
      "[epoch 6], [iter 35700 / 35967], [train loss 2.13412], [train acc 0.18857]\n",
      "[epoch 6], [iter 35800 / 35967], [train loss 2.13412], [train acc 0.18841]\n",
      "[epoch 6], [iter 35900 / 35967], [train loss 2.13417], [train acc 0.18847]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 8.03056], [val acc 0.10879]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [iter 100 / 35967], [train loss 2.15189], [train acc 0.16000]\n",
      "[epoch 7], [iter 200 / 35967], [train loss 2.13965], [train acc 0.18000]\n",
      "[epoch 7], [iter 300 / 35967], [train loss 2.09818], [train acc 0.20000]\n",
      "[epoch 7], [iter 400 / 35967], [train loss 2.11618], [train acc 0.18750]\n",
      "[epoch 7], [iter 500 / 35967], [train loss 2.11415], [train acc 0.17200]\n",
      "[epoch 7], [iter 600 / 35967], [train loss 2.13166], [train acc 0.17500]\n",
      "[epoch 7], [iter 700 / 35967], [train loss 2.13593], [train acc 0.17143]\n",
      "[epoch 7], [iter 800 / 35967], [train loss 2.13088], [train acc 0.17000]\n",
      "[epoch 7], [iter 900 / 35967], [train loss 2.13640], [train acc 0.17556]\n",
      "[epoch 7], [iter 1000 / 35967], [train loss 2.14713], [train acc 0.17300]\n",
      "[epoch 7], [iter 1100 / 35967], [train loss 2.14366], [train acc 0.17727]\n",
      "[epoch 7], [iter 1200 / 35967], [train loss 2.13897], [train acc 0.18083]\n",
      "[epoch 7], [iter 1300 / 35967], [train loss 2.13523], [train acc 0.18385]\n",
      "[epoch 7], [iter 1400 / 35967], [train loss 2.13129], [train acc 0.18643]\n",
      "[epoch 7], [iter 1500 / 35967], [train loss 2.13526], [train acc 0.18200]\n",
      "[epoch 7], [iter 1600 / 35967], [train loss 2.13731], [train acc 0.18125]\n",
      "[epoch 7], [iter 1700 / 35967], [train loss 2.13385], [train acc 0.18118]\n",
      "[epoch 7], [iter 1800 / 35967], [train loss 2.13695], [train acc 0.18056]\n",
      "[epoch 7], [iter 1900 / 35967], [train loss 2.14154], [train acc 0.18105]\n",
      "[epoch 7], [iter 2000 / 35967], [train loss 2.13970], [train acc 0.17950]\n",
      "[epoch 7], [iter 2100 / 35967], [train loss 2.13569], [train acc 0.18095]\n",
      "[epoch 7], [iter 2200 / 35967], [train loss 2.13333], [train acc 0.18318]\n",
      "[epoch 7], [iter 2300 / 35967], [train loss 2.13042], [train acc 0.18565]\n",
      "[epoch 7], [iter 2400 / 35967], [train loss 2.12917], [train acc 0.18417]\n",
      "[epoch 7], [iter 2500 / 35967], [train loss 2.13008], [train acc 0.18480]\n",
      "[epoch 7], [iter 2600 / 35967], [train loss 2.12783], [train acc 0.18500]\n",
      "[epoch 7], [iter 2700 / 35967], [train loss 2.12509], [train acc 0.18407]\n",
      "[epoch 7], [iter 2800 / 35967], [train loss 2.12572], [train acc 0.18571]\n",
      "[epoch 7], [iter 2900 / 35967], [train loss 2.12367], [train acc 0.18655]\n",
      "[epoch 7], [iter 3000 / 35967], [train loss 2.12436], [train acc 0.18467]\n",
      "[epoch 7], [iter 3100 / 35967], [train loss 2.12300], [train acc 0.18774]\n",
      "[epoch 7], [iter 3200 / 35967], [train loss 2.12745], [train acc 0.18656]\n",
      "[epoch 7], [iter 3300 / 35967], [train loss 2.12698], [train acc 0.18606]\n",
      "[epoch 7], [iter 3400 / 35967], [train loss 2.12583], [train acc 0.18588]\n",
      "[epoch 7], [iter 3500 / 35967], [train loss 2.12619], [train acc 0.18629]\n",
      "[epoch 7], [iter 3600 / 35967], [train loss 2.12592], [train acc 0.18611]\n",
      "[epoch 7], [iter 3700 / 35967], [train loss 2.12583], [train acc 0.18622]\n",
      "[epoch 7], [iter 3800 / 35967], [train loss 2.12345], [train acc 0.18632]\n",
      "[epoch 7], [iter 3900 / 35967], [train loss 2.11884], [train acc 0.18667]\n",
      "[epoch 7], [iter 4000 / 35967], [train loss 2.11857], [train acc 0.18650]\n",
      "[epoch 7], [iter 4100 / 35967], [train loss 2.11922], [train acc 0.18659]\n",
      "[epoch 7], [iter 4200 / 35967], [train loss 2.11693], [train acc 0.18738]\n",
      "[epoch 7], [iter 4300 / 35967], [train loss 2.11611], [train acc 0.18721]\n",
      "[epoch 7], [iter 4400 / 35967], [train loss 2.11352], [train acc 0.18977]\n",
      "[epoch 7], [iter 4500 / 35967], [train loss 2.11384], [train acc 0.19000]\n",
      "[epoch 7], [iter 4600 / 35967], [train loss 2.11256], [train acc 0.19022]\n",
      "[epoch 7], [iter 4700 / 35967], [train loss 2.11294], [train acc 0.18957]\n",
      "[epoch 7], [iter 4800 / 35967], [train loss 2.11443], [train acc 0.18937]\n",
      "[epoch 7], [iter 4900 / 35967], [train loss 2.11360], [train acc 0.18980]\n",
      "[epoch 7], [iter 5000 / 35967], [train loss 2.11463], [train acc 0.19080]\n",
      "[epoch 7], [iter 5100 / 35967], [train loss 2.11752], [train acc 0.18961]\n",
      "[epoch 7], [iter 5200 / 35967], [train loss 2.11706], [train acc 0.18962]\n",
      "[epoch 7], [iter 5300 / 35967], [train loss 2.11673], [train acc 0.18868]\n",
      "[epoch 7], [iter 5400 / 35967], [train loss 2.11589], [train acc 0.18926]\n",
      "[epoch 7], [iter 5500 / 35967], [train loss 2.11721], [train acc 0.18818]\n",
      "[epoch 7], [iter 5600 / 35967], [train loss 2.11656], [train acc 0.18911]\n",
      "[epoch 7], [iter 5700 / 35967], [train loss 2.11701], [train acc 0.18877]\n",
      "[epoch 7], [iter 5800 / 35967], [train loss 2.11605], [train acc 0.18879]\n",
      "[epoch 7], [iter 5900 / 35967], [train loss 2.11554], [train acc 0.18932]\n",
      "[epoch 7], [iter 6000 / 35967], [train loss 2.11656], [train acc 0.18900]\n",
      "[epoch 7], [iter 6100 / 35967], [train loss 2.11617], [train acc 0.18770]\n",
      "[epoch 7], [iter 6200 / 35967], [train loss 2.11697], [train acc 0.18790]\n",
      "[epoch 7], [iter 6300 / 35967], [train loss 2.11694], [train acc 0.18778]\n",
      "[epoch 7], [iter 6400 / 35967], [train loss 2.11632], [train acc 0.18781]\n",
      "[epoch 7], [iter 6500 / 35967], [train loss 2.11533], [train acc 0.18908]\n",
      "[epoch 7], [iter 6600 / 35967], [train loss 2.11431], [train acc 0.18924]\n",
      "[epoch 7], [iter 6700 / 35967], [train loss 2.11251], [train acc 0.18985]\n",
      "[epoch 7], [iter 6800 / 35967], [train loss 2.11278], [train acc 0.18985]\n",
      "[epoch 7], [iter 6900 / 35967], [train loss 2.11045], [train acc 0.19058]\n",
      "[epoch 7], [iter 7000 / 35967], [train loss 2.10991], [train acc 0.19086]\n",
      "[epoch 7], [iter 7100 / 35967], [train loss 2.10954], [train acc 0.19070]\n",
      "[epoch 7], [iter 7200 / 35967], [train loss 2.11181], [train acc 0.19056]\n",
      "[epoch 7], [iter 7300 / 35967], [train loss 2.11309], [train acc 0.19055]\n",
      "[epoch 7], [iter 7400 / 35967], [train loss 2.11330], [train acc 0.18973]\n",
      "[epoch 7], [iter 7500 / 35967], [train loss 2.11473], [train acc 0.18947]\n",
      "[epoch 7], [iter 7600 / 35967], [train loss 2.11498], [train acc 0.18882]\n",
      "[epoch 7], [iter 7700 / 35967], [train loss 2.11610], [train acc 0.18922]\n",
      "[epoch 7], [iter 7800 / 35967], [train loss 2.11612], [train acc 0.18872]\n",
      "[epoch 7], [iter 7900 / 35967], [train loss 2.11609], [train acc 0.18924]\n",
      "[epoch 7], [iter 8000 / 35967], [train loss 2.11537], [train acc 0.18887]\n",
      "[epoch 7], [iter 8100 / 35967], [train loss 2.11629], [train acc 0.18951]\n",
      "[epoch 7], [iter 8200 / 35967], [train loss 2.11538], [train acc 0.19012]\n",
      "[epoch 7], [iter 8300 / 35967], [train loss 2.11460], [train acc 0.18988]\n",
      "[epoch 7], [iter 8400 / 35967], [train loss 2.11509], [train acc 0.18988]\n",
      "[epoch 7], [iter 8500 / 35967], [train loss 2.11449], [train acc 0.19047]\n",
      "[epoch 7], [iter 8600 / 35967], [train loss 2.11409], [train acc 0.19070]\n",
      "[epoch 7], [iter 8700 / 35967], [train loss 2.11450], [train acc 0.19034]\n",
      "[epoch 7], [iter 8800 / 35967], [train loss 2.11375], [train acc 0.18989]\n",
      "[epoch 7], [iter 8900 / 35967], [train loss 2.11261], [train acc 0.18989]\n",
      "[epoch 7], [iter 9000 / 35967], [train loss 2.11315], [train acc 0.19067]\n",
      "[epoch 7], [iter 9100 / 35967], [train loss 2.11222], [train acc 0.19077]\n",
      "[epoch 7], [iter 9200 / 35967], [train loss 2.11342], [train acc 0.19054]\n",
      "[epoch 7], [iter 9300 / 35967], [train loss 2.11308], [train acc 0.19043]\n",
      "[epoch 7], [iter 9400 / 35967], [train loss 2.11245], [train acc 0.19053]\n",
      "[epoch 7], [iter 9500 / 35967], [train loss 2.11260], [train acc 0.19042]\n",
      "[epoch 7], [iter 9600 / 35967], [train loss 2.11225], [train acc 0.19042]\n",
      "[epoch 7], [iter 9700 / 35967], [train loss 2.11079], [train acc 0.19113]\n",
      "[epoch 7], [iter 9800 / 35967], [train loss 2.10969], [train acc 0.19153]\n",
      "[epoch 7], [iter 9900 / 35967], [train loss 2.11059], [train acc 0.19131]\n",
      "[epoch 7], [iter 10000 / 35967], [train loss 2.11052], [train acc 0.19180]\n",
      "[epoch 7], [iter 10100 / 35967], [train loss 2.11081], [train acc 0.19218]\n",
      "[epoch 7], [iter 10200 / 35967], [train loss 2.11136], [train acc 0.19196]\n",
      "[epoch 7], [iter 10300 / 35967], [train loss 2.11101], [train acc 0.19223]\n",
      "[epoch 7], [iter 10400 / 35967], [train loss 2.11088], [train acc 0.19231]\n",
      "[epoch 7], [iter 10500 / 35967], [train loss 2.10992], [train acc 0.19267]\n",
      "[epoch 7], [iter 10600 / 35967], [train loss 2.10837], [train acc 0.19406]\n",
      "[epoch 7], [iter 10700 / 35967], [train loss 2.10755], [train acc 0.19430]\n",
      "[epoch 7], [iter 10800 / 35967], [train loss 2.10697], [train acc 0.19472]\n",
      "[epoch 7], [iter 10900 / 35967], [train loss 2.10691], [train acc 0.19514]\n",
      "[epoch 7], [iter 11000 / 35967], [train loss 2.10723], [train acc 0.19482]\n",
      "[epoch 7], [iter 11100 / 35967], [train loss 2.10773], [train acc 0.19459]\n",
      "[epoch 7], [iter 11200 / 35967], [train loss 2.10804], [train acc 0.19420]\n",
      "[epoch 7], [iter 11300 / 35967], [train loss 2.10779], [train acc 0.19363]\n",
      "[epoch 7], [iter 11400 / 35967], [train loss 2.10846], [train acc 0.19325]\n",
      "[epoch 7], [iter 11500 / 35967], [train loss 2.10967], [train acc 0.19252]\n",
      "[epoch 7], [iter 11600 / 35967], [train loss 2.10987], [train acc 0.19267]\n",
      "[epoch 7], [iter 11700 / 35967], [train loss 2.11134], [train acc 0.19256]\n",
      "[epoch 7], [iter 11800 / 35967], [train loss 2.11090], [train acc 0.19263]\n",
      "[epoch 7], [iter 11900 / 35967], [train loss 2.11073], [train acc 0.19252]\n",
      "[epoch 7], [iter 12000 / 35967], [train loss 2.11184], [train acc 0.19192]\n",
      "[epoch 7], [iter 12100 / 35967], [train loss 2.11227], [train acc 0.19190]\n",
      "[epoch 7], [iter 12200 / 35967], [train loss 2.11347], [train acc 0.19164]\n",
      "[epoch 7], [iter 12300 / 35967], [train loss 2.11420], [train acc 0.19122]\n",
      "[epoch 7], [iter 12400 / 35967], [train loss 2.11321], [train acc 0.19129]\n",
      "[epoch 7], [iter 12500 / 35967], [train loss 2.11290], [train acc 0.19136]\n",
      "[epoch 7], [iter 12600 / 35967], [train loss 2.11225], [train acc 0.19159]\n",
      "[epoch 7], [iter 12700 / 35967], [train loss 2.11309], [train acc 0.19165]\n",
      "[epoch 7], [iter 12800 / 35967], [train loss 2.11323], [train acc 0.19148]\n",
      "[epoch 7], [iter 12900 / 35967], [train loss 2.11419], [train acc 0.19116]\n",
      "[epoch 7], [iter 13000 / 35967], [train loss 2.11403], [train acc 0.19123]\n",
      "[epoch 7], [iter 13100 / 35967], [train loss 2.11390], [train acc 0.19183]\n",
      "[epoch 7], [iter 13200 / 35967], [train loss 2.11402], [train acc 0.19212]\n",
      "[epoch 7], [iter 13300 / 35967], [train loss 2.11426], [train acc 0.19203]\n",
      "[epoch 7], [iter 13400 / 35967], [train loss 2.11543], [train acc 0.19209]\n",
      "[epoch 7], [iter 13500 / 35967], [train loss 2.11486], [train acc 0.19237]\n",
      "[epoch 7], [iter 13600 / 35967], [train loss 2.11445], [train acc 0.19272]\n",
      "[epoch 7], [iter 13700 / 35967], [train loss 2.11379], [train acc 0.19328]\n",
      "[epoch 7], [iter 13800 / 35967], [train loss 2.11434], [train acc 0.19290]\n",
      "[epoch 7], [iter 13900 / 35967], [train loss 2.11434], [train acc 0.19259]\n",
      "[epoch 7], [iter 14000 / 35967], [train loss 2.11344], [train acc 0.19321]\n",
      "[epoch 7], [iter 14100 / 35967], [train loss 2.11373], [train acc 0.19333]\n",
      "[epoch 7], [iter 14200 / 35967], [train loss 2.11443], [train acc 0.19303]\n",
      "[epoch 7], [iter 14300 / 35967], [train loss 2.11430], [train acc 0.19308]\n",
      "[epoch 7], [iter 14400 / 35967], [train loss 2.11389], [train acc 0.19382]\n",
      "[epoch 7], [iter 14500 / 35967], [train loss 2.11301], [train acc 0.19428]\n",
      "[epoch 7], [iter 14600 / 35967], [train loss 2.11256], [train acc 0.19418]\n",
      "[epoch 7], [iter 14700 / 35967], [train loss 2.11142], [train acc 0.19429]\n",
      "[epoch 7], [iter 14800 / 35967], [train loss 2.11128], [train acc 0.19453]\n",
      "[epoch 7], [iter 14900 / 35967], [train loss 2.11147], [train acc 0.19389]\n",
      "[epoch 7], [iter 15000 / 35967], [train loss 2.11199], [train acc 0.19367]\n",
      "[epoch 7], [iter 15100 / 35967], [train loss 2.11173], [train acc 0.19384]\n",
      "[epoch 7], [iter 15200 / 35967], [train loss 2.11272], [train acc 0.19408]\n",
      "[epoch 7], [iter 15300 / 35967], [train loss 2.11331], [train acc 0.19379]\n",
      "[epoch 7], [iter 15400 / 35967], [train loss 2.11322], [train acc 0.19383]\n",
      "[epoch 7], [iter 15500 / 35967], [train loss 2.11432], [train acc 0.19381]\n",
      "[epoch 7], [iter 15600 / 35967], [train loss 2.11523], [train acc 0.19410]\n",
      "[epoch 7], [iter 15700 / 35967], [train loss 2.11510], [train acc 0.19427]\n",
      "[epoch 7], [iter 15800 / 35967], [train loss 2.11457], [train acc 0.19475]\n",
      "[epoch 7], [iter 15900 / 35967], [train loss 2.11480], [train acc 0.19459]\n",
      "[epoch 7], [iter 16000 / 35967], [train loss 2.11441], [train acc 0.19450]\n",
      "[epoch 7], [iter 16100 / 35967], [train loss 2.11438], [train acc 0.19466]\n",
      "[epoch 7], [iter 16200 / 35967], [train loss 2.11444], [train acc 0.19494]\n",
      "[epoch 7], [iter 16300 / 35967], [train loss 2.11435], [train acc 0.19479]\n",
      "[epoch 7], [iter 16400 / 35967], [train loss 2.11420], [train acc 0.19476]\n",
      "[epoch 7], [iter 16500 / 35967], [train loss 2.11402], [train acc 0.19479]\n",
      "[epoch 7], [iter 16600 / 35967], [train loss 2.11372], [train acc 0.19530]\n",
      "[epoch 7], [iter 16700 / 35967], [train loss 2.11337], [train acc 0.19587]\n",
      "[epoch 7], [iter 16800 / 35967], [train loss 2.11346], [train acc 0.19601]\n",
      "[epoch 7], [iter 16900 / 35967], [train loss 2.11383], [train acc 0.19568]\n",
      "[epoch 7], [iter 17000 / 35967], [train loss 2.11440], [train acc 0.19571]\n",
      "[epoch 7], [iter 17100 / 35967], [train loss 2.11434], [train acc 0.19579]\n",
      "[epoch 7], [iter 17200 / 35967], [train loss 2.11420], [train acc 0.19558]\n",
      "[epoch 7], [iter 17300 / 35967], [train loss 2.11415], [train acc 0.19561]\n",
      "[epoch 7], [iter 17400 / 35967], [train loss 2.11362], [train acc 0.19580]\n",
      "[epoch 7], [iter 17500 / 35967], [train loss 2.11394], [train acc 0.19543]\n",
      "[epoch 7], [iter 17600 / 35967], [train loss 2.11429], [train acc 0.19528]\n",
      "[epoch 7], [iter 17700 / 35967], [train loss 2.11417], [train acc 0.19537]\n",
      "[epoch 7], [iter 17800 / 35967], [train loss 2.11457], [train acc 0.19517]\n",
      "[epoch 7], [iter 17900 / 35967], [train loss 2.11526], [train acc 0.19475]\n",
      "[epoch 7], [iter 18000 / 35967], [train loss 2.11578], [train acc 0.19478]\n",
      "[epoch 7], [iter 18100 / 35967], [train loss 2.11638], [train acc 0.19470]\n",
      "[epoch 7], [iter 18200 / 35967], [train loss 2.11649], [train acc 0.19429]\n",
      "[epoch 7], [iter 18300 / 35967], [train loss 2.11645], [train acc 0.19464]\n",
      "[epoch 7], [iter 18400 / 35967], [train loss 2.11667], [train acc 0.19429]\n",
      "[epoch 7], [iter 18500 / 35967], [train loss 2.11625], [train acc 0.19432]\n",
      "[epoch 7], [iter 18600 / 35967], [train loss 2.11578], [train acc 0.19441]\n",
      "[epoch 7], [iter 18700 / 35967], [train loss 2.11564], [train acc 0.19449]\n",
      "[epoch 7], [iter 18800 / 35967], [train loss 2.11503], [train acc 0.19473]\n",
      "[epoch 7], [iter 18900 / 35967], [train loss 2.11464], [train acc 0.19471]\n",
      "[epoch 7], [iter 19000 / 35967], [train loss 2.11459], [train acc 0.19458]\n",
      "[epoch 7], [iter 19100 / 35967], [train loss 2.11500], [train acc 0.19435]\n",
      "[epoch 7], [iter 19200 / 35967], [train loss 2.11502], [train acc 0.19406]\n",
      "[epoch 7], [iter 19300 / 35967], [train loss 2.11462], [train acc 0.19425]\n",
      "[epoch 7], [iter 19400 / 35967], [train loss 2.11461], [train acc 0.19438]\n",
      "[epoch 7], [iter 19500 / 35967], [train loss 2.11471], [train acc 0.19446]\n",
      "[epoch 7], [iter 19600 / 35967], [train loss 2.11481], [train acc 0.19444]\n",
      "[epoch 7], [iter 19700 / 35967], [train loss 2.11558], [train acc 0.19406]\n",
      "[epoch 7], [iter 19800 / 35967], [train loss 2.11612], [train acc 0.19429]\n",
      "[epoch 7], [iter 19900 / 35967], [train loss 2.11642], [train acc 0.19427]\n",
      "[epoch 7], [iter 20000 / 35967], [train loss 2.11616], [train acc 0.19405]\n",
      "[epoch 7], [iter 20100 / 35967], [train loss 2.11582], [train acc 0.19398]\n",
      "[epoch 7], [iter 20200 / 35967], [train loss 2.11649], [train acc 0.19411]\n",
      "[epoch 7], [iter 20300 / 35967], [train loss 2.11643], [train acc 0.19409]\n",
      "[epoch 7], [iter 20400 / 35967], [train loss 2.11648], [train acc 0.19392]\n",
      "[epoch 7], [iter 20500 / 35967], [train loss 2.11682], [train acc 0.19385]\n",
      "[epoch 7], [iter 20600 / 35967], [train loss 2.11647], [train acc 0.19408]\n",
      "[epoch 7], [iter 20700 / 35967], [train loss 2.11662], [train acc 0.19391]\n",
      "[epoch 7], [iter 20800 / 35967], [train loss 2.11690], [train acc 0.19370]\n",
      "[epoch 7], [iter 20900 / 35967], [train loss 2.11660], [train acc 0.19359]\n",
      "[epoch 7], [iter 21000 / 35967], [train loss 2.11603], [train acc 0.19381]\n",
      "[epoch 7], [iter 21100 / 35967], [train loss 2.11615], [train acc 0.19379]\n",
      "[epoch 7], [iter 21200 / 35967], [train loss 2.11578], [train acc 0.19406]\n",
      "[epoch 7], [iter 21300 / 35967], [train loss 2.11619], [train acc 0.19408]\n",
      "[epoch 7], [iter 21400 / 35967], [train loss 2.11647], [train acc 0.19393]\n",
      "[epoch 7], [iter 21500 / 35967], [train loss 2.11632], [train acc 0.19358]\n",
      "[epoch 7], [iter 21600 / 35967], [train loss 2.11598], [train acc 0.19356]\n",
      "[epoch 7], [iter 21700 / 35967], [train loss 2.11515], [train acc 0.19396]\n",
      "[epoch 7], [iter 21800 / 35967], [train loss 2.11505], [train acc 0.19413]\n",
      "[epoch 7], [iter 21900 / 35967], [train loss 2.11473], [train acc 0.19402]\n",
      "[epoch 7], [iter 22000 / 35967], [train loss 2.11481], [train acc 0.19391]\n",
      "[epoch 7], [iter 22100 / 35967], [train loss 2.11551], [train acc 0.19371]\n",
      "[epoch 7], [iter 22200 / 35967], [train loss 2.11572], [train acc 0.19374]\n",
      "[epoch 7], [iter 22300 / 35967], [train loss 2.11597], [train acc 0.19363]\n",
      "[epoch 7], [iter 22400 / 35967], [train loss 2.11612], [train acc 0.19362]\n",
      "[epoch 7], [iter 22500 / 35967], [train loss 2.11621], [train acc 0.19356]\n",
      "[epoch 7], [iter 22600 / 35967], [train loss 2.11596], [train acc 0.19354]\n",
      "[epoch 7], [iter 22700 / 35967], [train loss 2.11647], [train acc 0.19335]\n",
      "[epoch 7], [iter 22800 / 35967], [train loss 2.11701], [train acc 0.19316]\n",
      "[epoch 7], [iter 22900 / 35967], [train loss 2.11708], [train acc 0.19323]\n",
      "[epoch 7], [iter 23000 / 35967], [train loss 2.11684], [train acc 0.19343]\n",
      "[epoch 7], [iter 23100 / 35967], [train loss 2.11634], [train acc 0.19351]\n",
      "[epoch 7], [iter 23200 / 35967], [train loss 2.11639], [train acc 0.19349]\n",
      "[epoch 7], [iter 23300 / 35967], [train loss 2.11568], [train acc 0.19361]\n",
      "[epoch 7], [iter 23400 / 35967], [train loss 2.11538], [train acc 0.19380]\n",
      "[epoch 7], [iter 23500 / 35967], [train loss 2.11489], [train acc 0.19400]\n",
      "[epoch 7], [iter 23600 / 35967], [train loss 2.11562], [train acc 0.19394]\n",
      "[epoch 7], [iter 23700 / 35967], [train loss 2.11539], [train acc 0.19392]\n",
      "[epoch 7], [iter 23800 / 35967], [train loss 2.11536], [train acc 0.19399]\n",
      "[epoch 7], [iter 23900 / 35967], [train loss 2.11527], [train acc 0.19393]\n",
      "[epoch 7], [iter 24000 / 35967], [train loss 2.11494], [train acc 0.19375]\n",
      "[epoch 7], [iter 24100 / 35967], [train loss 2.11485], [train acc 0.19398]\n",
      "[epoch 7], [iter 24200 / 35967], [train loss 2.11499], [train acc 0.19401]\n",
      "[epoch 7], [iter 24300 / 35967], [train loss 2.11531], [train acc 0.19391]\n",
      "[epoch 7], [iter 24400 / 35967], [train loss 2.11533], [train acc 0.19365]\n",
      "[epoch 7], [iter 24500 / 35967], [train loss 2.11465], [train acc 0.19380]\n",
      "[epoch 7], [iter 24600 / 35967], [train loss 2.11401], [train acc 0.19407]\n",
      "[epoch 7], [iter 24700 / 35967], [train loss 2.11375], [train acc 0.19437]\n",
      "[epoch 7], [iter 24800 / 35967], [train loss 2.11393], [train acc 0.19440]\n",
      "[epoch 7], [iter 24900 / 35967], [train loss 2.11399], [train acc 0.19438]\n",
      "[epoch 7], [iter 25000 / 35967], [train loss 2.11418], [train acc 0.19416]\n",
      "[epoch 7], [iter 25100 / 35967], [train loss 2.11451], [train acc 0.19410]\n",
      "[epoch 7], [iter 25200 / 35967], [train loss 2.11495], [train acc 0.19409]\n",
      "[epoch 7], [iter 25300 / 35967], [train loss 2.11473], [train acc 0.19427]\n",
      "[epoch 7], [iter 25400 / 35967], [train loss 2.11459], [train acc 0.19417]\n",
      "[epoch 7], [iter 25500 / 35967], [train loss 2.11424], [train acc 0.19404]\n",
      "[epoch 7], [iter 25600 / 35967], [train loss 2.11444], [train acc 0.19383]\n",
      "[epoch 7], [iter 25700 / 35967], [train loss 2.11443], [train acc 0.19377]\n",
      "[epoch 7], [iter 25800 / 35967], [train loss 2.11445], [train acc 0.19395]\n",
      "[epoch 7], [iter 25900 / 35967], [train loss 2.11482], [train acc 0.19398]\n",
      "[epoch 7], [iter 26000 / 35967], [train loss 2.11512], [train acc 0.19412]\n",
      "[epoch 7], [iter 26100 / 35967], [train loss 2.11488], [train acc 0.19425]\n",
      "[epoch 7], [iter 26200 / 35967], [train loss 2.11468], [train acc 0.19420]\n",
      "[epoch 7], [iter 26300 / 35967], [train loss 2.11455], [train acc 0.19433]\n",
      "[epoch 7], [iter 26400 / 35967], [train loss 2.11395], [train acc 0.19477]\n",
      "[epoch 7], [iter 26500 / 35967], [train loss 2.11402], [train acc 0.19468]\n",
      "[epoch 7], [iter 26600 / 35967], [train loss 2.11423], [train acc 0.19481]\n",
      "[epoch 7], [iter 26700 / 35967], [train loss 2.11461], [train acc 0.19479]\n",
      "[epoch 7], [iter 26800 / 35967], [train loss 2.11499], [train acc 0.19489]\n",
      "[epoch 7], [iter 26900 / 35967], [train loss 2.11525], [train acc 0.19498]\n",
      "[epoch 7], [iter 27000 / 35967], [train loss 2.11520], [train acc 0.19496]\n",
      "[epoch 7], [iter 27100 / 35967], [train loss 2.11550], [train acc 0.19494]\n",
      "[epoch 7], [iter 27200 / 35967], [train loss 2.11563], [train acc 0.19489]\n",
      "[epoch 7], [iter 27300 / 35967], [train loss 2.11524], [train acc 0.19502]\n",
      "[epoch 7], [iter 27400 / 35967], [train loss 2.11529], [train acc 0.19493]\n",
      "[epoch 7], [iter 27500 / 35967], [train loss 2.11540], [train acc 0.19476]\n",
      "[epoch 7], [iter 27600 / 35967], [train loss 2.11544], [train acc 0.19457]\n",
      "[epoch 7], [iter 27700 / 35967], [train loss 2.11525], [train acc 0.19469]\n",
      "[epoch 7], [iter 27800 / 35967], [train loss 2.11523], [train acc 0.19475]\n",
      "[epoch 7], [iter 27900 / 35967], [train loss 2.11523], [train acc 0.19477]\n",
      "[epoch 7], [iter 28000 / 35967], [train loss 2.11529], [train acc 0.19457]\n",
      "[epoch 7], [iter 28100 / 35967], [train loss 2.11550], [train acc 0.19445]\n",
      "[epoch 7], [iter 28200 / 35967], [train loss 2.11516], [train acc 0.19443]\n",
      "[epoch 7], [iter 28300 / 35967], [train loss 2.11490], [train acc 0.19435]\n",
      "[epoch 7], [iter 28400 / 35967], [train loss 2.11469], [train acc 0.19451]\n",
      "[epoch 7], [iter 28500 / 35967], [train loss 2.11483], [train acc 0.19446]\n",
      "[epoch 7], [iter 28600 / 35967], [train loss 2.11438], [train acc 0.19465]\n",
      "[epoch 7], [iter 28700 / 35967], [train loss 2.11444], [train acc 0.19467]\n",
      "[epoch 7], [iter 28800 / 35967], [train loss 2.11471], [train acc 0.19455]\n",
      "[epoch 7], [iter 28900 / 35967], [train loss 2.11540], [train acc 0.19436]\n",
      "[epoch 7], [iter 29000 / 35967], [train loss 2.11570], [train acc 0.19434]\n",
      "[epoch 7], [iter 29100 / 35967], [train loss 2.11585], [train acc 0.19412]\n",
      "[epoch 7], [iter 29200 / 35967], [train loss 2.11631], [train acc 0.19390]\n",
      "[epoch 7], [iter 29300 / 35967], [train loss 2.11645], [train acc 0.19382]\n",
      "[epoch 7], [iter 29400 / 35967], [train loss 2.11660], [train acc 0.19378]\n",
      "[epoch 7], [iter 29500 / 35967], [train loss 2.11654], [train acc 0.19397]\n",
      "[epoch 7], [iter 29600 / 35967], [train loss 2.11612], [train acc 0.19395]\n",
      "[epoch 7], [iter 29700 / 35967], [train loss 2.11632], [train acc 0.19397]\n",
      "[epoch 7], [iter 29800 / 35967], [train loss 2.11648], [train acc 0.19393]\n",
      "[epoch 7], [iter 29900 / 35967], [train loss 2.11661], [train acc 0.19388]\n",
      "[epoch 7], [iter 30000 / 35967], [train loss 2.11678], [train acc 0.19370]\n",
      "[epoch 7], [iter 30100 / 35967], [train loss 2.11695], [train acc 0.19352]\n",
      "[epoch 7], [iter 30200 / 35967], [train loss 2.11667], [train acc 0.19371]\n",
      "[epoch 7], [iter 30300 / 35967], [train loss 2.11661], [train acc 0.19366]\n",
      "[epoch 7], [iter 30400 / 35967], [train loss 2.11638], [train acc 0.19375]\n",
      "[epoch 7], [iter 30500 / 35967], [train loss 2.11618], [train acc 0.19387]\n",
      "[epoch 7], [iter 30600 / 35967], [train loss 2.11623], [train acc 0.19395]\n",
      "[epoch 7], [iter 30700 / 35967], [train loss 2.11620], [train acc 0.19404]\n",
      "[epoch 7], [iter 30800 / 35967], [train loss 2.11587], [train acc 0.19399]\n",
      "[epoch 7], [iter 30900 / 35967], [train loss 2.11559], [train acc 0.19405]\n",
      "[epoch 7], [iter 31000 / 35967], [train loss 2.11530], [train acc 0.19410]\n",
      "[epoch 7], [iter 31100 / 35967], [train loss 2.11552], [train acc 0.19415]\n",
      "[epoch 7], [iter 31200 / 35967], [train loss 2.11527], [train acc 0.19420]\n",
      "[epoch 7], [iter 31300 / 35967], [train loss 2.11528], [train acc 0.19422]\n",
      "[epoch 7], [iter 31400 / 35967], [train loss 2.11526], [train acc 0.19414]\n",
      "[epoch 7], [iter 31500 / 35967], [train loss 2.11514], [train acc 0.19416]\n",
      "[epoch 7], [iter 31600 / 35967], [train loss 2.11498], [train acc 0.19405]\n",
      "[epoch 7], [iter 31700 / 35967], [train loss 2.11483], [train acc 0.19432]\n",
      "[epoch 7], [iter 31800 / 35967], [train loss 2.11485], [train acc 0.19440]\n",
      "[epoch 7], [iter 31900 / 35967], [train loss 2.11479], [train acc 0.19448]\n",
      "[epoch 7], [iter 32000 / 35967], [train loss 2.11505], [train acc 0.19447]\n",
      "[epoch 7], [iter 32100 / 35967], [train loss 2.11456], [train acc 0.19458]\n",
      "[epoch 7], [iter 32200 / 35967], [train loss 2.11443], [train acc 0.19453]\n",
      "[epoch 7], [iter 32300 / 35967], [train loss 2.11438], [train acc 0.19474]\n",
      "[epoch 7], [iter 32400 / 35967], [train loss 2.11376], [train acc 0.19488]\n",
      "[epoch 7], [iter 32500 / 35967], [train loss 2.11408], [train acc 0.19474]\n",
      "[epoch 7], [iter 32600 / 35967], [train loss 2.11408], [train acc 0.19475]\n",
      "[epoch 7], [iter 32700 / 35967], [train loss 2.11432], [train acc 0.19462]\n",
      "[epoch 7], [iter 32800 / 35967], [train loss 2.11427], [train acc 0.19454]\n",
      "[epoch 7], [iter 32900 / 35967], [train loss 2.11436], [train acc 0.19456]\n",
      "[epoch 7], [iter 33000 / 35967], [train loss 2.11422], [train acc 0.19448]\n",
      "[epoch 7], [iter 33100 / 35967], [train loss 2.11419], [train acc 0.19444]\n",
      "[epoch 7], [iter 33200 / 35967], [train loss 2.11433], [train acc 0.19443]\n",
      "[epoch 7], [iter 33300 / 35967], [train loss 2.11427], [train acc 0.19456]\n",
      "[epoch 7], [iter 33400 / 35967], [train loss 2.11417], [train acc 0.19473]\n",
      "[epoch 7], [iter 33500 / 35967], [train loss 2.11432], [train acc 0.19448]\n",
      "[epoch 7], [iter 33600 / 35967], [train loss 2.11399], [train acc 0.19464]\n",
      "[epoch 7], [iter 33700 / 35967], [train loss 2.11373], [train acc 0.19466]\n",
      "[epoch 7], [iter 33800 / 35967], [train loss 2.11369], [train acc 0.19476]\n",
      "[epoch 7], [iter 33900 / 35967], [train loss 2.11376], [train acc 0.19493]\n",
      "[epoch 7], [iter 34000 / 35967], [train loss 2.11366], [train acc 0.19488]\n",
      "[epoch 7], [iter 34100 / 35967], [train loss 2.11342], [train acc 0.19501]\n",
      "[epoch 7], [iter 34200 / 35967], [train loss 2.11368], [train acc 0.19491]\n",
      "[epoch 7], [iter 34300 / 35967], [train loss 2.11339], [train acc 0.19510]\n",
      "[epoch 7], [iter 34400 / 35967], [train loss 2.11343], [train acc 0.19520]\n",
      "[epoch 7], [iter 34500 / 35967], [train loss 2.11348], [train acc 0.19525]\n",
      "[epoch 7], [iter 34600 / 35967], [train loss 2.11377], [train acc 0.19538]\n",
      "[epoch 7], [iter 34700 / 35967], [train loss 2.11426], [train acc 0.19539]\n",
      "[epoch 7], [iter 34800 / 35967], [train loss 2.11406], [train acc 0.19537]\n",
      "[epoch 7], [iter 34900 / 35967], [train loss 2.11408], [train acc 0.19530]\n",
      "[epoch 7], [iter 35000 / 35967], [train loss 2.11421], [train acc 0.19534]\n",
      "[epoch 7], [iter 35100 / 35967], [train loss 2.11408], [train acc 0.19538]\n",
      "[epoch 7], [iter 35200 / 35967], [train loss 2.11387], [train acc 0.19534]\n",
      "[epoch 7], [iter 35300 / 35967], [train loss 2.11373], [train acc 0.19524]\n",
      "[epoch 7], [iter 35400 / 35967], [train loss 2.11360], [train acc 0.19537]\n",
      "[epoch 7], [iter 35500 / 35967], [train loss 2.11380], [train acc 0.19538]\n",
      "[epoch 7], [iter 35600 / 35967], [train loss 2.11351], [train acc 0.19553]\n",
      "[epoch 7], [iter 35700 / 35967], [train loss 2.11332], [train acc 0.19560]\n",
      "[epoch 7], [iter 35800 / 35967], [train loss 2.11349], [train acc 0.19556]\n",
      "[epoch 7], [iter 35900 / 35967], [train loss 2.11315], [train acc 0.19549]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 9.31639], [val acc 0.08704]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [iter 100 / 35967], [train loss 2.04156], [train acc 0.19000]\n",
      "[epoch 8], [iter 200 / 35967], [train loss 2.11730], [train acc 0.18500]\n",
      "[epoch 8], [iter 300 / 35967], [train loss 2.10692], [train acc 0.17667]\n",
      "[epoch 8], [iter 400 / 35967], [train loss 2.10318], [train acc 0.19000]\n",
      "[epoch 8], [iter 500 / 35967], [train loss 2.10679], [train acc 0.17400]\n",
      "[epoch 8], [iter 600 / 35967], [train loss 2.08821], [train acc 0.18167]\n",
      "[epoch 8], [iter 700 / 35967], [train loss 2.10762], [train acc 0.18143]\n",
      "[epoch 8], [iter 800 / 35967], [train loss 2.10642], [train acc 0.18250]\n",
      "[epoch 8], [iter 900 / 35967], [train loss 2.09179], [train acc 0.19889]\n",
      "[epoch 8], [iter 1000 / 35967], [train loss 2.08240], [train acc 0.20200]\n",
      "[epoch 8], [iter 1100 / 35967], [train loss 2.09007], [train acc 0.19818]\n",
      "[epoch 8], [iter 1200 / 35967], [train loss 2.09097], [train acc 0.20500]\n",
      "[epoch 8], [iter 1300 / 35967], [train loss 2.09324], [train acc 0.20615]\n",
      "[epoch 8], [iter 1400 / 35967], [train loss 2.08736], [train acc 0.21071]\n",
      "[epoch 8], [iter 1500 / 35967], [train loss 2.08730], [train acc 0.20933]\n",
      "[epoch 8], [iter 1600 / 35967], [train loss 2.08757], [train acc 0.20688]\n",
      "[epoch 8], [iter 1700 / 35967], [train loss 2.08754], [train acc 0.20765]\n",
      "[epoch 8], [iter 1800 / 35967], [train loss 2.08958], [train acc 0.20556]\n",
      "[epoch 8], [iter 1900 / 35967], [train loss 2.09405], [train acc 0.20368]\n",
      "[epoch 8], [iter 2000 / 35967], [train loss 2.09512], [train acc 0.20100]\n",
      "[epoch 8], [iter 2100 / 35967], [train loss 2.09521], [train acc 0.20143]\n",
      "[epoch 8], [iter 2200 / 35967], [train loss 2.09542], [train acc 0.20182]\n",
      "[epoch 8], [iter 2300 / 35967], [train loss 2.09888], [train acc 0.19957]\n",
      "[epoch 8], [iter 2400 / 35967], [train loss 2.09423], [train acc 0.20292]\n",
      "[epoch 8], [iter 2500 / 35967], [train loss 2.09264], [train acc 0.20160]\n",
      "[epoch 8], [iter 2600 / 35967], [train loss 2.09425], [train acc 0.20269]\n",
      "[epoch 8], [iter 2700 / 35967], [train loss 2.09235], [train acc 0.20259]\n",
      "[epoch 8], [iter 2800 / 35967], [train loss 2.09210], [train acc 0.20429]\n",
      "[epoch 8], [iter 2900 / 35967], [train loss 2.08970], [train acc 0.20345]\n",
      "[epoch 8], [iter 3000 / 35967], [train loss 2.09281], [train acc 0.20200]\n",
      "[epoch 8], [iter 3100 / 35967], [train loss 2.09413], [train acc 0.19935]\n",
      "[epoch 8], [iter 3200 / 35967], [train loss 2.09523], [train acc 0.19687]\n",
      "[epoch 8], [iter 3300 / 35967], [train loss 2.09236], [train acc 0.19758]\n",
      "[epoch 8], [iter 3400 / 35967], [train loss 2.09435], [train acc 0.19676]\n",
      "[epoch 8], [iter 3500 / 35967], [train loss 2.09098], [train acc 0.19771]\n",
      "[epoch 8], [iter 3600 / 35967], [train loss 2.09331], [train acc 0.19722]\n",
      "[epoch 8], [iter 3700 / 35967], [train loss 2.09162], [train acc 0.19757]\n",
      "[epoch 8], [iter 3800 / 35967], [train loss 2.09090], [train acc 0.19500]\n",
      "[epoch 8], [iter 3900 / 35967], [train loss 2.09209], [train acc 0.19410]\n",
      "[epoch 8], [iter 4000 / 35967], [train loss 2.09391], [train acc 0.19400]\n",
      "[epoch 8], [iter 4100 / 35967], [train loss 2.09320], [train acc 0.19415]\n",
      "[epoch 8], [iter 4200 / 35967], [train loss 2.09364], [train acc 0.19476]\n",
      "[epoch 8], [iter 4300 / 35967], [train loss 2.09450], [train acc 0.19442]\n",
      "[epoch 8], [iter 4400 / 35967], [train loss 2.09235], [train acc 0.19591]\n",
      "[epoch 8], [iter 4500 / 35967], [train loss 2.09018], [train acc 0.19667]\n",
      "[epoch 8], [iter 4600 / 35967], [train loss 2.09345], [train acc 0.19674]\n",
      "[epoch 8], [iter 4700 / 35967], [train loss 2.09174], [train acc 0.19660]\n",
      "[epoch 8], [iter 4800 / 35967], [train loss 2.09303], [train acc 0.19687]\n",
      "[epoch 8], [iter 4900 / 35967], [train loss 2.09191], [train acc 0.19653]\n",
      "[epoch 8], [iter 5000 / 35967], [train loss 2.09192], [train acc 0.19560]\n",
      "[epoch 8], [iter 5100 / 35967], [train loss 2.09147], [train acc 0.19627]\n",
      "[epoch 8], [iter 5200 / 35967], [train loss 2.09011], [train acc 0.19692]\n",
      "[epoch 8], [iter 5300 / 35967], [train loss 2.09109], [train acc 0.19585]\n",
      "[epoch 8], [iter 5400 / 35967], [train loss 2.09236], [train acc 0.19630]\n",
      "[epoch 8], [iter 5500 / 35967], [train loss 2.08932], [train acc 0.19709]\n",
      "[epoch 8], [iter 5600 / 35967], [train loss 2.09147], [train acc 0.19661]\n",
      "[epoch 8], [iter 5700 / 35967], [train loss 2.09419], [train acc 0.19596]\n",
      "[epoch 8], [iter 5800 / 35967], [train loss 2.09302], [train acc 0.19741]\n",
      "[epoch 8], [iter 5900 / 35967], [train loss 2.09626], [train acc 0.19763]\n",
      "[epoch 8], [iter 6000 / 35967], [train loss 2.09639], [train acc 0.19783]\n",
      "[epoch 8], [iter 6100 / 35967], [train loss 2.09761], [train acc 0.19787]\n",
      "[epoch 8], [iter 6200 / 35967], [train loss 2.09658], [train acc 0.19839]\n",
      "[epoch 8], [iter 6300 / 35967], [train loss 2.09729], [train acc 0.19841]\n",
      "[epoch 8], [iter 6400 / 35967], [train loss 2.09926], [train acc 0.19797]\n",
      "[epoch 8], [iter 6500 / 35967], [train loss 2.09619], [train acc 0.19969]\n",
      "[epoch 8], [iter 6600 / 35967], [train loss 2.09578], [train acc 0.20076]\n",
      "[epoch 8], [iter 6700 / 35967], [train loss 2.09684], [train acc 0.20045]\n",
      "[epoch 8], [iter 6800 / 35967], [train loss 2.09688], [train acc 0.19985]\n",
      "[epoch 8], [iter 6900 / 35967], [train loss 2.09476], [train acc 0.19957]\n",
      "[epoch 8], [iter 7000 / 35967], [train loss 2.09615], [train acc 0.19914]\n",
      "[epoch 8], [iter 7100 / 35967], [train loss 2.09793], [train acc 0.19887]\n",
      "[epoch 8], [iter 7200 / 35967], [train loss 2.09694], [train acc 0.19972]\n",
      "[epoch 8], [iter 7300 / 35967], [train loss 2.09618], [train acc 0.19945]\n",
      "[epoch 8], [iter 7400 / 35967], [train loss 2.09874], [train acc 0.19973]\n",
      "[epoch 8], [iter 7500 / 35967], [train loss 2.09943], [train acc 0.19960]\n",
      "[epoch 8], [iter 7600 / 35967], [train loss 2.09962], [train acc 0.20013]\n",
      "[epoch 8], [iter 7700 / 35967], [train loss 2.09998], [train acc 0.19935]\n",
      "[epoch 8], [iter 7800 / 35967], [train loss 2.10319], [train acc 0.19885]\n",
      "[epoch 8], [iter 7900 / 35967], [train loss 2.10210], [train acc 0.19962]\n",
      "[epoch 8], [iter 8000 / 35967], [train loss 2.10259], [train acc 0.19937]\n",
      "[epoch 8], [iter 8100 / 35967], [train loss 2.10331], [train acc 0.19889]\n",
      "[epoch 8], [iter 8200 / 35967], [train loss 2.10578], [train acc 0.19829]\n",
      "[epoch 8], [iter 8300 / 35967], [train loss 2.10589], [train acc 0.19880]\n",
      "[epoch 8], [iter 8400 / 35967], [train loss 2.10541], [train acc 0.19857]\n",
      "[epoch 8], [iter 8500 / 35967], [train loss 2.10544], [train acc 0.19859]\n",
      "[epoch 8], [iter 8600 / 35967], [train loss 2.10604], [train acc 0.19802]\n",
      "[epoch 8], [iter 8700 / 35967], [train loss 2.10543], [train acc 0.19816]\n",
      "[epoch 8], [iter 8800 / 35967], [train loss 2.10564], [train acc 0.19795]\n",
      "[epoch 8], [iter 8900 / 35967], [train loss 2.10472], [train acc 0.19865]\n",
      "[epoch 8], [iter 9000 / 35967], [train loss 2.10324], [train acc 0.19867]\n",
      "[epoch 8], [iter 9100 / 35967], [train loss 2.10502], [train acc 0.19824]\n",
      "[epoch 8], [iter 9200 / 35967], [train loss 2.10556], [train acc 0.19815]\n",
      "[epoch 8], [iter 9300 / 35967], [train loss 2.10600], [train acc 0.19828]\n",
      "[epoch 8], [iter 9400 / 35967], [train loss 2.10614], [train acc 0.19819]\n",
      "[epoch 8], [iter 9500 / 35967], [train loss 2.10567], [train acc 0.19853]\n",
      "[epoch 8], [iter 9600 / 35967], [train loss 2.10522], [train acc 0.19844]\n",
      "[epoch 8], [iter 9700 / 35967], [train loss 2.10485], [train acc 0.19897]\n",
      "[epoch 8], [iter 9800 / 35967], [train loss 2.10454], [train acc 0.19908]\n",
      "[epoch 8], [iter 9900 / 35967], [train loss 2.10590], [train acc 0.19859]\n",
      "[epoch 8], [iter 10000 / 35967], [train loss 2.10539], [train acc 0.19880]\n",
      "[epoch 8], [iter 10100 / 35967], [train loss 2.10589], [train acc 0.19861]\n",
      "[epoch 8], [iter 10200 / 35967], [train loss 2.10573], [train acc 0.19882]\n",
      "[epoch 8], [iter 10300 / 35967], [train loss 2.10600], [train acc 0.19825]\n",
      "[epoch 8], [iter 10400 / 35967], [train loss 2.10626], [train acc 0.19846]\n",
      "[epoch 8], [iter 10500 / 35967], [train loss 2.10590], [train acc 0.19838]\n",
      "[epoch 8], [iter 10600 / 35967], [train loss 2.10536], [train acc 0.19877]\n",
      "[epoch 8], [iter 10700 / 35967], [train loss 2.10595], [train acc 0.19879]\n",
      "[epoch 8], [iter 10800 / 35967], [train loss 2.10690], [train acc 0.19843]\n",
      "[epoch 8], [iter 10900 / 35967], [train loss 2.10633], [train acc 0.19853]\n",
      "[epoch 8], [iter 11000 / 35967], [train loss 2.10661], [train acc 0.19873]\n",
      "[epoch 8], [iter 11100 / 35967], [train loss 2.10584], [train acc 0.19856]\n",
      "[epoch 8], [iter 11200 / 35967], [train loss 2.10463], [train acc 0.19893]\n",
      "[epoch 8], [iter 11300 / 35967], [train loss 2.10363], [train acc 0.19947]\n",
      "[epoch 8], [iter 11400 / 35967], [train loss 2.10408], [train acc 0.19956]\n",
      "[epoch 8], [iter 11500 / 35967], [train loss 2.10445], [train acc 0.19913]\n",
      "[epoch 8], [iter 11600 / 35967], [train loss 2.10346], [train acc 0.19966]\n",
      "[epoch 8], [iter 11700 / 35967], [train loss 2.10337], [train acc 0.19949]\n",
      "[epoch 8], [iter 11800 / 35967], [train loss 2.10399], [train acc 0.19966]\n",
      "[epoch 8], [iter 11900 / 35967], [train loss 2.10339], [train acc 0.20000]\n",
      "[epoch 8], [iter 12000 / 35967], [train loss 2.10292], [train acc 0.20025]\n",
      "[epoch 8], [iter 12100 / 35967], [train loss 2.10209], [train acc 0.20041]\n",
      "[epoch 8], [iter 12200 / 35967], [train loss 2.10149], [train acc 0.20082]\n",
      "[epoch 8], [iter 12300 / 35967], [train loss 2.10180], [train acc 0.20057]\n",
      "[epoch 8], [iter 12400 / 35967], [train loss 2.10270], [train acc 0.20032]\n",
      "[epoch 8], [iter 12500 / 35967], [train loss 2.10271], [train acc 0.20000]\n",
      "[epoch 8], [iter 12600 / 35967], [train loss 2.10346], [train acc 0.20008]\n",
      "[epoch 8], [iter 12700 / 35967], [train loss 2.10339], [train acc 0.20031]\n",
      "[epoch 8], [iter 12800 / 35967], [train loss 2.10392], [train acc 0.20047]\n",
      "[epoch 8], [iter 12900 / 35967], [train loss 2.10422], [train acc 0.20016]\n",
      "[epoch 8], [iter 13000 / 35967], [train loss 2.10458], [train acc 0.19954]\n",
      "[epoch 8], [iter 13100 / 35967], [train loss 2.10470], [train acc 0.19947]\n",
      "[epoch 8], [iter 13200 / 35967], [train loss 2.10375], [train acc 0.19962]\n",
      "[epoch 8], [iter 13300 / 35967], [train loss 2.10423], [train acc 0.19947]\n",
      "[epoch 8], [iter 13400 / 35967], [train loss 2.10414], [train acc 0.19940]\n",
      "[epoch 8], [iter 13500 / 35967], [train loss 2.10496], [train acc 0.19948]\n",
      "[epoch 8], [iter 13600 / 35967], [train loss 2.10520], [train acc 0.19919]\n",
      "[epoch 8], [iter 13700 / 35967], [train loss 2.10516], [train acc 0.19942]\n",
      "[epoch 8], [iter 13800 / 35967], [train loss 2.10428], [train acc 0.19971]\n",
      "[epoch 8], [iter 13900 / 35967], [train loss 2.10465], [train acc 0.19935]\n",
      "[epoch 8], [iter 14000 / 35967], [train loss 2.10413], [train acc 0.19971]\n",
      "[epoch 8], [iter 14100 / 35967], [train loss 2.10471], [train acc 0.19943]\n",
      "[epoch 8], [iter 14200 / 35967], [train loss 2.10481], [train acc 0.19908]\n",
      "[epoch 8], [iter 14300 / 35967], [train loss 2.10451], [train acc 0.19937]\n",
      "[epoch 8], [iter 14400 / 35967], [train loss 2.10454], [train acc 0.19951]\n",
      "[epoch 8], [iter 14500 / 35967], [train loss 2.10545], [train acc 0.19938]\n",
      "[epoch 8], [iter 14600 / 35967], [train loss 2.10535], [train acc 0.19884]\n",
      "[epoch 8], [iter 14700 / 35967], [train loss 2.10522], [train acc 0.19891]\n",
      "[epoch 8], [iter 14800 / 35967], [train loss 2.10584], [train acc 0.19878]\n",
      "[epoch 8], [iter 14900 / 35967], [train loss 2.10553], [train acc 0.19886]\n",
      "[epoch 8], [iter 15000 / 35967], [train loss 2.10604], [train acc 0.19860]\n",
      "[epoch 8], [iter 15100 / 35967], [train loss 2.10618], [train acc 0.19841]\n",
      "[epoch 8], [iter 15200 / 35967], [train loss 2.10650], [train acc 0.19862]\n",
      "[epoch 8], [iter 15300 / 35967], [train loss 2.10689], [train acc 0.19830]\n",
      "[epoch 8], [iter 15400 / 35967], [train loss 2.10652], [train acc 0.19864]\n",
      "[epoch 8], [iter 15500 / 35967], [train loss 2.10629], [train acc 0.19858]\n",
      "[epoch 8], [iter 15600 / 35967], [train loss 2.10636], [train acc 0.19878]\n",
      "[epoch 8], [iter 15700 / 35967], [train loss 2.10610], [train acc 0.19879]\n",
      "[epoch 8], [iter 15800 / 35967], [train loss 2.10600], [train acc 0.19861]\n",
      "[epoch 8], [iter 15900 / 35967], [train loss 2.10579], [train acc 0.19868]\n",
      "[epoch 8], [iter 16000 / 35967], [train loss 2.10608], [train acc 0.19831]\n",
      "[epoch 8], [iter 16100 / 35967], [train loss 2.10537], [train acc 0.19832]\n",
      "[epoch 8], [iter 16200 / 35967], [train loss 2.10573], [train acc 0.19821]\n",
      "[epoch 8], [iter 16300 / 35967], [train loss 2.10609], [train acc 0.19853]\n",
      "[epoch 8], [iter 16400 / 35967], [train loss 2.10584], [train acc 0.19902]\n",
      "[epoch 8], [iter 16500 / 35967], [train loss 2.10609], [train acc 0.19885]\n",
      "[epoch 8], [iter 16600 / 35967], [train loss 2.10672], [train acc 0.19880]\n",
      "[epoch 8], [iter 16700 / 35967], [train loss 2.10637], [train acc 0.19874]\n",
      "[epoch 8], [iter 16800 / 35967], [train loss 2.10589], [train acc 0.19875]\n",
      "[epoch 8], [iter 16900 / 35967], [train loss 2.10544], [train acc 0.19864]\n",
      "[epoch 8], [iter 17000 / 35967], [train loss 2.10526], [train acc 0.19882]\n",
      "[epoch 8], [iter 17100 / 35967], [train loss 2.10562], [train acc 0.19854]\n",
      "[epoch 8], [iter 17200 / 35967], [train loss 2.10557], [train acc 0.19890]\n",
      "[epoch 8], [iter 17300 / 35967], [train loss 2.10480], [train acc 0.19925]\n",
      "[epoch 8], [iter 17400 / 35967], [train loss 2.10498], [train acc 0.19908]\n",
      "[epoch 8], [iter 17500 / 35967], [train loss 2.10496], [train acc 0.19920]\n",
      "[epoch 8], [iter 17600 / 35967], [train loss 2.10438], [train acc 0.19949]\n",
      "[epoch 8], [iter 17700 / 35967], [train loss 2.10436], [train acc 0.19927]\n",
      "[epoch 8], [iter 17800 / 35967], [train loss 2.10442], [train acc 0.19927]\n",
      "[epoch 8], [iter 17900 / 35967], [train loss 2.10378], [train acc 0.19933]\n",
      "[epoch 8], [iter 18000 / 35967], [train loss 2.10362], [train acc 0.19917]\n",
      "[epoch 8], [iter 18100 / 35967], [train loss 2.10319], [train acc 0.19956]\n",
      "[epoch 8], [iter 18200 / 35967], [train loss 2.10315], [train acc 0.19989]\n",
      "[epoch 8], [iter 18300 / 35967], [train loss 2.10353], [train acc 0.19989]\n",
      "[epoch 8], [iter 18400 / 35967], [train loss 2.10362], [train acc 0.19995]\n",
      "[epoch 8], [iter 18500 / 35967], [train loss 2.10354], [train acc 0.19962]\n",
      "[epoch 8], [iter 18600 / 35967], [train loss 2.10342], [train acc 0.19989]\n",
      "[epoch 8], [iter 18700 / 35967], [train loss 2.10374], [train acc 0.19984]\n",
      "[epoch 8], [iter 18800 / 35967], [train loss 2.10347], [train acc 0.19968]\n",
      "[epoch 8], [iter 18900 / 35967], [train loss 2.10359], [train acc 0.19958]\n",
      "[epoch 8], [iter 19000 / 35967], [train loss 2.10460], [train acc 0.19958]\n",
      "[epoch 8], [iter 19100 / 35967], [train loss 2.10420], [train acc 0.19974]\n",
      "[epoch 8], [iter 19200 / 35967], [train loss 2.10480], [train acc 0.19958]\n",
      "[epoch 8], [iter 19300 / 35967], [train loss 2.10457], [train acc 0.19969]\n",
      "[epoch 8], [iter 19400 / 35967], [train loss 2.10491], [train acc 0.19969]\n",
      "[epoch 8], [iter 19500 / 35967], [train loss 2.10546], [train acc 0.19969]\n",
      "[epoch 8], [iter 19600 / 35967], [train loss 2.10528], [train acc 0.19974]\n",
      "[epoch 8], [iter 19700 / 35967], [train loss 2.10472], [train acc 0.19980]\n",
      "[epoch 8], [iter 19800 / 35967], [train loss 2.10496], [train acc 0.19980]\n",
      "[epoch 8], [iter 19900 / 35967], [train loss 2.10514], [train acc 0.19980]\n",
      "[epoch 8], [iter 20000 / 35967], [train loss 2.10539], [train acc 0.19960]\n",
      "[epoch 8], [iter 20100 / 35967], [train loss 2.10528], [train acc 0.19955]\n",
      "[epoch 8], [iter 20200 / 35967], [train loss 2.10503], [train acc 0.19985]\n",
      "[epoch 8], [iter 20300 / 35967], [train loss 2.10485], [train acc 0.19990]\n",
      "[epoch 8], [iter 20400 / 35967], [train loss 2.10457], [train acc 0.19995]\n",
      "[epoch 8], [iter 20500 / 35967], [train loss 2.10446], [train acc 0.20015]\n",
      "[epoch 8], [iter 20600 / 35967], [train loss 2.10438], [train acc 0.20039]\n",
      "[epoch 8], [iter 20700 / 35967], [train loss 2.10501], [train acc 0.20043]\n",
      "[epoch 8], [iter 20800 / 35967], [train loss 2.10456], [train acc 0.20058]\n",
      "[epoch 8], [iter 20900 / 35967], [train loss 2.10475], [train acc 0.20057]\n",
      "[epoch 8], [iter 21000 / 35967], [train loss 2.10538], [train acc 0.20043]\n",
      "[epoch 8], [iter 21100 / 35967], [train loss 2.10548], [train acc 0.20024]\n",
      "[epoch 8], [iter 21200 / 35967], [train loss 2.10512], [train acc 0.20061]\n",
      "[epoch 8], [iter 21300 / 35967], [train loss 2.10542], [train acc 0.20075]\n",
      "[epoch 8], [iter 21400 / 35967], [train loss 2.10497], [train acc 0.20084]\n",
      "[epoch 8], [iter 21500 / 35967], [train loss 2.10488], [train acc 0.20042]\n",
      "[epoch 8], [iter 21600 / 35967], [train loss 2.10501], [train acc 0.20051]\n",
      "[epoch 8], [iter 21700 / 35967], [train loss 2.10546], [train acc 0.20028]\n",
      "[epoch 8], [iter 21800 / 35967], [train loss 2.10556], [train acc 0.20014]\n",
      "[epoch 8], [iter 21900 / 35967], [train loss 2.10518], [train acc 0.20009]\n",
      "[epoch 8], [iter 22000 / 35967], [train loss 2.10506], [train acc 0.19991]\n",
      "[epoch 8], [iter 22100 / 35967], [train loss 2.10428], [train acc 0.20027]\n",
      "[epoch 8], [iter 22200 / 35967], [train loss 2.10466], [train acc 0.20000]\n",
      "[epoch 8], [iter 22300 / 35967], [train loss 2.10441], [train acc 0.19987]\n",
      "[epoch 8], [iter 22400 / 35967], [train loss 2.10419], [train acc 0.19982]\n",
      "[epoch 8], [iter 22500 / 35967], [train loss 2.10376], [train acc 0.20000]\n",
      "[epoch 8], [iter 22600 / 35967], [train loss 2.10339], [train acc 0.19996]\n",
      "[epoch 8], [iter 22700 / 35967], [train loss 2.10306], [train acc 0.20009]\n",
      "[epoch 8], [iter 22800 / 35967], [train loss 2.10258], [train acc 0.20018]\n",
      "[epoch 8], [iter 22900 / 35967], [train loss 2.10257], [train acc 0.20026]\n",
      "[epoch 8], [iter 23000 / 35967], [train loss 2.10308], [train acc 0.20009]\n",
      "[epoch 8], [iter 23100 / 35967], [train loss 2.10284], [train acc 0.20017]\n",
      "[epoch 8], [iter 23200 / 35967], [train loss 2.10235], [train acc 0.20039]\n",
      "[epoch 8], [iter 23300 / 35967], [train loss 2.10252], [train acc 0.20043]\n",
      "[epoch 8], [iter 23400 / 35967], [train loss 2.10201], [train acc 0.20043]\n",
      "[epoch 8], [iter 23500 / 35967], [train loss 2.10213], [train acc 0.20038]\n",
      "[epoch 8], [iter 23600 / 35967], [train loss 2.10221], [train acc 0.20038]\n",
      "[epoch 8], [iter 23700 / 35967], [train loss 2.10193], [train acc 0.20072]\n",
      "[epoch 8], [iter 23800 / 35967], [train loss 2.10141], [train acc 0.20092]\n",
      "[epoch 8], [iter 23900 / 35967], [train loss 2.10140], [train acc 0.20105]\n",
      "[epoch 8], [iter 24000 / 35967], [train loss 2.10090], [train acc 0.20112]\n",
      "[epoch 8], [iter 24100 / 35967], [train loss 2.10062], [train acc 0.20108]\n",
      "[epoch 8], [iter 24200 / 35967], [train loss 2.10083], [train acc 0.20099]\n",
      "[epoch 8], [iter 24300 / 35967], [train loss 2.10100], [train acc 0.20074]\n",
      "[epoch 8], [iter 24400 / 35967], [train loss 2.10058], [train acc 0.20094]\n",
      "[epoch 8], [iter 24500 / 35967], [train loss 2.10063], [train acc 0.20110]\n",
      "[epoch 8], [iter 24600 / 35967], [train loss 2.10058], [train acc 0.20106]\n",
      "[epoch 8], [iter 24700 / 35967], [train loss 2.10024], [train acc 0.20134]\n",
      "[epoch 8], [iter 24800 / 35967], [train loss 2.10027], [train acc 0.20129]\n",
      "[epoch 8], [iter 24900 / 35967], [train loss 2.10070], [train acc 0.20104]\n",
      "[epoch 8], [iter 25000 / 35967], [train loss 2.10071], [train acc 0.20124]\n",
      "[epoch 8], [iter 25100 / 35967], [train loss 2.10077], [train acc 0.20135]\n",
      "[epoch 8], [iter 25200 / 35967], [train loss 2.10107], [train acc 0.20127]\n",
      "[epoch 8], [iter 25300 / 35967], [train loss 2.10124], [train acc 0.20126]\n",
      "[epoch 8], [iter 25400 / 35967], [train loss 2.10138], [train acc 0.20130]\n",
      "[epoch 8], [iter 25500 / 35967], [train loss 2.10106], [train acc 0.20122]\n",
      "[epoch 8], [iter 25600 / 35967], [train loss 2.10083], [train acc 0.20117]\n",
      "[epoch 8], [iter 25700 / 35967], [train loss 2.10077], [train acc 0.20109]\n",
      "[epoch 8], [iter 25800 / 35967], [train loss 2.10046], [train acc 0.20097]\n",
      "[epoch 8], [iter 25900 / 35967], [train loss 2.10076], [train acc 0.20097]\n",
      "[epoch 8], [iter 26000 / 35967], [train loss 2.10081], [train acc 0.20081]\n",
      "[epoch 8], [iter 26100 / 35967], [train loss 2.10115], [train acc 0.20046]\n",
      "[epoch 8], [iter 26200 / 35967], [train loss 2.10128], [train acc 0.20015]\n",
      "[epoch 8], [iter 26300 / 35967], [train loss 2.10118], [train acc 0.20034]\n",
      "[epoch 8], [iter 26400 / 35967], [train loss 2.10090], [train acc 0.20023]\n",
      "[epoch 8], [iter 26500 / 35967], [train loss 2.10096], [train acc 0.20030]\n",
      "[epoch 8], [iter 26600 / 35967], [train loss 2.10083], [train acc 0.20041]\n",
      "[epoch 8], [iter 26700 / 35967], [train loss 2.10107], [train acc 0.20060]\n",
      "[epoch 8], [iter 26800 / 35967], [train loss 2.10060], [train acc 0.20071]\n",
      "[epoch 8], [iter 26900 / 35967], [train loss 2.10030], [train acc 0.20089]\n",
      "[epoch 8], [iter 27000 / 35967], [train loss 2.10047], [train acc 0.20081]\n",
      "[epoch 8], [iter 27100 / 35967], [train loss 2.10054], [train acc 0.20070]\n",
      "[epoch 8], [iter 27200 / 35967], [train loss 2.10041], [train acc 0.20066]\n",
      "[epoch 8], [iter 27300 / 35967], [train loss 2.10069], [train acc 0.20026]\n",
      "[epoch 8], [iter 27400 / 35967], [train loss 2.10038], [train acc 0.20015]\n",
      "[epoch 8], [iter 27500 / 35967], [train loss 2.10045], [train acc 0.20025]\n",
      "[epoch 8], [iter 27600 / 35967], [train loss 2.10073], [train acc 0.20014]\n",
      "[epoch 8], [iter 27700 / 35967], [train loss 2.10065], [train acc 0.20011]\n",
      "[epoch 8], [iter 27800 / 35967], [train loss 2.10051], [train acc 0.20007]\n",
      "[epoch 8], [iter 27900 / 35967], [train loss 2.10070], [train acc 0.19996]\n",
      "[epoch 8], [iter 28000 / 35967], [train loss 2.10080], [train acc 0.20007]\n",
      "[epoch 8], [iter 28100 / 35967], [train loss 2.10098], [train acc 0.20011]\n",
      "[epoch 8], [iter 28200 / 35967], [train loss 2.10048], [train acc 0.20007]\n",
      "[epoch 8], [iter 28300 / 35967], [train loss 2.10055], [train acc 0.19989]\n",
      "[epoch 8], [iter 28400 / 35967], [train loss 2.10065], [train acc 0.19972]\n",
      "[epoch 8], [iter 28500 / 35967], [train loss 2.10063], [train acc 0.19961]\n",
      "[epoch 8], [iter 28600 / 35967], [train loss 2.10040], [train acc 0.19979]\n",
      "[epoch 8], [iter 28700 / 35967], [train loss 2.10019], [train acc 0.20003]\n",
      "[epoch 8], [iter 28800 / 35967], [train loss 2.10057], [train acc 0.19972]\n",
      "[epoch 8], [iter 28900 / 35967], [train loss 2.10074], [train acc 0.19979]\n",
      "[epoch 8], [iter 29000 / 35967], [train loss 2.10066], [train acc 0.19979]\n",
      "[epoch 8], [iter 29100 / 35967], [train loss 2.10102], [train acc 0.20000]\n",
      "[epoch 8], [iter 29200 / 35967], [train loss 2.10094], [train acc 0.20003]\n",
      "[epoch 8], [iter 29300 / 35967], [train loss 2.10086], [train acc 0.20010]\n",
      "[epoch 8], [iter 29400 / 35967], [train loss 2.10092], [train acc 0.20017]\n",
      "[epoch 8], [iter 29500 / 35967], [train loss 2.10091], [train acc 0.20010]\n",
      "[epoch 8], [iter 29600 / 35967], [train loss 2.10066], [train acc 0.20020]\n",
      "[epoch 8], [iter 29700 / 35967], [train loss 2.10060], [train acc 0.20030]\n",
      "[epoch 8], [iter 29800 / 35967], [train loss 2.10021], [train acc 0.20020]\n",
      "[epoch 8], [iter 29900 / 35967], [train loss 2.10016], [train acc 0.20017]\n",
      "[epoch 8], [iter 30000 / 35967], [train loss 2.10034], [train acc 0.20000]\n",
      "[epoch 8], [iter 30100 / 35967], [train loss 2.10010], [train acc 0.20003]\n",
      "[epoch 8], [iter 30200 / 35967], [train loss 2.09984], [train acc 0.20023]\n",
      "[epoch 8], [iter 30300 / 35967], [train loss 2.09930], [train acc 0.20030]\n",
      "[epoch 8], [iter 30400 / 35967], [train loss 2.09923], [train acc 0.20033]\n",
      "[epoch 8], [iter 30500 / 35967], [train loss 2.09912], [train acc 0.20020]\n",
      "[epoch 8], [iter 30600 / 35967], [train loss 2.09942], [train acc 0.20007]\n",
      "[epoch 8], [iter 30700 / 35967], [train loss 2.09933], [train acc 0.20010]\n",
      "[epoch 8], [iter 30800 / 35967], [train loss 2.09942], [train acc 0.20010]\n",
      "[epoch 8], [iter 30900 / 35967], [train loss 2.09920], [train acc 0.20026]\n",
      "[epoch 8], [iter 31000 / 35967], [train loss 2.09944], [train acc 0.20016]\n",
      "[epoch 8], [iter 31100 / 35967], [train loss 2.09939], [train acc 0.20019]\n",
      "[epoch 8], [iter 31200 / 35967], [train loss 2.09957], [train acc 0.20026]\n",
      "[epoch 8], [iter 31300 / 35967], [train loss 2.09968], [train acc 0.20006]\n",
      "[epoch 8], [iter 31400 / 35967], [train loss 2.09964], [train acc 0.20000]\n",
      "[epoch 8], [iter 31500 / 35967], [train loss 2.09949], [train acc 0.20019]\n",
      "[epoch 8], [iter 31600 / 35967], [train loss 2.09949], [train acc 0.20016]\n",
      "[epoch 8], [iter 31700 / 35967], [train loss 2.09953], [train acc 0.19997]\n",
      "[epoch 8], [iter 31800 / 35967], [train loss 2.09931], [train acc 0.19984]\n",
      "[epoch 8], [iter 31900 / 35967], [train loss 2.09972], [train acc 0.19972]\n",
      "[epoch 8], [iter 32000 / 35967], [train loss 2.09969], [train acc 0.19962]\n",
      "[epoch 8], [iter 32100 / 35967], [train loss 2.09960], [train acc 0.19944]\n",
      "[epoch 8], [iter 32200 / 35967], [train loss 2.09914], [train acc 0.19953]\n",
      "[epoch 8], [iter 32300 / 35967], [train loss 2.09928], [train acc 0.19935]\n",
      "[epoch 8], [iter 32400 / 35967], [train loss 2.09920], [train acc 0.19926]\n",
      "[epoch 8], [iter 32500 / 35967], [train loss 2.09957], [train acc 0.19932]\n",
      "[epoch 8], [iter 32600 / 35967], [train loss 2.09953], [train acc 0.19945]\n",
      "[epoch 8], [iter 32700 / 35967], [train loss 2.09943], [train acc 0.19948]\n",
      "[epoch 8], [iter 32800 / 35967], [train loss 2.09980], [train acc 0.19924]\n",
      "[epoch 8], [iter 32900 / 35967], [train loss 2.09944], [train acc 0.19933]\n",
      "[epoch 8], [iter 33000 / 35967], [train loss 2.09939], [train acc 0.19942]\n",
      "[epoch 8], [iter 33100 / 35967], [train loss 2.09939], [train acc 0.19949]\n",
      "[epoch 8], [iter 33200 / 35967], [train loss 2.09956], [train acc 0.19943]\n",
      "[epoch 8], [iter 33300 / 35967], [train loss 2.09937], [train acc 0.19955]\n",
      "[epoch 8], [iter 33400 / 35967], [train loss 2.09970], [train acc 0.19946]\n",
      "[epoch 8], [iter 33500 / 35967], [train loss 2.09958], [train acc 0.19946]\n",
      "[epoch 8], [iter 33600 / 35967], [train loss 2.09943], [train acc 0.19946]\n",
      "[epoch 8], [iter 33700 / 35967], [train loss 2.09947], [train acc 0.19944]\n",
      "[epoch 8], [iter 33800 / 35967], [train loss 2.09932], [train acc 0.19938]\n",
      "[epoch 8], [iter 33900 / 35967], [train loss 2.09967], [train acc 0.19929]\n",
      "[epoch 8], [iter 34000 / 35967], [train loss 2.09980], [train acc 0.19941]\n",
      "[epoch 8], [iter 34100 / 35967], [train loss 2.10000], [train acc 0.19933]\n",
      "[epoch 8], [iter 34200 / 35967], [train loss 2.10011], [train acc 0.19904]\n",
      "[epoch 8], [iter 34300 / 35967], [train loss 2.10011], [train acc 0.19901]\n",
      "[epoch 8], [iter 34400 / 35967], [train loss 2.09999], [train acc 0.19901]\n",
      "[epoch 8], [iter 34500 / 35967], [train loss 2.09982], [train acc 0.19922]\n",
      "[epoch 8], [iter 34600 / 35967], [train loss 2.09985], [train acc 0.19922]\n",
      "[epoch 8], [iter 34700 / 35967], [train loss 2.10014], [train acc 0.19908]\n",
      "[epoch 8], [iter 34800 / 35967], [train loss 2.09998], [train acc 0.19917]\n",
      "[epoch 8], [iter 34900 / 35967], [train loss 2.09994], [train acc 0.19908]\n",
      "[epoch 8], [iter 35000 / 35967], [train loss 2.10001], [train acc 0.19897]\n",
      "[epoch 8], [iter 35100 / 35967], [train loss 2.10004], [train acc 0.19897]\n",
      "[epoch 8], [iter 35200 / 35967], [train loss 2.10021], [train acc 0.19884]\n",
      "[epoch 8], [iter 35300 / 35967], [train loss 2.10021], [train acc 0.19856]\n",
      "[epoch 8], [iter 35400 / 35967], [train loss 2.10007], [train acc 0.19856]\n",
      "[epoch 8], [iter 35500 / 35967], [train loss 2.09979], [train acc 0.19856]\n",
      "[epoch 8], [iter 35600 / 35967], [train loss 2.09966], [train acc 0.19851]\n",
      "[epoch 8], [iter 35700 / 35967], [train loss 2.09954], [train acc 0.19852]\n",
      "[epoch 8], [iter 35800 / 35967], [train loss 2.09966], [train acc 0.19855]\n",
      "[epoch 8], [iter 35900 / 35967], [train loss 2.09966], [train acc 0.19864]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 11.59987], [val acc 0.07706]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [iter 100 / 35967], [train loss 2.08072], [train acc 0.15000]\n",
      "[epoch 9], [iter 200 / 35967], [train loss 2.05765], [train acc 0.17500]\n",
      "[epoch 9], [iter 300 / 35967], [train loss 2.04611], [train acc 0.18667]\n",
      "[epoch 9], [iter 400 / 35967], [train loss 2.07256], [train acc 0.17500]\n",
      "[epoch 9], [iter 500 / 35967], [train loss 2.08271], [train acc 0.17400]\n",
      "[epoch 9], [iter 600 / 35967], [train loss 2.08004], [train acc 0.17833]\n",
      "[epoch 9], [iter 700 / 35967], [train loss 2.08311], [train acc 0.18429]\n",
      "[epoch 9], [iter 800 / 35967], [train loss 2.07253], [train acc 0.19250]\n",
      "[epoch 9], [iter 900 / 35967], [train loss 2.07181], [train acc 0.19000]\n",
      "[epoch 9], [iter 1000 / 35967], [train loss 2.08641], [train acc 0.18500]\n",
      "[epoch 9], [iter 1100 / 35967], [train loss 2.08891], [train acc 0.18545]\n",
      "[epoch 9], [iter 1200 / 35967], [train loss 2.07633], [train acc 0.18833]\n",
      "[epoch 9], [iter 1300 / 35967], [train loss 2.07222], [train acc 0.18615]\n",
      "[epoch 9], [iter 1400 / 35967], [train loss 2.07270], [train acc 0.18500]\n",
      "[epoch 9], [iter 1500 / 35967], [train loss 2.07472], [train acc 0.18600]\n",
      "[epoch 9], [iter 1600 / 35967], [train loss 2.06874], [train acc 0.18812]\n",
      "[epoch 9], [iter 1700 / 35967], [train loss 2.07570], [train acc 0.19059]\n",
      "[epoch 9], [iter 1800 / 35967], [train loss 2.07144], [train acc 0.19500]\n",
      "[epoch 9], [iter 1900 / 35967], [train loss 2.07416], [train acc 0.19474]\n",
      "[epoch 9], [iter 2000 / 35967], [train loss 2.07005], [train acc 0.19650]\n",
      "[epoch 9], [iter 2100 / 35967], [train loss 2.07074], [train acc 0.19762]\n",
      "[epoch 9], [iter 2200 / 35967], [train loss 2.07374], [train acc 0.19909]\n",
      "[epoch 9], [iter 2300 / 35967], [train loss 2.07712], [train acc 0.20043]\n",
      "[epoch 9], [iter 2400 / 35967], [train loss 2.07652], [train acc 0.20083]\n",
      "[epoch 9], [iter 2500 / 35967], [train loss 2.07985], [train acc 0.20080]\n",
      "[epoch 9], [iter 2600 / 35967], [train loss 2.07917], [train acc 0.20077]\n",
      "[epoch 9], [iter 2700 / 35967], [train loss 2.08015], [train acc 0.20148]\n",
      "[epoch 9], [iter 2800 / 35967], [train loss 2.07912], [train acc 0.20143]\n",
      "[epoch 9], [iter 2900 / 35967], [train loss 2.08421], [train acc 0.20034]\n",
      "[epoch 9], [iter 3000 / 35967], [train loss 2.08787], [train acc 0.19967]\n",
      "[epoch 9], [iter 3100 / 35967], [train loss 2.08535], [train acc 0.20000]\n",
      "[epoch 9], [iter 3200 / 35967], [train loss 2.08535], [train acc 0.20062]\n",
      "[epoch 9], [iter 3300 / 35967], [train loss 2.08619], [train acc 0.20121]\n",
      "[epoch 9], [iter 3400 / 35967], [train loss 2.08800], [train acc 0.20029]\n",
      "[epoch 9], [iter 3500 / 35967], [train loss 2.08733], [train acc 0.20000]\n",
      "[epoch 9], [iter 3600 / 35967], [train loss 2.08722], [train acc 0.20056]\n",
      "[epoch 9], [iter 3700 / 35967], [train loss 2.08843], [train acc 0.19973]\n",
      "[epoch 9], [iter 3800 / 35967], [train loss 2.09034], [train acc 0.20079]\n",
      "[epoch 9], [iter 3900 / 35967], [train loss 2.09239], [train acc 0.19949]\n",
      "[epoch 9], [iter 4000 / 35967], [train loss 2.08897], [train acc 0.19950]\n",
      "[epoch 9], [iter 4100 / 35967], [train loss 2.08682], [train acc 0.20073]\n",
      "[epoch 9], [iter 4200 / 35967], [train loss 2.08626], [train acc 0.20143]\n",
      "[epoch 9], [iter 4300 / 35967], [train loss 2.08563], [train acc 0.20163]\n",
      "[epoch 9], [iter 4400 / 35967], [train loss 2.08503], [train acc 0.20295]\n",
      "[epoch 9], [iter 4500 / 35967], [train loss 2.08423], [train acc 0.20289]\n",
      "[epoch 9], [iter 4600 / 35967], [train loss 2.08342], [train acc 0.20239]\n",
      "[epoch 9], [iter 4700 / 35967], [train loss 2.08336], [train acc 0.20319]\n",
      "[epoch 9], [iter 4800 / 35967], [train loss 2.08157], [train acc 0.20479]\n",
      "[epoch 9], [iter 4900 / 35967], [train loss 2.08187], [train acc 0.20469]\n",
      "[epoch 9], [iter 5000 / 35967], [train loss 2.08221], [train acc 0.20520]\n",
      "[epoch 9], [iter 5100 / 35967], [train loss 2.08301], [train acc 0.20490]\n",
      "[epoch 9], [iter 5200 / 35967], [train loss 2.08171], [train acc 0.20442]\n",
      "[epoch 9], [iter 5300 / 35967], [train loss 2.07968], [train acc 0.20472]\n",
      "[epoch 9], [iter 5400 / 35967], [train loss 2.07978], [train acc 0.20537]\n",
      "[epoch 9], [iter 5500 / 35967], [train loss 2.08109], [train acc 0.20600]\n",
      "[epoch 9], [iter 5600 / 35967], [train loss 2.07997], [train acc 0.20696]\n",
      "[epoch 9], [iter 5700 / 35967], [train loss 2.08024], [train acc 0.20561]\n",
      "[epoch 9], [iter 5800 / 35967], [train loss 2.08188], [train acc 0.20534]\n",
      "[epoch 9], [iter 5900 / 35967], [train loss 2.08201], [train acc 0.20508]\n",
      "[epoch 9], [iter 6000 / 35967], [train loss 2.08371], [train acc 0.20417]\n",
      "[epoch 9], [iter 6100 / 35967], [train loss 2.08139], [train acc 0.20443]\n",
      "[epoch 9], [iter 6200 / 35967], [train loss 2.08066], [train acc 0.20419]\n",
      "[epoch 9], [iter 6300 / 35967], [train loss 2.08186], [train acc 0.20302]\n",
      "[epoch 9], [iter 6400 / 35967], [train loss 2.08251], [train acc 0.20344]\n",
      "[epoch 9], [iter 6500 / 35967], [train loss 2.08106], [train acc 0.20415]\n",
      "[epoch 9], [iter 6600 / 35967], [train loss 2.08072], [train acc 0.20455]\n",
      "[epoch 9], [iter 6700 / 35967], [train loss 2.08133], [train acc 0.20493]\n",
      "[epoch 9], [iter 6800 / 35967], [train loss 2.08108], [train acc 0.20603]\n",
      "[epoch 9], [iter 6900 / 35967], [train loss 2.08304], [train acc 0.20507]\n",
      "[epoch 9], [iter 7000 / 35967], [train loss 2.08421], [train acc 0.20514]\n",
      "[epoch 9], [iter 7100 / 35967], [train loss 2.08614], [train acc 0.20437]\n",
      "[epoch 9], [iter 7200 / 35967], [train loss 2.08686], [train acc 0.20347]\n",
      "[epoch 9], [iter 7300 / 35967], [train loss 2.08808], [train acc 0.20342]\n",
      "[epoch 9], [iter 7400 / 35967], [train loss 2.08677], [train acc 0.20284]\n",
      "[epoch 9], [iter 7500 / 35967], [train loss 2.08689], [train acc 0.20347]\n",
      "[epoch 9], [iter 7600 / 35967], [train loss 2.08930], [train acc 0.20316]\n",
      "[epoch 9], [iter 7700 / 35967], [train loss 2.08859], [train acc 0.20364]\n",
      "[epoch 9], [iter 7800 / 35967], [train loss 2.09005], [train acc 0.20346]\n",
      "[epoch 9], [iter 7900 / 35967], [train loss 2.08870], [train acc 0.20354]\n",
      "[epoch 9], [iter 8000 / 35967], [train loss 2.08913], [train acc 0.20325]\n",
      "[epoch 9], [iter 8100 / 35967], [train loss 2.08996], [train acc 0.20370]\n",
      "[epoch 9], [iter 8200 / 35967], [train loss 2.08898], [train acc 0.20378]\n",
      "[epoch 9], [iter 8300 / 35967], [train loss 2.08817], [train acc 0.20325]\n",
      "[epoch 9], [iter 8400 / 35967], [train loss 2.08716], [train acc 0.20262]\n",
      "[epoch 9], [iter 8500 / 35967], [train loss 2.08675], [train acc 0.20212]\n",
      "[epoch 9], [iter 8600 / 35967], [train loss 2.08705], [train acc 0.20174]\n",
      "[epoch 9], [iter 8700 / 35967], [train loss 2.08663], [train acc 0.20241]\n",
      "[epoch 9], [iter 8800 / 35967], [train loss 2.08722], [train acc 0.20250]\n",
      "[epoch 9], [iter 8900 / 35967], [train loss 2.08732], [train acc 0.20202]\n",
      "[epoch 9], [iter 9000 / 35967], [train loss 2.08743], [train acc 0.20222]\n",
      "[epoch 9], [iter 9100 / 35967], [train loss 2.08851], [train acc 0.20176]\n",
      "[epoch 9], [iter 9200 / 35967], [train loss 2.08903], [train acc 0.20163]\n",
      "[epoch 9], [iter 9300 / 35967], [train loss 2.08883], [train acc 0.20097]\n",
      "[epoch 9], [iter 9400 / 35967], [train loss 2.08790], [train acc 0.20138]\n",
      "[epoch 9], [iter 9500 / 35967], [train loss 2.08835], [train acc 0.20137]\n",
      "[epoch 9], [iter 9600 / 35967], [train loss 2.08824], [train acc 0.20146]\n",
      "[epoch 9], [iter 9700 / 35967], [train loss 2.08739], [train acc 0.20165]\n",
      "[epoch 9], [iter 9800 / 35967], [train loss 2.08759], [train acc 0.20143]\n",
      "[epoch 9], [iter 9900 / 35967], [train loss 2.08745], [train acc 0.20111]\n",
      "[epoch 9], [iter 10000 / 35967], [train loss 2.08826], [train acc 0.20070]\n",
      "[epoch 9], [iter 10100 / 35967], [train loss 2.08741], [train acc 0.20119]\n",
      "[epoch 9], [iter 10200 / 35967], [train loss 2.08667], [train acc 0.20157]\n",
      "[epoch 9], [iter 10300 / 35967], [train loss 2.08600], [train acc 0.20165]\n",
      "[epoch 9], [iter 10400 / 35967], [train loss 2.08490], [train acc 0.20212]\n",
      "[epoch 9], [iter 10500 / 35967], [train loss 2.08479], [train acc 0.20219]\n",
      "[epoch 9], [iter 10600 / 35967], [train loss 2.08458], [train acc 0.20189]\n",
      "[epoch 9], [iter 10700 / 35967], [train loss 2.08475], [train acc 0.20140]\n",
      "[epoch 9], [iter 10800 / 35967], [train loss 2.08487], [train acc 0.20102]\n",
      "[epoch 9], [iter 10900 / 35967], [train loss 2.08491], [train acc 0.20055]\n",
      "[epoch 9], [iter 11000 / 35967], [train loss 2.08528], [train acc 0.20036]\n",
      "[epoch 9], [iter 11100 / 35967], [train loss 2.08519], [train acc 0.20045]\n",
      "[epoch 9], [iter 11200 / 35967], [train loss 2.08531], [train acc 0.20107]\n",
      "[epoch 9], [iter 11300 / 35967], [train loss 2.08408], [train acc 0.20177]\n",
      "[epoch 9], [iter 11400 / 35967], [train loss 2.08432], [train acc 0.20219]\n",
      "[epoch 9], [iter 11500 / 35967], [train loss 2.08431], [train acc 0.20217]\n",
      "[epoch 9], [iter 11600 / 35967], [train loss 2.08464], [train acc 0.20172]\n",
      "[epoch 9], [iter 11700 / 35967], [train loss 2.08425], [train acc 0.20197]\n",
      "[epoch 9], [iter 11800 / 35967], [train loss 2.08494], [train acc 0.20195]\n",
      "[epoch 9], [iter 11900 / 35967], [train loss 2.08461], [train acc 0.20202]\n",
      "[epoch 9], [iter 12000 / 35967], [train loss 2.08403], [train acc 0.20250]\n",
      "[epoch 9], [iter 12100 / 35967], [train loss 2.08336], [train acc 0.20281]\n",
      "[epoch 9], [iter 12200 / 35967], [train loss 2.08286], [train acc 0.20279]\n",
      "[epoch 9], [iter 12300 / 35967], [train loss 2.08199], [train acc 0.20285]\n",
      "[epoch 9], [iter 12400 / 35967], [train loss 2.08137], [train acc 0.20298]\n",
      "[epoch 9], [iter 12500 / 35967], [train loss 2.08169], [train acc 0.20304]\n",
      "[epoch 9], [iter 12600 / 35967], [train loss 2.08183], [train acc 0.20302]\n",
      "[epoch 9], [iter 12700 / 35967], [train loss 2.08158], [train acc 0.20299]\n",
      "[epoch 9], [iter 12800 / 35967], [train loss 2.08149], [train acc 0.20328]\n",
      "[epoch 9], [iter 12900 / 35967], [train loss 2.08031], [train acc 0.20395]\n",
      "[epoch 9], [iter 13000 / 35967], [train loss 2.07962], [train acc 0.20423]\n",
      "[epoch 9], [iter 13100 / 35967], [train loss 2.08018], [train acc 0.20412]\n",
      "[epoch 9], [iter 13200 / 35967], [train loss 2.08069], [train acc 0.20394]\n",
      "[epoch 9], [iter 13300 / 35967], [train loss 2.08128], [train acc 0.20353]\n",
      "[epoch 9], [iter 13400 / 35967], [train loss 2.08046], [train acc 0.20358]\n",
      "[epoch 9], [iter 13500 / 35967], [train loss 2.08076], [train acc 0.20348]\n",
      "[epoch 9], [iter 13600 / 35967], [train loss 2.08064], [train acc 0.20382]\n",
      "[epoch 9], [iter 13700 / 35967], [train loss 2.08170], [train acc 0.20380]\n",
      "[epoch 9], [iter 13800 / 35967], [train loss 2.08200], [train acc 0.20391]\n",
      "[epoch 9], [iter 13900 / 35967], [train loss 2.08130], [train acc 0.20367]\n",
      "[epoch 9], [iter 14000 / 35967], [train loss 2.08172], [train acc 0.20350]\n",
      "[epoch 9], [iter 14100 / 35967], [train loss 2.08232], [train acc 0.20312]\n",
      "[epoch 9], [iter 14200 / 35967], [train loss 2.08327], [train acc 0.20310]\n",
      "[epoch 9], [iter 14300 / 35967], [train loss 2.08306], [train acc 0.20357]\n",
      "[epoch 9], [iter 14400 / 35967], [train loss 2.08224], [train acc 0.20410]\n",
      "[epoch 9], [iter 14500 / 35967], [train loss 2.08326], [train acc 0.20366]\n",
      "[epoch 9], [iter 14600 / 35967], [train loss 2.08331], [train acc 0.20390]\n",
      "[epoch 9], [iter 14700 / 35967], [train loss 2.08306], [train acc 0.20395]\n",
      "[epoch 9], [iter 14800 / 35967], [train loss 2.08331], [train acc 0.20412]\n",
      "[epoch 9], [iter 14900 / 35967], [train loss 2.08276], [train acc 0.20396]\n",
      "[epoch 9], [iter 15000 / 35967], [train loss 2.08249], [train acc 0.20407]\n",
      "[epoch 9], [iter 15100 / 35967], [train loss 2.08242], [train acc 0.20358]\n",
      "[epoch 9], [iter 15200 / 35967], [train loss 2.08310], [train acc 0.20408]\n",
      "[epoch 9], [iter 15300 / 35967], [train loss 2.08388], [train acc 0.20399]\n",
      "[epoch 9], [iter 15400 / 35967], [train loss 2.08363], [train acc 0.20383]\n",
      "[epoch 9], [iter 15500 / 35967], [train loss 2.08338], [train acc 0.20400]\n",
      "[epoch 9], [iter 15600 / 35967], [train loss 2.08281], [train acc 0.20404]\n",
      "[epoch 9], [iter 15700 / 35967], [train loss 2.08302], [train acc 0.20401]\n",
      "[epoch 9], [iter 15800 / 35967], [train loss 2.08304], [train acc 0.20373]\n",
      "[epoch 9], [iter 15900 / 35967], [train loss 2.08329], [train acc 0.20365]\n",
      "[epoch 9], [iter 16000 / 35967], [train loss 2.08389], [train acc 0.20338]\n",
      "[epoch 9], [iter 16100 / 35967], [train loss 2.08429], [train acc 0.20298]\n",
      "[epoch 9], [iter 16200 / 35967], [train loss 2.08478], [train acc 0.20315]\n",
      "[epoch 9], [iter 16300 / 35967], [train loss 2.08481], [train acc 0.20313]\n",
      "[epoch 9], [iter 16400 / 35967], [train loss 2.08551], [train acc 0.20317]\n",
      "[epoch 9], [iter 16500 / 35967], [train loss 2.08519], [train acc 0.20327]\n",
      "[epoch 9], [iter 16600 / 35967], [train loss 2.08561], [train acc 0.20307]\n",
      "[epoch 9], [iter 16700 / 35967], [train loss 2.08579], [train acc 0.20299]\n",
      "[epoch 9], [iter 16800 / 35967], [train loss 2.08622], [train acc 0.20274]\n",
      "[epoch 9], [iter 16900 / 35967], [train loss 2.08585], [train acc 0.20266]\n",
      "[epoch 9], [iter 17000 / 35967], [train loss 2.08548], [train acc 0.20271]\n",
      "[epoch 9], [iter 17100 / 35967], [train loss 2.08484], [train acc 0.20310]\n",
      "[epoch 9], [iter 17200 / 35967], [train loss 2.08440], [train acc 0.20308]\n",
      "[epoch 9], [iter 17300 / 35967], [train loss 2.08392], [train acc 0.20318]\n",
      "[epoch 9], [iter 17400 / 35967], [train loss 2.08411], [train acc 0.20276]\n",
      "[epoch 9], [iter 17500 / 35967], [train loss 2.08478], [train acc 0.20257]\n",
      "[epoch 9], [iter 17600 / 35967], [train loss 2.08474], [train acc 0.20267]\n",
      "[epoch 9], [iter 17700 / 35967], [train loss 2.08492], [train acc 0.20271]\n",
      "[epoch 9], [iter 17800 / 35967], [train loss 2.08455], [train acc 0.20287]\n",
      "[epoch 9], [iter 17900 / 35967], [train loss 2.08430], [train acc 0.20291]\n",
      "[epoch 9], [iter 18000 / 35967], [train loss 2.08481], [train acc 0.20294]\n",
      "[epoch 9], [iter 18100 / 35967], [train loss 2.08504], [train acc 0.20287]\n",
      "[epoch 9], [iter 18200 / 35967], [train loss 2.08517], [train acc 0.20308]\n",
      "[epoch 9], [iter 18300 / 35967], [train loss 2.08523], [train acc 0.20311]\n",
      "[epoch 9], [iter 18400 / 35967], [train loss 2.08542], [train acc 0.20332]\n",
      "[epoch 9], [iter 18500 / 35967], [train loss 2.08522], [train acc 0.20319]\n",
      "[epoch 9], [iter 18600 / 35967], [train loss 2.08542], [train acc 0.20301]\n",
      "[epoch 9], [iter 18700 / 35967], [train loss 2.08467], [train acc 0.20299]\n",
      "[epoch 9], [iter 18800 / 35967], [train loss 2.08438], [train acc 0.20287]\n",
      "[epoch 9], [iter 18900 / 35967], [train loss 2.08458], [train acc 0.20291]\n",
      "[epoch 9], [iter 19000 / 35967], [train loss 2.08463], [train acc 0.20284]\n",
      "[epoch 9], [iter 19100 / 35967], [train loss 2.08477], [train acc 0.20277]\n",
      "[epoch 9], [iter 19200 / 35967], [train loss 2.08401], [train acc 0.20323]\n",
      "[epoch 9], [iter 19300 / 35967], [train loss 2.08578], [train acc 0.20301]\n",
      "[epoch 9], [iter 19400 / 35967], [train loss 2.08605], [train acc 0.20309]\n",
      "[epoch 9], [iter 19500 / 35967], [train loss 2.08618], [train acc 0.20313]\n",
      "[epoch 9], [iter 19600 / 35967], [train loss 2.08595], [train acc 0.20291]\n",
      "[epoch 9], [iter 19700 / 35967], [train loss 2.08636], [train acc 0.20294]\n",
      "[epoch 9], [iter 19800 / 35967], [train loss 2.08628], [train acc 0.20298]\n",
      "[epoch 9], [iter 19900 / 35967], [train loss 2.08642], [train acc 0.20327]\n",
      "[epoch 9], [iter 20000 / 35967], [train loss 2.08677], [train acc 0.20330]\n",
      "[epoch 9], [iter 20100 / 35967], [train loss 2.08627], [train acc 0.20358]\n",
      "[epoch 9], [iter 20200 / 35967], [train loss 2.08558], [train acc 0.20411]\n",
      "[epoch 9], [iter 20300 / 35967], [train loss 2.08560], [train acc 0.20438]\n",
      "[epoch 9], [iter 20400 / 35967], [train loss 2.08578], [train acc 0.20446]\n",
      "[epoch 9], [iter 20500 / 35967], [train loss 2.08610], [train acc 0.20463]\n",
      "[epoch 9], [iter 20600 / 35967], [train loss 2.08607], [train acc 0.20466]\n",
      "[epoch 9], [iter 20700 / 35967], [train loss 2.08638], [train acc 0.20449]\n",
      "[epoch 9], [iter 20800 / 35967], [train loss 2.08698], [train acc 0.20442]\n",
      "[epoch 9], [iter 20900 / 35967], [train loss 2.08687], [train acc 0.20459]\n",
      "[epoch 9], [iter 21000 / 35967], [train loss 2.08661], [train acc 0.20471]\n",
      "[epoch 9], [iter 21100 / 35967], [train loss 2.08665], [train acc 0.20469]\n",
      "[epoch 9], [iter 21200 / 35967], [train loss 2.08656], [train acc 0.20443]\n",
      "[epoch 9], [iter 21300 / 35967], [train loss 2.08606], [train acc 0.20469]\n",
      "[epoch 9], [iter 21400 / 35967], [train loss 2.08590], [train acc 0.20481]\n",
      "[epoch 9], [iter 21500 / 35967], [train loss 2.08597], [train acc 0.20470]\n",
      "[epoch 9], [iter 21600 / 35967], [train loss 2.08618], [train acc 0.20440]\n",
      "[epoch 9], [iter 21700 / 35967], [train loss 2.08624], [train acc 0.20410]\n",
      "[epoch 9], [iter 21800 / 35967], [train loss 2.08728], [train acc 0.20385]\n",
      "[epoch 9], [iter 21900 / 35967], [train loss 2.08741], [train acc 0.20397]\n",
      "[epoch 9], [iter 22000 / 35967], [train loss 2.08787], [train acc 0.20414]\n",
      "[epoch 9], [iter 22100 / 35967], [train loss 2.08787], [train acc 0.20407]\n",
      "[epoch 9], [iter 22200 / 35967], [train loss 2.08743], [train acc 0.20432]\n",
      "[epoch 9], [iter 22300 / 35967], [train loss 2.08708], [train acc 0.20453]\n",
      "[epoch 9], [iter 22400 / 35967], [train loss 2.08738], [train acc 0.20451]\n",
      "[epoch 9], [iter 22500 / 35967], [train loss 2.08743], [train acc 0.20458]\n",
      "[epoch 9], [iter 22600 / 35967], [train loss 2.08808], [train acc 0.20460]\n",
      "[epoch 9], [iter 22700 / 35967], [train loss 2.08804], [train acc 0.20441]\n",
      "[epoch 9], [iter 22800 / 35967], [train loss 2.08758], [train acc 0.20456]\n",
      "[epoch 9], [iter 22900 / 35967], [train loss 2.08744], [train acc 0.20437]\n",
      "[epoch 9], [iter 23000 / 35967], [train loss 2.08755], [train acc 0.20443]\n",
      "[epoch 9], [iter 23100 / 35967], [train loss 2.08705], [train acc 0.20468]\n",
      "[epoch 9], [iter 23200 / 35967], [train loss 2.08730], [train acc 0.20466]\n",
      "[epoch 9], [iter 23300 / 35967], [train loss 2.08768], [train acc 0.20433]\n",
      "[epoch 9], [iter 23400 / 35967], [train loss 2.08738], [train acc 0.20436]\n",
      "[epoch 9], [iter 23500 / 35967], [train loss 2.08722], [train acc 0.20434]\n",
      "[epoch 9], [iter 23600 / 35967], [train loss 2.08707], [train acc 0.20445]\n",
      "[epoch 9], [iter 23700 / 35967], [train loss 2.08733], [train acc 0.20430]\n",
      "[epoch 9], [iter 23800 / 35967], [train loss 2.08691], [train acc 0.20454]\n",
      "[epoch 9], [iter 23900 / 35967], [train loss 2.08676], [train acc 0.20473]\n",
      "[epoch 9], [iter 24000 / 35967], [train loss 2.08694], [train acc 0.20492]\n",
      "[epoch 9], [iter 24100 / 35967], [train loss 2.08670], [train acc 0.20531]\n",
      "[epoch 9], [iter 24200 / 35967], [train loss 2.08663], [train acc 0.20541]\n",
      "[epoch 9], [iter 24300 / 35967], [train loss 2.08665], [train acc 0.20547]\n",
      "[epoch 9], [iter 24400 / 35967], [train loss 2.08630], [train acc 0.20578]\n",
      "[epoch 9], [iter 24500 / 35967], [train loss 2.08595], [train acc 0.20588]\n",
      "[epoch 9], [iter 24600 / 35967], [train loss 2.08621], [train acc 0.20585]\n",
      "[epoch 9], [iter 24700 / 35967], [train loss 2.08572], [train acc 0.20591]\n",
      "[epoch 9], [iter 24800 / 35967], [train loss 2.08638], [train acc 0.20573]\n",
      "[epoch 9], [iter 24900 / 35967], [train loss 2.08692], [train acc 0.20550]\n",
      "[epoch 9], [iter 25000 / 35967], [train loss 2.08690], [train acc 0.20552]\n",
      "[epoch 9], [iter 25100 / 35967], [train loss 2.08694], [train acc 0.20542]\n",
      "[epoch 9], [iter 25200 / 35967], [train loss 2.08671], [train acc 0.20528]\n",
      "[epoch 9], [iter 25300 / 35967], [train loss 2.08671], [train acc 0.20526]\n",
      "[epoch 9], [iter 25400 / 35967], [train loss 2.08639], [train acc 0.20539]\n",
      "[epoch 9], [iter 25500 / 35967], [train loss 2.08623], [train acc 0.20549]\n",
      "[epoch 9], [iter 25600 / 35967], [train loss 2.08603], [train acc 0.20566]\n",
      "[epoch 9], [iter 25700 / 35967], [train loss 2.08607], [train acc 0.20556]\n",
      "[epoch 9], [iter 25800 / 35967], [train loss 2.08656], [train acc 0.20547]\n",
      "[epoch 9], [iter 25900 / 35967], [train loss 2.08662], [train acc 0.20537]\n",
      "[epoch 9], [iter 26000 / 35967], [train loss 2.08640], [train acc 0.20558]\n",
      "[epoch 9], [iter 26100 / 35967], [train loss 2.08630], [train acc 0.20571]\n",
      "[epoch 9], [iter 26200 / 35967], [train loss 2.08632], [train acc 0.20565]\n",
      "[epoch 9], [iter 26300 / 35967], [train loss 2.08607], [train acc 0.20578]\n",
      "[epoch 9], [iter 26400 / 35967], [train loss 2.08588], [train acc 0.20587]\n",
      "[epoch 9], [iter 26500 / 35967], [train loss 2.08568], [train acc 0.20611]\n",
      "[epoch 9], [iter 26600 / 35967], [train loss 2.08561], [train acc 0.20624]\n",
      "[epoch 9], [iter 26700 / 35967], [train loss 2.08592], [train acc 0.20618]\n",
      "[epoch 9], [iter 26800 / 35967], [train loss 2.08615], [train acc 0.20619]\n",
      "[epoch 9], [iter 26900 / 35967], [train loss 2.08632], [train acc 0.20621]\n",
      "[epoch 9], [iter 27000 / 35967], [train loss 2.08603], [train acc 0.20622]\n",
      "[epoch 9], [iter 27100 / 35967], [train loss 2.08638], [train acc 0.20616]\n",
      "[epoch 9], [iter 27200 / 35967], [train loss 2.08617], [train acc 0.20651]\n",
      "[epoch 9], [iter 27300 / 35967], [train loss 2.08622], [train acc 0.20648]\n",
      "[epoch 9], [iter 27400 / 35967], [train loss 2.08595], [train acc 0.20672]\n",
      "[epoch 9], [iter 27500 / 35967], [train loss 2.08596], [train acc 0.20691]\n",
      "[epoch 9], [iter 27600 / 35967], [train loss 2.08628], [train acc 0.20696]\n",
      "[epoch 9], [iter 27700 / 35967], [train loss 2.08619], [train acc 0.20693]\n",
      "[epoch 9], [iter 27800 / 35967], [train loss 2.08601], [train acc 0.20691]\n",
      "[epoch 9], [iter 27900 / 35967], [train loss 2.08597], [train acc 0.20699]\n",
      "[epoch 9], [iter 28000 / 35967], [train loss 2.08552], [train acc 0.20711]\n",
      "[epoch 9], [iter 28100 / 35967], [train loss 2.08580], [train acc 0.20705]\n",
      "[epoch 9], [iter 28200 / 35967], [train loss 2.08633], [train acc 0.20695]\n",
      "[epoch 9], [iter 28300 / 35967], [train loss 2.08633], [train acc 0.20682]\n",
      "[epoch 9], [iter 28400 / 35967], [train loss 2.08641], [train acc 0.20690]\n",
      "[epoch 9], [iter 28500 / 35967], [train loss 2.08655], [train acc 0.20684]\n",
      "[epoch 9], [iter 28600 / 35967], [train loss 2.08616], [train acc 0.20699]\n",
      "[epoch 9], [iter 28700 / 35967], [train loss 2.08594], [train acc 0.20700]\n",
      "[epoch 9], [iter 28800 / 35967], [train loss 2.08636], [train acc 0.20705]\n",
      "[epoch 9], [iter 28900 / 35967], [train loss 2.08645], [train acc 0.20692]\n",
      "[epoch 9], [iter 29000 / 35967], [train loss 2.08646], [train acc 0.20686]\n",
      "[epoch 9], [iter 29100 / 35967], [train loss 2.08613], [train acc 0.20698]\n",
      "[epoch 9], [iter 29200 / 35967], [train loss 2.08624], [train acc 0.20709]\n",
      "[epoch 9], [iter 29300 / 35967], [train loss 2.08633], [train acc 0.20724]\n",
      "[epoch 9], [iter 29400 / 35967], [train loss 2.08637], [train acc 0.20718]\n",
      "[epoch 9], [iter 29500 / 35967], [train loss 2.08678], [train acc 0.20712]\n",
      "[epoch 9], [iter 29600 / 35967], [train loss 2.08695], [train acc 0.20706]\n",
      "[epoch 9], [iter 29700 / 35967], [train loss 2.08695], [train acc 0.20697]\n",
      "[epoch 9], [iter 29800 / 35967], [train loss 2.08717], [train acc 0.20708]\n",
      "[epoch 9], [iter 29900 / 35967], [train loss 2.08754], [train acc 0.20692]\n",
      "[epoch 9], [iter 30000 / 35967], [train loss 2.08731], [train acc 0.20697]\n",
      "[epoch 9], [iter 30100 / 35967], [train loss 2.08720], [train acc 0.20688]\n",
      "[epoch 9], [iter 30200 / 35967], [train loss 2.08695], [train acc 0.20666]\n",
      "[epoch 9], [iter 30300 / 35967], [train loss 2.08706], [train acc 0.20663]\n",
      "[epoch 9], [iter 30400 / 35967], [train loss 2.08685], [train acc 0.20664]\n",
      "[epoch 9], [iter 30500 / 35967], [train loss 2.08705], [train acc 0.20652]\n",
      "[epoch 9], [iter 30600 / 35967], [train loss 2.08714], [train acc 0.20647]\n",
      "[epoch 9], [iter 30700 / 35967], [train loss 2.08695], [train acc 0.20632]\n",
      "[epoch 9], [iter 30800 / 35967], [train loss 2.08689], [train acc 0.20640]\n",
      "[epoch 9], [iter 30900 / 35967], [train loss 2.08656], [train acc 0.20660]\n",
      "[epoch 9], [iter 31000 / 35967], [train loss 2.08635], [train acc 0.20690]\n",
      "[epoch 9], [iter 31100 / 35967], [train loss 2.08638], [train acc 0.20675]\n",
      "[epoch 9], [iter 31200 / 35967], [train loss 2.08629], [train acc 0.20673]\n",
      "[epoch 9], [iter 31300 / 35967], [train loss 2.08614], [train acc 0.20677]\n",
      "[epoch 9], [iter 31400 / 35967], [train loss 2.08609], [train acc 0.20675]\n",
      "[epoch 9], [iter 31500 / 35967], [train loss 2.08622], [train acc 0.20686]\n",
      "[epoch 9], [iter 31600 / 35967], [train loss 2.08654], [train acc 0.20677]\n",
      "[epoch 9], [iter 31700 / 35967], [train loss 2.08648], [train acc 0.20685]\n",
      "[epoch 9], [iter 31800 / 35967], [train loss 2.08654], [train acc 0.20695]\n",
      "[epoch 9], [iter 31900 / 35967], [train loss 2.08679], [train acc 0.20690]\n",
      "[epoch 9], [iter 32000 / 35967], [train loss 2.08664], [train acc 0.20703]\n",
      "[epoch 9], [iter 32100 / 35967], [train loss 2.08668], [train acc 0.20704]\n",
      "[epoch 9], [iter 32200 / 35967], [train loss 2.08666], [train acc 0.20699]\n",
      "[epoch 9], [iter 32300 / 35967], [train loss 2.08658], [train acc 0.20706]\n",
      "[epoch 9], [iter 32400 / 35967], [train loss 2.08636], [train acc 0.20713]\n",
      "[epoch 9], [iter 32500 / 35967], [train loss 2.08622], [train acc 0.20738]\n",
      "[epoch 9], [iter 32600 / 35967], [train loss 2.08645], [train acc 0.20755]\n",
      "[epoch 9], [iter 32700 / 35967], [train loss 2.08665], [train acc 0.20761]\n",
      "[epoch 9], [iter 32800 / 35967], [train loss 2.08638], [train acc 0.20780]\n",
      "[epoch 9], [iter 32900 / 35967], [train loss 2.08666], [train acc 0.20781]\n",
      "[epoch 9], [iter 33000 / 35967], [train loss 2.08653], [train acc 0.20803]\n",
      "[epoch 9], [iter 33100 / 35967], [train loss 2.08634], [train acc 0.20816]\n",
      "[epoch 9], [iter 33200 / 35967], [train loss 2.08635], [train acc 0.20837]\n",
      "[epoch 9], [iter 33300 / 35967], [train loss 2.08633], [train acc 0.20844]\n",
      "[epoch 9], [iter 33400 / 35967], [train loss 2.08641], [train acc 0.20844]\n",
      "[epoch 9], [iter 33500 / 35967], [train loss 2.08602], [train acc 0.20845]\n",
      "[epoch 9], [iter 33600 / 35967], [train loss 2.08591], [train acc 0.20860]\n",
      "[epoch 9], [iter 33700 / 35967], [train loss 2.08598], [train acc 0.20869]\n",
      "[epoch 9], [iter 33800 / 35967], [train loss 2.08580], [train acc 0.20885]\n",
      "[epoch 9], [iter 33900 / 35967], [train loss 2.08593], [train acc 0.20858]\n",
      "[epoch 9], [iter 34000 / 35967], [train loss 2.08588], [train acc 0.20876]\n",
      "[epoch 9], [iter 34100 / 35967], [train loss 2.08619], [train acc 0.20859]\n",
      "[epoch 9], [iter 34200 / 35967], [train loss 2.08627], [train acc 0.20860]\n",
      "[epoch 9], [iter 34300 / 35967], [train loss 2.08636], [train acc 0.20854]\n",
      "[epoch 9], [iter 34400 / 35967], [train loss 2.08653], [train acc 0.20849]\n",
      "[epoch 9], [iter 34500 / 35967], [train loss 2.08663], [train acc 0.20855]\n",
      "[epoch 9], [iter 34600 / 35967], [train loss 2.08676], [train acc 0.20867]\n",
      "[epoch 9], [iter 34700 / 35967], [train loss 2.08646], [train acc 0.20862]\n",
      "[epoch 9], [iter 34800 / 35967], [train loss 2.08636], [train acc 0.20853]\n",
      "[epoch 9], [iter 34900 / 35967], [train loss 2.08640], [train acc 0.20840]\n",
      "[epoch 9], [iter 35000 / 35967], [train loss 2.08600], [train acc 0.20854]\n",
      "[epoch 9], [iter 35100 / 35967], [train loss 2.08593], [train acc 0.20838]\n",
      "[epoch 9], [iter 35200 / 35967], [train loss 2.08601], [train acc 0.20847]\n",
      "[epoch 9], [iter 35300 / 35967], [train loss 2.08578], [train acc 0.20856]\n",
      "[epoch 9], [iter 35400 / 35967], [train loss 2.08577], [train acc 0.20842]\n",
      "[epoch 9], [iter 35500 / 35967], [train loss 2.08557], [train acc 0.20845]\n",
      "[epoch 9], [iter 35600 / 35967], [train loss 2.08555], [train acc 0.20857]\n",
      "[epoch 9], [iter 35700 / 35967], [train loss 2.08577], [train acc 0.20843]\n",
      "[epoch 9], [iter 35800 / 35967], [train loss 2.08564], [train acc 0.20844]\n",
      "[epoch 9], [iter 35900 / 35967], [train loss 2.08563], [train acc 0.20836]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 15.52687], [val acc 0.03264]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [iter 100 / 35967], [train loss 2.12820], [train acc 0.18000]\n",
      "[epoch 10], [iter 200 / 35967], [train loss 2.07363], [train acc 0.20500]\n",
      "[epoch 10], [iter 300 / 35967], [train loss 2.16043], [train acc 0.18000]\n",
      "[epoch 10], [iter 400 / 35967], [train loss 2.15733], [train acc 0.16500]\n",
      "[epoch 10], [iter 500 / 35967], [train loss 2.14147], [train acc 0.16600]\n",
      "[epoch 10], [iter 600 / 35967], [train loss 2.14038], [train acc 0.17000]\n",
      "[epoch 10], [iter 700 / 35967], [train loss 2.15021], [train acc 0.17286]\n",
      "[epoch 10], [iter 800 / 35967], [train loss 2.13128], [train acc 0.18750]\n",
      "[epoch 10], [iter 900 / 35967], [train loss 2.11864], [train acc 0.19111]\n",
      "[epoch 10], [iter 1000 / 35967], [train loss 2.12404], [train acc 0.19100]\n",
      "[epoch 10], [iter 1100 / 35967], [train loss 2.11853], [train acc 0.19273]\n",
      "[epoch 10], [iter 1200 / 35967], [train loss 2.11258], [train acc 0.19500]\n",
      "[epoch 10], [iter 1300 / 35967], [train loss 2.10855], [train acc 0.19692]\n",
      "[epoch 10], [iter 1400 / 35967], [train loss 2.11317], [train acc 0.19214]\n",
      "[epoch 10], [iter 1500 / 35967], [train loss 2.11631], [train acc 0.19067]\n",
      "[epoch 10], [iter 1600 / 35967], [train loss 2.11654], [train acc 0.19250]\n",
      "[epoch 10], [iter 1700 / 35967], [train loss 2.11478], [train acc 0.19059]\n",
      "[epoch 10], [iter 1800 / 35967], [train loss 2.11369], [train acc 0.18944]\n",
      "[epoch 10], [iter 1900 / 35967], [train loss 2.12283], [train acc 0.18895]\n",
      "[epoch 10], [iter 2000 / 35967], [train loss 2.12332], [train acc 0.18850]\n",
      "[epoch 10], [iter 2100 / 35967], [train loss 2.12131], [train acc 0.18905]\n",
      "[epoch 10], [iter 2200 / 35967], [train loss 2.11978], [train acc 0.18909]\n",
      "[epoch 10], [iter 2300 / 35967], [train loss 2.11887], [train acc 0.19087]\n",
      "[epoch 10], [iter 2400 / 35967], [train loss 2.12116], [train acc 0.19083]\n",
      "[epoch 10], [iter 2500 / 35967], [train loss 2.12372], [train acc 0.18840]\n",
      "[epoch 10], [iter 2600 / 35967], [train loss 2.12278], [train acc 0.18923]\n",
      "[epoch 10], [iter 2700 / 35967], [train loss 2.12507], [train acc 0.18815]\n",
      "[epoch 10], [iter 2800 / 35967], [train loss 2.12865], [train acc 0.18643]\n",
      "[epoch 10], [iter 2900 / 35967], [train loss 2.12487], [train acc 0.18793]\n",
      "[epoch 10], [iter 3000 / 35967], [train loss 2.12318], [train acc 0.18667]\n",
      "[epoch 10], [iter 3100 / 35967], [train loss 2.12515], [train acc 0.18548]\n",
      "[epoch 10], [iter 3200 / 35967], [train loss 2.12698], [train acc 0.18625]\n",
      "[epoch 10], [iter 3300 / 35967], [train loss 2.12518], [train acc 0.18515]\n",
      "[epoch 10], [iter 3400 / 35967], [train loss 2.12326], [train acc 0.18559]\n",
      "[epoch 10], [iter 3500 / 35967], [train loss 2.12566], [train acc 0.18571]\n",
      "[epoch 10], [iter 3600 / 35967], [train loss 2.12222], [train acc 0.18806]\n",
      "[epoch 10], [iter 3700 / 35967], [train loss 2.11818], [train acc 0.18919]\n",
      "[epoch 10], [iter 3800 / 35967], [train loss 2.11535], [train acc 0.18947]\n",
      "[epoch 10], [iter 3900 / 35967], [train loss 2.11582], [train acc 0.19231]\n",
      "[epoch 10], [iter 4000 / 35967], [train loss 2.11382], [train acc 0.19275]\n",
      "[epoch 10], [iter 4100 / 35967], [train loss 2.11872], [train acc 0.19268]\n",
      "[epoch 10], [iter 4200 / 35967], [train loss 2.11742], [train acc 0.19357]\n",
      "[epoch 10], [iter 4300 / 35967], [train loss 2.11610], [train acc 0.19442]\n",
      "[epoch 10], [iter 4400 / 35967], [train loss 2.11436], [train acc 0.19455]\n",
      "[epoch 10], [iter 4500 / 35967], [train loss 2.11367], [train acc 0.19689]\n",
      "[epoch 10], [iter 4600 / 35967], [train loss 2.10852], [train acc 0.19978]\n",
      "[epoch 10], [iter 4700 / 35967], [train loss 2.11032], [train acc 0.20000]\n",
      "[epoch 10], [iter 4800 / 35967], [train loss 2.10778], [train acc 0.20000]\n",
      "[epoch 10], [iter 4900 / 35967], [train loss 2.10953], [train acc 0.19918]\n",
      "[epoch 10], [iter 5000 / 35967], [train loss 2.10768], [train acc 0.20080]\n",
      "[epoch 10], [iter 5100 / 35967], [train loss 2.10950], [train acc 0.20059]\n",
      "[epoch 10], [iter 5200 / 35967], [train loss 2.11139], [train acc 0.19962]\n",
      "[epoch 10], [iter 5300 / 35967], [train loss 2.11094], [train acc 0.19943]\n",
      "[epoch 10], [iter 5400 / 35967], [train loss 2.10894], [train acc 0.19907]\n",
      "[epoch 10], [iter 5500 / 35967], [train loss 2.10727], [train acc 0.19982]\n",
      "[epoch 10], [iter 5600 / 35967], [train loss 2.10739], [train acc 0.19946]\n",
      "[epoch 10], [iter 5700 / 35967], [train loss 2.10531], [train acc 0.20018]\n",
      "[epoch 10], [iter 5800 / 35967], [train loss 2.10314], [train acc 0.20017]\n",
      "[epoch 10], [iter 5900 / 35967], [train loss 2.10231], [train acc 0.20119]\n",
      "[epoch 10], [iter 6000 / 35967], [train loss 2.10153], [train acc 0.20050]\n",
      "[epoch 10], [iter 6100 / 35967], [train loss 2.10146], [train acc 0.20066]\n",
      "[epoch 10], [iter 6200 / 35967], [train loss 2.10190], [train acc 0.20065]\n",
      "[epoch 10], [iter 6300 / 35967], [train loss 2.10273], [train acc 0.20111]\n",
      "[epoch 10], [iter 6400 / 35967], [train loss 2.10318], [train acc 0.20094]\n",
      "[epoch 10], [iter 6500 / 35967], [train loss 2.10468], [train acc 0.20077]\n",
      "[epoch 10], [iter 6600 / 35967], [train loss 2.10302], [train acc 0.20167]\n",
      "[epoch 10], [iter 6700 / 35967], [train loss 2.10409], [train acc 0.20149]\n",
      "[epoch 10], [iter 6800 / 35967], [train loss 2.10331], [train acc 0.20221]\n",
      "[epoch 10], [iter 6900 / 35967], [train loss 2.10412], [train acc 0.20261]\n",
      "[epoch 10], [iter 7000 / 35967], [train loss 2.10398], [train acc 0.20300]\n",
      "[epoch 10], [iter 7100 / 35967], [train loss 2.10306], [train acc 0.20394]\n",
      "[epoch 10], [iter 7200 / 35967], [train loss 2.10404], [train acc 0.20389]\n",
      "[epoch 10], [iter 7300 / 35967], [train loss 2.10350], [train acc 0.20438]\n",
      "[epoch 10], [iter 7400 / 35967], [train loss 2.10240], [train acc 0.20486]\n",
      "[epoch 10], [iter 7500 / 35967], [train loss 2.10258], [train acc 0.20560]\n",
      "[epoch 10], [iter 7600 / 35967], [train loss 2.10266], [train acc 0.20539]\n",
      "[epoch 10], [iter 7700 / 35967], [train loss 2.10221], [train acc 0.20584]\n",
      "[epoch 10], [iter 7800 / 35967], [train loss 2.10246], [train acc 0.20526]\n",
      "[epoch 10], [iter 7900 / 35967], [train loss 2.10172], [train acc 0.20595]\n",
      "[epoch 10], [iter 8000 / 35967], [train loss 2.10180], [train acc 0.20563]\n",
      "[epoch 10], [iter 8100 / 35967], [train loss 2.10106], [train acc 0.20580]\n",
      "[epoch 10], [iter 8200 / 35967], [train loss 2.10280], [train acc 0.20537]\n",
      "[epoch 10], [iter 8300 / 35967], [train loss 2.10293], [train acc 0.20542]\n",
      "[epoch 10], [iter 8400 / 35967], [train loss 2.10209], [train acc 0.20536]\n",
      "[epoch 10], [iter 8500 / 35967], [train loss 2.10140], [train acc 0.20576]\n",
      "[epoch 10], [iter 8600 / 35967], [train loss 2.10012], [train acc 0.20558]\n",
      "[epoch 10], [iter 8700 / 35967], [train loss 2.10031], [train acc 0.20529]\n",
      "[epoch 10], [iter 8800 / 35967], [train loss 2.10021], [train acc 0.20602]\n",
      "[epoch 10], [iter 8900 / 35967], [train loss 2.10089], [train acc 0.20596]\n",
      "[epoch 10], [iter 9000 / 35967], [train loss 2.10054], [train acc 0.20589]\n",
      "[epoch 10], [iter 9100 / 35967], [train loss 2.10176], [train acc 0.20582]\n",
      "[epoch 10], [iter 9200 / 35967], [train loss 2.10123], [train acc 0.20587]\n",
      "[epoch 10], [iter 9300 / 35967], [train loss 2.09980], [train acc 0.20656]\n",
      "[epoch 10], [iter 9400 / 35967], [train loss 2.09875], [train acc 0.20649]\n",
      "[epoch 10], [iter 9500 / 35967], [train loss 2.09706], [train acc 0.20726]\n",
      "[epoch 10], [iter 9600 / 35967], [train loss 2.09654], [train acc 0.20729]\n",
      "[epoch 10], [iter 9700 / 35967], [train loss 2.09691], [train acc 0.20722]\n",
      "[epoch 10], [iter 9800 / 35967], [train loss 2.09611], [train acc 0.20806]\n",
      "[epoch 10], [iter 9900 / 35967], [train loss 2.09535], [train acc 0.20828]\n",
      "[epoch 10], [iter 10000 / 35967], [train loss 2.09473], [train acc 0.20840]\n",
      "[epoch 10], [iter 10100 / 35967], [train loss 2.09532], [train acc 0.20812]\n",
      "[epoch 10], [iter 10200 / 35967], [train loss 2.09611], [train acc 0.20804]\n",
      "[epoch 10], [iter 10300 / 35967], [train loss 2.09580], [train acc 0.20777]\n",
      "[epoch 10], [iter 10400 / 35967], [train loss 2.09568], [train acc 0.20731]\n",
      "[epoch 10], [iter 10500 / 35967], [train loss 2.09465], [train acc 0.20771]\n",
      "[epoch 10], [iter 10600 / 35967], [train loss 2.09462], [train acc 0.20745]\n",
      "[epoch 10], [iter 10700 / 35967], [train loss 2.09342], [train acc 0.20766]\n",
      "[epoch 10], [iter 10800 / 35967], [train loss 2.09314], [train acc 0.20769]\n",
      "[epoch 10], [iter 10900 / 35967], [train loss 2.09261], [train acc 0.20807]\n",
      "[epoch 10], [iter 11000 / 35967], [train loss 2.09226], [train acc 0.20818]\n",
      "[epoch 10], [iter 11100 / 35967], [train loss 2.09250], [train acc 0.20802]\n",
      "[epoch 10], [iter 11200 / 35967], [train loss 2.09196], [train acc 0.20830]\n",
      "[epoch 10], [iter 11300 / 35967], [train loss 2.09225], [train acc 0.20832]\n",
      "[epoch 10], [iter 11400 / 35967], [train loss 2.09265], [train acc 0.20842]\n",
      "[epoch 10], [iter 11500 / 35967], [train loss 2.09233], [train acc 0.20809]\n",
      "[epoch 10], [iter 11600 / 35967], [train loss 2.09142], [train acc 0.20836]\n",
      "[epoch 10], [iter 11700 / 35967], [train loss 2.09231], [train acc 0.20846]\n",
      "[epoch 10], [iter 11800 / 35967], [train loss 2.09125], [train acc 0.20873]\n",
      "[epoch 10], [iter 11900 / 35967], [train loss 2.09092], [train acc 0.20849]\n",
      "[epoch 10], [iter 12000 / 35967], [train loss 2.09069], [train acc 0.20917]\n",
      "[epoch 10], [iter 12100 / 35967], [train loss 2.09042], [train acc 0.20934]\n",
      "[epoch 10], [iter 12200 / 35967], [train loss 2.09074], [train acc 0.20959]\n",
      "[epoch 10], [iter 12300 / 35967], [train loss 2.08994], [train acc 0.20976]\n",
      "[epoch 10], [iter 12400 / 35967], [train loss 2.09053], [train acc 0.20919]\n",
      "[epoch 10], [iter 12500 / 35967], [train loss 2.09040], [train acc 0.20912]\n",
      "[epoch 10], [iter 12600 / 35967], [train loss 2.09108], [train acc 0.20881]\n",
      "[epoch 10], [iter 12700 / 35967], [train loss 2.09047], [train acc 0.20866]\n",
      "[epoch 10], [iter 12800 / 35967], [train loss 2.09008], [train acc 0.20859]\n",
      "[epoch 10], [iter 12900 / 35967], [train loss 2.09024], [train acc 0.20822]\n",
      "[epoch 10], [iter 13000 / 35967], [train loss 2.09008], [train acc 0.20862]\n",
      "[epoch 10], [iter 13100 / 35967], [train loss 2.08971], [train acc 0.20924]\n",
      "[epoch 10], [iter 13200 / 35967], [train loss 2.08976], [train acc 0.20932]\n",
      "[epoch 10], [iter 13300 / 35967], [train loss 2.09036], [train acc 0.20932]\n",
      "[epoch 10], [iter 13400 / 35967], [train loss 2.08924], [train acc 0.21007]\n",
      "[epoch 10], [iter 13500 / 35967], [train loss 2.08887], [train acc 0.21015]\n",
      "[epoch 10], [iter 13600 / 35967], [train loss 2.08810], [train acc 0.21059]\n",
      "[epoch 10], [iter 13700 / 35967], [train loss 2.08760], [train acc 0.21036]\n",
      "[epoch 10], [iter 13800 / 35967], [train loss 2.08734], [train acc 0.21022]\n",
      "[epoch 10], [iter 13900 / 35967], [train loss 2.08690], [train acc 0.21079]\n",
      "[epoch 10], [iter 14000 / 35967], [train loss 2.08655], [train acc 0.21114]\n",
      "[epoch 10], [iter 14100 / 35967], [train loss 2.08655], [train acc 0.21135]\n",
      "[epoch 10], [iter 14200 / 35967], [train loss 2.08828], [train acc 0.21148]\n",
      "[epoch 10], [iter 14300 / 35967], [train loss 2.08808], [train acc 0.21168]\n",
      "[epoch 10], [iter 14400 / 35967], [train loss 2.08813], [train acc 0.21188]\n",
      "[epoch 10], [iter 14500 / 35967], [train loss 2.08840], [train acc 0.21159]\n",
      "[epoch 10], [iter 14600 / 35967], [train loss 2.08799], [train acc 0.21192]\n",
      "[epoch 10], [iter 14700 / 35967], [train loss 2.08775], [train acc 0.21224]\n",
      "[epoch 10], [iter 14800 / 35967], [train loss 2.08766], [train acc 0.21196]\n",
      "[epoch 10], [iter 14900 / 35967], [train loss 2.08659], [train acc 0.21215]\n",
      "[epoch 10], [iter 15000 / 35967], [train loss 2.08699], [train acc 0.21227]\n",
      "[epoch 10], [iter 15100 / 35967], [train loss 2.08807], [train acc 0.21225]\n",
      "[epoch 10], [iter 15200 / 35967], [train loss 2.08805], [train acc 0.21197]\n",
      "[epoch 10], [iter 15300 / 35967], [train loss 2.08790], [train acc 0.21203]\n",
      "[epoch 10], [iter 15400 / 35967], [train loss 2.08822], [train acc 0.21208]\n",
      "[epoch 10], [iter 15500 / 35967], [train loss 2.08818], [train acc 0.21181]\n",
      "[epoch 10], [iter 15600 / 35967], [train loss 2.08933], [train acc 0.21167]\n",
      "[epoch 10], [iter 15700 / 35967], [train loss 2.09005], [train acc 0.21121]\n",
      "[epoch 10], [iter 15800 / 35967], [train loss 2.08984], [train acc 0.21133]\n",
      "[epoch 10], [iter 15900 / 35967], [train loss 2.08873], [train acc 0.21170]\n",
      "[epoch 10], [iter 16000 / 35967], [train loss 2.08798], [train acc 0.21188]\n",
      "[epoch 10], [iter 16100 / 35967], [train loss 2.08817], [train acc 0.21180]\n",
      "[epoch 10], [iter 16200 / 35967], [train loss 2.08809], [train acc 0.21191]\n",
      "[epoch 10], [iter 16300 / 35967], [train loss 2.08860], [train acc 0.21147]\n",
      "[epoch 10], [iter 16400 / 35967], [train loss 2.08866], [train acc 0.21110]\n",
      "[epoch 10], [iter 16500 / 35967], [train loss 2.08898], [train acc 0.21109]\n",
      "[epoch 10], [iter 16600 / 35967], [train loss 2.08864], [train acc 0.21108]\n",
      "[epoch 10], [iter 16700 / 35967], [train loss 2.08933], [train acc 0.21078]\n",
      "[epoch 10], [iter 16800 / 35967], [train loss 2.08886], [train acc 0.21113]\n",
      "[epoch 10], [iter 16900 / 35967], [train loss 2.08835], [train acc 0.21118]\n",
      "[epoch 10], [iter 17000 / 35967], [train loss 2.08816], [train acc 0.21118]\n",
      "[epoch 10], [iter 17100 / 35967], [train loss 2.08829], [train acc 0.21094]\n",
      "[epoch 10], [iter 17200 / 35967], [train loss 2.08797], [train acc 0.21134]\n",
      "[epoch 10], [iter 17300 / 35967], [train loss 2.08773], [train acc 0.21133]\n",
      "[epoch 10], [iter 17400 / 35967], [train loss 2.08717], [train acc 0.21161]\n",
      "[epoch 10], [iter 17500 / 35967], [train loss 2.08715], [train acc 0.21114]\n",
      "[epoch 10], [iter 17600 / 35967], [train loss 2.08670], [train acc 0.21142]\n",
      "[epoch 10], [iter 17700 / 35967], [train loss 2.08647], [train acc 0.21158]\n",
      "[epoch 10], [iter 17800 / 35967], [train loss 2.08624], [train acc 0.21197]\n",
      "[epoch 10], [iter 17900 / 35967], [train loss 2.08521], [train acc 0.21212]\n",
      "[epoch 10], [iter 18000 / 35967], [train loss 2.08450], [train acc 0.21211]\n",
      "[epoch 10], [iter 18100 / 35967], [train loss 2.08430], [train acc 0.21210]\n",
      "[epoch 10], [iter 18200 / 35967], [train loss 2.08448], [train acc 0.21203]\n",
      "[epoch 10], [iter 18300 / 35967], [train loss 2.08512], [train acc 0.21202]\n",
      "[epoch 10], [iter 18400 / 35967], [train loss 2.08516], [train acc 0.21201]\n",
      "[epoch 10], [iter 18500 / 35967], [train loss 2.08541], [train acc 0.21189]\n",
      "[epoch 10], [iter 18600 / 35967], [train loss 2.08510], [train acc 0.21167]\n",
      "[epoch 10], [iter 18700 / 35967], [train loss 2.08563], [train acc 0.21139]\n",
      "[epoch 10], [iter 18800 / 35967], [train loss 2.08552], [train acc 0.21154]\n",
      "[epoch 10], [iter 18900 / 35967], [train loss 2.08597], [train acc 0.21169]\n",
      "[epoch 10], [iter 19000 / 35967], [train loss 2.08650], [train acc 0.21153]\n",
      "[epoch 10], [iter 19100 / 35967], [train loss 2.08717], [train acc 0.21141]\n",
      "[epoch 10], [iter 19200 / 35967], [train loss 2.08727], [train acc 0.21141]\n",
      "[epoch 10], [iter 19300 / 35967], [train loss 2.08725], [train acc 0.21135]\n",
      "[epoch 10], [iter 19400 / 35967], [train loss 2.08728], [train acc 0.21139]\n",
      "[epoch 10], [iter 19500 / 35967], [train loss 2.08666], [train acc 0.21195]\n",
      "[epoch 10], [iter 19600 / 35967], [train loss 2.08665], [train acc 0.21214]\n",
      "[epoch 10], [iter 19700 / 35967], [train loss 2.08628], [train acc 0.21218]\n",
      "[epoch 10], [iter 19800 / 35967], [train loss 2.08548], [train acc 0.21263]\n",
      "[epoch 10], [iter 19900 / 35967], [train loss 2.08484], [train acc 0.21296]\n",
      "[epoch 10], [iter 20000 / 35967], [train loss 2.08508], [train acc 0.21305]\n",
      "[epoch 10], [iter 20100 / 35967], [train loss 2.08510], [train acc 0.21313]\n",
      "[epoch 10], [iter 20200 / 35967], [train loss 2.08546], [train acc 0.21297]\n",
      "[epoch 10], [iter 20300 / 35967], [train loss 2.08592], [train acc 0.21310]\n",
      "[epoch 10], [iter 20400 / 35967], [train loss 2.08551], [train acc 0.21328]\n",
      "[epoch 10], [iter 20500 / 35967], [train loss 2.08626], [train acc 0.21302]\n",
      "[epoch 10], [iter 20600 / 35967], [train loss 2.08641], [train acc 0.21296]\n",
      "[epoch 10], [iter 20700 / 35967], [train loss 2.08647], [train acc 0.21275]\n",
      "[epoch 10], [iter 20800 / 35967], [train loss 2.08672], [train acc 0.21274]\n",
      "[epoch 10], [iter 20900 / 35967], [train loss 2.08643], [train acc 0.21297]\n",
      "[epoch 10], [iter 21000 / 35967], [train loss 2.08600], [train acc 0.21300]\n",
      "[epoch 10], [iter 21100 / 35967], [train loss 2.08594], [train acc 0.21308]\n",
      "[epoch 10], [iter 21200 / 35967], [train loss 2.08557], [train acc 0.21307]\n",
      "[epoch 10], [iter 21300 / 35967], [train loss 2.08585], [train acc 0.21282]\n",
      "[epoch 10], [iter 21400 / 35967], [train loss 2.08584], [train acc 0.21262]\n",
      "[epoch 10], [iter 21500 / 35967], [train loss 2.08562], [train acc 0.21260]\n",
      "[epoch 10], [iter 21600 / 35967], [train loss 2.08562], [train acc 0.21259]\n",
      "[epoch 10], [iter 21700 / 35967], [train loss 2.08537], [train acc 0.21244]\n",
      "[epoch 10], [iter 21800 / 35967], [train loss 2.08524], [train acc 0.21248]\n",
      "[epoch 10], [iter 21900 / 35967], [train loss 2.08509], [train acc 0.21274]\n",
      "[epoch 10], [iter 22000 / 35967], [train loss 2.08496], [train acc 0.21250]\n",
      "[epoch 10], [iter 22100 / 35967], [train loss 2.08513], [train acc 0.21253]\n",
      "[epoch 10], [iter 22200 / 35967], [train loss 2.08531], [train acc 0.21252]\n",
      "[epoch 10], [iter 22300 / 35967], [train loss 2.08506], [train acc 0.21260]\n",
      "[epoch 10], [iter 22400 / 35967], [train loss 2.08479], [train acc 0.21246]\n",
      "[epoch 10], [iter 22500 / 35967], [train loss 2.08477], [train acc 0.21222]\n",
      "[epoch 10], [iter 22600 / 35967], [train loss 2.08433], [train acc 0.21243]\n",
      "[epoch 10], [iter 22700 / 35967], [train loss 2.08431], [train acc 0.21229]\n",
      "[epoch 10], [iter 22800 / 35967], [train loss 2.08421], [train acc 0.21246]\n",
      "[epoch 10], [iter 22900 / 35967], [train loss 2.08389], [train acc 0.21245]\n",
      "[epoch 10], [iter 23000 / 35967], [train loss 2.08391], [train acc 0.21230]\n",
      "[epoch 10], [iter 23100 / 35967], [train loss 2.08359], [train acc 0.21260]\n",
      "[epoch 10], [iter 23200 / 35967], [train loss 2.08336], [train acc 0.21263]\n",
      "[epoch 10], [iter 23300 / 35967], [train loss 2.08316], [train acc 0.21270]\n",
      "[epoch 10], [iter 23400 / 35967], [train loss 2.08317], [train acc 0.21274]\n",
      "[epoch 10], [iter 23500 / 35967], [train loss 2.08285], [train acc 0.21285]\n",
      "[epoch 10], [iter 23600 / 35967], [train loss 2.08229], [train acc 0.21284]\n",
      "[epoch 10], [iter 23700 / 35967], [train loss 2.08258], [train acc 0.21283]\n",
      "[epoch 10], [iter 23800 / 35967], [train loss 2.08282], [train acc 0.21252]\n",
      "[epoch 10], [iter 23900 / 35967], [train loss 2.08278], [train acc 0.21247]\n",
      "[epoch 10], [iter 24000 / 35967], [train loss 2.08263], [train acc 0.21225]\n",
      "[epoch 10], [iter 24100 / 35967], [train loss 2.08221], [train acc 0.21245]\n",
      "[epoch 10], [iter 24200 / 35967], [train loss 2.08236], [train acc 0.21248]\n",
      "[epoch 10], [iter 24300 / 35967], [train loss 2.08194], [train acc 0.21267]\n",
      "[epoch 10], [iter 24400 / 35967], [train loss 2.08152], [train acc 0.21275]\n",
      "[epoch 10], [iter 24500 / 35967], [train loss 2.08122], [train acc 0.21269]\n",
      "[epoch 10], [iter 24600 / 35967], [train loss 2.08137], [train acc 0.21252]\n",
      "[epoch 10], [iter 24700 / 35967], [train loss 2.08146], [train acc 0.21251]\n",
      "[epoch 10], [iter 24800 / 35967], [train loss 2.08138], [train acc 0.21250]\n",
      "[epoch 10], [iter 24900 / 35967], [train loss 2.08189], [train acc 0.21225]\n",
      "[epoch 10], [iter 25000 / 35967], [train loss 2.08191], [train acc 0.21228]\n",
      "[epoch 10], [iter 25100 / 35967], [train loss 2.08216], [train acc 0.21219]\n",
      "[epoch 10], [iter 25200 / 35967], [train loss 2.08238], [train acc 0.21210]\n",
      "[epoch 10], [iter 25300 / 35967], [train loss 2.08193], [train acc 0.21225]\n",
      "[epoch 10], [iter 25400 / 35967], [train loss 2.08211], [train acc 0.21224]\n",
      "[epoch 10], [iter 25500 / 35967], [train loss 2.08235], [train acc 0.21227]\n",
      "[epoch 10], [iter 25600 / 35967], [train loss 2.08212], [train acc 0.21230]\n",
      "[epoch 10], [iter 25700 / 35967], [train loss 2.08229], [train acc 0.21222]\n",
      "[epoch 10], [iter 25800 / 35967], [train loss 2.08219], [train acc 0.21209]\n",
      "[epoch 10], [iter 25900 / 35967], [train loss 2.08212], [train acc 0.21205]\n",
      "[epoch 10], [iter 26000 / 35967], [train loss 2.08210], [train acc 0.21196]\n",
      "[epoch 10], [iter 26100 / 35967], [train loss 2.08187], [train acc 0.21195]\n",
      "[epoch 10], [iter 26200 / 35967], [train loss 2.08149], [train acc 0.21191]\n",
      "[epoch 10], [iter 26300 / 35967], [train loss 2.08157], [train acc 0.21183]\n",
      "[epoch 10], [iter 26400 / 35967], [train loss 2.08197], [train acc 0.21170]\n",
      "[epoch 10], [iter 26500 / 35967], [train loss 2.08166], [train acc 0.21170]\n",
      "[epoch 10], [iter 26600 / 35967], [train loss 2.08139], [train acc 0.21173]\n",
      "[epoch 10], [iter 26700 / 35967], [train loss 2.08163], [train acc 0.21176]\n",
      "[epoch 10], [iter 26800 / 35967], [train loss 2.08137], [train acc 0.21187]\n",
      "[epoch 10], [iter 26900 / 35967], [train loss 2.08153], [train acc 0.21171]\n",
      "[epoch 10], [iter 27000 / 35967], [train loss 2.08139], [train acc 0.21178]\n",
      "[epoch 10], [iter 27100 / 35967], [train loss 2.08099], [train acc 0.21203]\n",
      "[epoch 10], [iter 27200 / 35967], [train loss 2.08118], [train acc 0.21195]\n",
      "[epoch 10], [iter 27300 / 35967], [train loss 2.08118], [train acc 0.21201]\n",
      "[epoch 10], [iter 27400 / 35967], [train loss 2.08112], [train acc 0.21197]\n",
      "[epoch 10], [iter 27500 / 35967], [train loss 2.08100], [train acc 0.21207]\n",
      "[epoch 10], [iter 27600 / 35967], [train loss 2.08106], [train acc 0.21196]\n",
      "[epoch 10], [iter 27700 / 35967], [train loss 2.08081], [train acc 0.21217]\n",
      "[epoch 10], [iter 27800 / 35967], [train loss 2.08090], [train acc 0.21205]\n",
      "[epoch 10], [iter 27900 / 35967], [train loss 2.08102], [train acc 0.21219]\n",
      "[epoch 10], [iter 28000 / 35967], [train loss 2.08092], [train acc 0.21204]\n",
      "[epoch 10], [iter 28100 / 35967], [train loss 2.08064], [train acc 0.21235]\n",
      "[epoch 10], [iter 28200 / 35967], [train loss 2.08067], [train acc 0.21252]\n",
      "[epoch 10], [iter 28300 / 35967], [train loss 2.08019], [train acc 0.21258]\n",
      "[epoch 10], [iter 28400 / 35967], [train loss 2.08039], [train acc 0.21254]\n",
      "[epoch 10], [iter 28500 / 35967], [train loss 2.08062], [train acc 0.21253]\n",
      "[epoch 10], [iter 28600 / 35967], [train loss 2.08049], [train acc 0.21234]\n",
      "[epoch 10], [iter 28700 / 35967], [train loss 2.08061], [train acc 0.21220]\n",
      "[epoch 10], [iter 28800 / 35967], [train loss 2.07986], [train acc 0.21233]\n",
      "[epoch 10], [iter 28900 / 35967], [train loss 2.07990], [train acc 0.21221]\n",
      "[epoch 10], [iter 29000 / 35967], [train loss 2.08007], [train acc 0.21203]\n",
      "[epoch 10], [iter 29100 / 35967], [train loss 2.07968], [train acc 0.21216]\n",
      "[epoch 10], [iter 29200 / 35967], [train loss 2.07982], [train acc 0.21212]\n",
      "[epoch 10], [iter 29300 / 35967], [train loss 2.07982], [train acc 0.21212]\n",
      "[epoch 10], [iter 29400 / 35967], [train loss 2.07962], [train acc 0.21228]\n",
      "[epoch 10], [iter 29500 / 35967], [train loss 2.07925], [train acc 0.21237]\n",
      "[epoch 10], [iter 29600 / 35967], [train loss 2.07964], [train acc 0.21233]\n",
      "[epoch 10], [iter 29700 / 35967], [train loss 2.07980], [train acc 0.21215]\n",
      "[epoch 10], [iter 29800 / 35967], [train loss 2.07933], [train acc 0.21232]\n",
      "[epoch 10], [iter 29900 / 35967], [train loss 2.07878], [train acc 0.21278]\n",
      "[epoch 10], [iter 30000 / 35967], [train loss 2.07881], [train acc 0.21290]\n",
      "[epoch 10], [iter 30100 / 35967], [train loss 2.07919], [train acc 0.21292]\n",
      "[epoch 10], [iter 30200 / 35967], [train loss 2.07957], [train acc 0.21268]\n",
      "[epoch 10], [iter 30300 / 35967], [train loss 2.07990], [train acc 0.21284]\n",
      "[epoch 10], [iter 30400 / 35967], [train loss 2.08006], [train acc 0.21266]\n",
      "[epoch 10], [iter 30500 / 35967], [train loss 2.08026], [train acc 0.21269]\n",
      "[epoch 10], [iter 30600 / 35967], [train loss 2.08052], [train acc 0.21258]\n",
      "[epoch 10], [iter 30700 / 35967], [train loss 2.08032], [train acc 0.21274]\n",
      "[epoch 10], [iter 30800 / 35967], [train loss 2.08050], [train acc 0.21266]\n",
      "[epoch 10], [iter 30900 / 35967], [train loss 2.08066], [train acc 0.21269]\n",
      "[epoch 10], [iter 31000 / 35967], [train loss 2.08046], [train acc 0.21271]\n",
      "[epoch 10], [iter 31100 / 35967], [train loss 2.08060], [train acc 0.21273]\n",
      "[epoch 10], [iter 31200 / 35967], [train loss 2.08072], [train acc 0.21269]\n",
      "[epoch 10], [iter 31300 / 35967], [train loss 2.08117], [train acc 0.21268]\n",
      "[epoch 10], [iter 31400 / 35967], [train loss 2.08114], [train acc 0.21268]\n",
      "[epoch 10], [iter 31500 / 35967], [train loss 2.08088], [train acc 0.21283]\n",
      "[epoch 10], [iter 31600 / 35967], [train loss 2.08125], [train acc 0.21272]\n",
      "[epoch 10], [iter 31700 / 35967], [train loss 2.08131], [train acc 0.21262]\n",
      "[epoch 10], [iter 31800 / 35967], [train loss 2.08110], [train acc 0.21261]\n",
      "[epoch 10], [iter 31900 / 35967], [train loss 2.08113], [train acc 0.21257]\n",
      "[epoch 10], [iter 32000 / 35967], [train loss 2.08125], [train acc 0.21241]\n",
      "[epoch 10], [iter 32100 / 35967], [train loss 2.08131], [train acc 0.21234]\n",
      "[epoch 10], [iter 32200 / 35967], [train loss 2.08139], [train acc 0.21236]\n",
      "[epoch 10], [iter 32300 / 35967], [train loss 2.08161], [train acc 0.21238]\n",
      "[epoch 10], [iter 32400 / 35967], [train loss 2.08142], [train acc 0.21244]\n",
      "[epoch 10], [iter 32500 / 35967], [train loss 2.08146], [train acc 0.21231]\n",
      "[epoch 10], [iter 32600 / 35967], [train loss 2.08137], [train acc 0.21233]\n",
      "[epoch 10], [iter 32700 / 35967], [train loss 2.08146], [train acc 0.21239]\n",
      "[epoch 10], [iter 32800 / 35967], [train loss 2.08072], [train acc 0.21253]\n",
      "[epoch 10], [iter 32900 / 35967], [train loss 2.08081], [train acc 0.21249]\n",
      "[epoch 10], [iter 33000 / 35967], [train loss 2.08081], [train acc 0.21245]\n",
      "[epoch 10], [iter 33100 / 35967], [train loss 2.08086], [train acc 0.21251]\n",
      "[epoch 10], [iter 33200 / 35967], [train loss 2.08082], [train acc 0.21262]\n",
      "[epoch 10], [iter 33300 / 35967], [train loss 2.08101], [train acc 0.21246]\n",
      "[epoch 10], [iter 33400 / 35967], [train loss 2.08150], [train acc 0.21246]\n",
      "[epoch 10], [iter 33500 / 35967], [train loss 2.08188], [train acc 0.21260]\n",
      "[epoch 10], [iter 33600 / 35967], [train loss 2.08162], [train acc 0.21265]\n",
      "[epoch 10], [iter 33700 / 35967], [train loss 2.08118], [train acc 0.21264]\n",
      "[epoch 10], [iter 33800 / 35967], [train loss 2.08091], [train acc 0.21278]\n",
      "[epoch 10], [iter 33900 / 35967], [train loss 2.08044], [train acc 0.21277]\n",
      "[epoch 10], [iter 34000 / 35967], [train loss 2.08016], [train acc 0.21312]\n",
      "[epoch 10], [iter 34100 / 35967], [train loss 2.08021], [train acc 0.21299]\n",
      "[epoch 10], [iter 34200 / 35967], [train loss 2.08009], [train acc 0.21304]\n",
      "[epoch 10], [iter 34300 / 35967], [train loss 2.08031], [train acc 0.21294]\n",
      "[epoch 10], [iter 34400 / 35967], [train loss 2.08036], [train acc 0.21314]\n",
      "[epoch 10], [iter 34500 / 35967], [train loss 2.08062], [train acc 0.21296]\n",
      "[epoch 10], [iter 34600 / 35967], [train loss 2.08033], [train acc 0.21280]\n",
      "[epoch 10], [iter 34700 / 35967], [train loss 2.08001], [train acc 0.21294]\n",
      "[epoch 10], [iter 34800 / 35967], [train loss 2.07991], [train acc 0.21290]\n",
      "[epoch 10], [iter 34900 / 35967], [train loss 2.07989], [train acc 0.21298]\n",
      "[epoch 10], [iter 35000 / 35967], [train loss 2.07977], [train acc 0.21294]\n",
      "[epoch 10], [iter 35100 / 35967], [train loss 2.07938], [train acc 0.21308]\n",
      "[epoch 10], [iter 35200 / 35967], [train loss 2.07914], [train acc 0.21313]\n",
      "[epoch 10], [iter 35300 / 35967], [train loss 2.07897], [train acc 0.21320]\n",
      "[epoch 10], [iter 35400 / 35967], [train loss 2.07882], [train acc 0.21314]\n",
      "[epoch 10], [iter 35500 / 35967], [train loss 2.07863], [train acc 0.21313]\n",
      "[epoch 10], [iter 35600 / 35967], [train loss 2.07863], [train acc 0.21315]\n",
      "[epoch 10], [iter 35700 / 35967], [train loss 2.07845], [train acc 0.21322]\n",
      "[epoch 10], [iter 35800 / 35967], [train loss 2.07815], [train acc 0.21321]\n",
      "[epoch 10], [iter 35900 / 35967], [train loss 2.07855], [train acc 0.21323]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [val loss 11.60054], [val acc 0.09882]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(num = 2)\n",
    "fig1 = fig.add_subplot(2,1,1)\n",
    "fig2 = fig.add_subplot(2,1,2)\n",
    "fig1.plot(total_loss_train, label = 'training loss')\n",
    "fig1.plot(total_acc_train, label = 'training accuracy')\n",
    "fig2.plot(total_loss_val, label = 'validation loss')\n",
    "fig2.plot(total_acc_val, label = 'validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m         prediction \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     11\u001b[0m         y_label\u001b[39m.\u001b[39mextend(labels\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m---> 12\u001b[0m         y_predict\u001b[39m.\u001b[39;49mextend(np\u001b[39m.\u001b[39;49msqueeze(prediction\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39;49mT))\n\u001b[0;32m     14\u001b[0m \u001b[39m# compute the confusion matrix\u001b[39;00m\n\u001b[0;32m     15\u001b[0m confusion_mtx \u001b[39m=\u001b[39m confusion_matrix(y_label, y_predict)\n",
      "\u001b[1;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_label = []\n",
    "y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        y_label.extend(labels.cpu().numpy())\n",
    "        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_label, y_predict)\n",
    "# plot the confusion matrix\n",
    "plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\n",
    "plot_confusion_matrix(confusion_mtx, plot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Generate a classification report\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m report \u001b[39m=\u001b[39m classification_report(y_label, y_predict, target_names\u001b[39m=\u001b[39mplot_labels)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(report)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "report = classification_report(y_label, y_predict, target_names=plot_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_mtx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m label_frac_error \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdiag(confusion_mtx) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(confusion_mtx, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mbar(np\u001b[39m.\u001b[39marange(\u001b[39m7\u001b[39m),label_frac_error)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mTrue Label\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_mtx' is not defined"
     ]
    }
   ],
   "source": [
    "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
    "plt.bar(np.arange(7),label_frac_error)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction classified incorrectly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to train with different network structures. When using Densenet-121, the average accuracy of 7 classes on the validation set can reach 92% in 10 epochs. We also calculated the confusion matrix for all classes and the F1-score for each class, which is a more comprehensive indicator that can take into account both the precision and recall of the classification model.Our model can achieve more than 90% on the F1-score indicator.\n",
    "\n",
    "Due to limited time, we did not spend much time on model training. By increasing in training epochs, adjustmenting of model hyperparameters, and attempting at different networks may further enhance the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use image data and patient case data at the same time, my plan is to use CNN to extract features from images, use xgboost to convert medical records into vectors and then concat them with CNN network full-layer features. Two branch networks are trained simultaneously using a loss function. We can refer to the methods used in the advertising CTR estimation task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
