{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very interesting task and it's very suitable for beginners, through this task you can learn about data analysis, data processing, model building, model training, parameter optimization and so on. When only use the images, with a common network, such as Resnet, Densenet, you can achieve a relatively good accuracy very easily. \n",
    "\n",
    "By analyzing the data, the basic information of the patient is also related to the classification of the diseased tissue. Therefore, if we can combine the case information to carry out the classification task, it will be a very meaningful work. Actually during clinical diagnosis, doctors will also combine different modal data to make comprehensive judgments.\n",
    "\n",
    "Due to the urgency of time, my current method only uses image data, and then I will consider adding the patient's personal information to the classification task to train a more complete model. I will update my kernel immediately once I finished.\n",
    "\n",
    "Before you really start, I strongly recommend you to read the material of pigmented lesions and dermatoscopic images[https://arxiv.org/abs/1803.10417]. After that, you can learn about the characteristics and distribution of the data from the task description and this kernel[https://www.kaggle.com/kmader/dermatology-mnist-loading-and-processing]\n",
    "\n",
    "In this kernel I have followed following steps for model building and evaluation: \n",
    "\n",
    "> Step 1. Data analysis and preprocessing\n",
    "\n",
    "> Step 2. Model building\n",
    "\n",
    "> Step 3. Model training\n",
    "\n",
    "> Step 4. Model evaluation\n",
    "\n",
    "I used the pytorch framework to complete the entire task. The code contains several common networks, such as Resnet, VGG, Densenet, and Inception. You only need to make minor changes on the code to complete the network switch. Without the hyperparameter adjustment, I used **Densenet-121 to achieve an accuracy of more than 90% on the validation set in 10 epochs.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### First, import all libraries that used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'archive', 'skin-lesion-classification-acc-90-pytorch.ipynb', 'test_database']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# python libraties\n",
    "import os, cv2,itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# to make the results are reproducible\n",
    "np.random.seed(10)\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Data analysis and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the all image data paths, match the row information in HAM10000_metadata.csv with its corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_dir = '../input/archive' #database directory\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*.jpg')) #find all files with jpg extension in database directory\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path} #map base filaname to its path\n",
    "\n",
    "#TODO: this might be modified to only accomodate for malignant vs benign tumors\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to compute the mean and standard deviation on the whole dataset, will use for inputs normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_img_mean_std(image_paths):\n",
    "    \"\"\"\n",
    "        computing the mean and std of three channel on the whole dataset,\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "\n",
    "    img_h, img_w = 224, 224\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    means.reverse()  # BGR --> RGB\n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    return means,stdevs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the mean and std of RGB channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10015/10015 [02:40<00:00, 62.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3, 10015)\n",
      "normMean = [0.7630327, 0.5456458, 0.5700465]\n",
      "normStd = [0.14092782, 0.15261382, 0.16997577]\n"
     ]
    }
   ],
   "source": [
    "norm_mean,norm_std = compute_img_mean_std(all_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add three columns to the original DataFrame:\n",
    "-path (image path)\n",
    "-cell_type (the whole name),\n",
    "-cell_type_idx (the corresponding index  of cell type, as the image label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_1\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_1\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_1\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_1\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_2\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path  \\\n",
       "0  ../input/archive\\HAM10000_images_part_1\\ISIC_0...   \n",
       "1  ../input/archive\\HAM10000_images_part_1\\ISIC_0...   \n",
       "2  ../input/archive\\HAM10000_images_part_1\\ISIC_0...   \n",
       "3  ../input/archive\\HAM10000_images_part_1\\ISIC_0...   \n",
       "4  ../input/archive\\HAM10000_images_part_2\\ISIC_0...   \n",
       "\n",
       "                        cell_type  cell_type_idx  \n",
       "0  Benign keratosis-like lesions               2  \n",
       "1  Benign keratosis-like lesions               2  \n",
       "2  Benign keratosis-like lesions               2  \n",
       "3  Benign keratosis-like lesions               2  \n",
       "4  Benign keratosis-like lesions               2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(os.path.join(data_dir, 'HAM10000_metadata.csv'))\n",
    "df_original['path'] = df_original['image_id'].map(imageid_path_dict.get)\n",
    "df_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)\n",
    "df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10015"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5514\n"
     ]
    }
   ],
   "source": [
    "# this will tell us how many images are associated with each lesion_id\n",
    "df_undup = df_original.groupby('lesion_id').count()\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "df_undup.reset_index(inplace=True)\n",
    "df_undup.head()\n",
    "print(len(df_undup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "      <th>duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_1\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_1\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_1\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_1\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>../input/archive\\HAM10000_images_part_2\\ISIC_0...</td>\n",
       "      <td>Benign keratosis-like lesions</td>\n",
       "      <td>2</td>\n",
       "      <td>duplicated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path  \\\n",
       "0  ../input/archive\\HAM10000_images_part_1\\ISIC_0...   \n",
       "1  ../input/archive\\HAM10000_images_part_1\\ISIC_0...   \n",
       "2  ../input/archive\\HAM10000_images_part_1\\ISIC_0...   \n",
       "3  ../input/archive\\HAM10000_images_part_1\\ISIC_0...   \n",
       "4  ../input/archive\\HAM10000_images_part_2\\ISIC_0...   \n",
       "\n",
       "                        cell_type  cell_type_idx  duplicates  \n",
       "0  Benign keratosis-like lesions               2  duplicated  \n",
       "1  Benign keratosis-like lesions               2  duplicated  \n",
       "2  Benign keratosis-like lesions               2  duplicated  \n",
       "3  Benign keratosis-like lesions               2  duplicated  \n",
       "4  Benign keratosis-like lesions               2  duplicated  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we identify lesion_id's that have duplicate images and those that have only one image.\n",
    "def get_duplicates(x):\n",
    "    unique_list = list(df_undup['lesion_id'])\n",
    "    if x in unique_list:\n",
    "        return 'unduplicated'\n",
    "    else:\n",
    "        return 'duplicated'\n",
    "\n",
    "# create a new colum that is a copy of the lesion_id column\n",
    "df_original['duplicates'] = df_original['lesion_id']\n",
    "# apply the function to this new column\n",
    "df_original['duplicates'] = df_original['duplicates'].apply(get_duplicates)\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unduplicated    5514\n",
       "duplicated      4501\n",
       "Name: duplicates, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5514, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we filter out images that don't have duplicates\n",
    "df_undup = df_original[df_original['duplicates'] == 'unduplicated']\n",
    "df_undup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we create a validation set using df because we are sure that none of these images have augmented duplicates in the train set\n",
    "y = df_undup['cell_type_idx']\n",
    "_, df_val = train_test_split(df_undup, test_size=0.2, random_state=101, stratify=y)\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    883\n",
       "2     88\n",
       "5     46\n",
       "1     35\n",
       "0     30\n",
       "6     13\n",
       "3      8\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8912\n",
      "1103\n"
     ]
    }
   ],
   "source": [
    "# This set will be df_original excluding all rows that are in the val set\n",
    "# This function identifies if an image is part of the train or val set.\n",
    "def get_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_original['train_or_val'] = df_original['image_id']\n",
    "# apply the function to this new column\n",
    "df_original['train_or_val'] = df_original['train_or_val'].apply(get_val_rows)\n",
    "# filter out train rows\n",
    "df_train = df_original[df_original['train_or_val'] == 'train']\n",
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi                  5822\n",
       "Melanoma                          1067\n",
       "Benign keratosis-like lesions     1011\n",
       "Basal cell carcinoma               479\n",
       "Actinic keratoses                  297\n",
       "Vascular lesions                   129\n",
       "Dermatofibroma                     107\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanocytic nevi                  883\n",
       "Benign keratosis-like lesions      88\n",
       "Melanoma                           46\n",
       "Basal cell carcinoma               35\n",
       "Actinic keratoses                  30\n",
       "Vascular lesions                   13\n",
       "Dermatofibroma                      8\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From From the above statistics of each category, we can see that there is a serious class imbalance in the training data. To solve this problem, I think we can start from two aspects, one is equalization sampling, and the other is a loss function that can be used to mitigate category imbalance during training, such as focal loss.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Melanoma                          42680\n",
       "Melanocytic nevi                   5822\n",
       "Dermatofibroma                     5350\n",
       "Benign keratosis-like lesions      5055\n",
       "Basal cell carcinoma               4790\n",
       "Actinic keratoses                  4455\n",
       "Vascular lesions                    645\n",
       "Name: cell_type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy fewer class to balance the number of 7 classes\n",
    "data_aug_rate = [15,10,5,50,0,40,5]\n",
    "for i in range(7):\n",
    "    if data_aug_rate[i]:\n",
    "        df_train=df_train.append([df_train.loc[df_train['cell_type_idx'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n",
    "df_train['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning, I divided the data into three parts, training set, validation set and test set. Considering the small amount of data, I did not further divide the validation set data in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can split the test set again in a validation set and a true test set:\n",
    "# df_val, df_test = train_test_split(df_val, test_size=0.5)\n",
    "df_train = df_train.reset_index()\n",
    "df_val = df_val.reset_index()\n",
    "# df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28240/1583968764.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extract is a boolean that defines if we are finetuning or feature extracting. \n",
    "# If feature_extract = False, the model is finetuned and all model parameters are updated. \n",
    "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18, resnet34, resnet50, resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet121\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change your backbone network, here are 4 different networks, each network also has sevaral versions. Considering the limited training data, we used the ImageNet pre-training model for fine-tuning. This can speed up the convergence of the model and improve the accuracy.\n",
    "\n",
    "There is one thing you need to pay attention to, the input size of Inception is different from the others (299x299), you need to change the setting of compute_img_mean_std() function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# resnet,vgg,densenet,inception\n",
    "model_name = 'densenet'\n",
    "num_classes = 7\n",
    "feature_extract = False\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") #on laptop, use cpu torch\n",
    "\n",
    "# device = torch.device('cuda:0')\n",
    "print(device)\n",
    "# Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_mean = (0.49139968, 0.48215827, 0.44653124)\n",
    "# norm_std = (0.24703233, 0.24348505, 0.26158768)\n",
    "# define the transformation of the train images.\n",
    "train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)])\n",
    "# define the transformation of the val images.\n",
    "val_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pytorch dataloader for this dataset\n",
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index])\n",
    "        y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28240/3276026331.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training set using the table train_df and using our defined transitions (train_transform)\n",
    "training_set = HAM10000(df_train, transform=train_transform)\n",
    "#NOTE: previously set batch_size to 32\n",
    "train_loader = DataLoader(training_set, shuffle=True)\n",
    "#train_loader = DataLoader(training_set, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "# Same for the validation set:\n",
    "validation_set = HAM10000(df_val, transform=train_transform)\n",
    "val_loader = DataLoader(validation_set, shuffle=False)\n",
    "#val_loader = DataLoader(validation_set, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use Adam optimizer, use cross entropy loss as our loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used during training, to compute the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        #print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 100 / 3127], [train loss 2.29561], [train acc 0.08000]\n",
      "[epoch 1], [iter 200 / 3127], [train loss 2.19931], [train acc 0.15500]\n",
      "[epoch 1], [iter 300 / 3127], [train loss 2.18325], [train acc 0.15000]\n",
      "[epoch 1], [iter 400 / 3127], [train loss 2.13940], [train acc 0.16250]\n",
      "[epoch 1], [iter 500 / 3127], [train loss 2.14568], [train acc 0.15400]\n",
      "[epoch 1], [iter 600 / 3127], [train loss 2.14581], [train acc 0.14833]\n",
      "[epoch 1], [iter 700 / 3127], [train loss 2.13724], [train acc 0.15286]\n",
      "[epoch 1], [iter 800 / 3127], [train loss 2.12747], [train acc 0.14750]\n",
      "[epoch 1], [iter 900 / 3127], [train loss 2.12911], [train acc 0.14333]\n",
      "[epoch 1], [iter 1000 / 3127], [train loss 2.13106], [train acc 0.14100]\n",
      "[epoch 1], [iter 1100 / 3127], [train loss 2.13186], [train acc 0.13636]\n",
      "[epoch 1], [iter 1200 / 3127], [train loss 2.13000], [train acc 0.13667]\n",
      "[epoch 1], [iter 1300 / 3127], [train loss 2.12979], [train acc 0.13769]\n",
      "[epoch 1], [iter 1400 / 3127], [train loss 2.12930], [train acc 0.13857]\n",
      "[epoch 1], [iter 1500 / 3127], [train loss 2.12586], [train acc 0.13933]\n",
      "[epoch 1], [iter 1600 / 3127], [train loss 2.11841], [train acc 0.14062]\n",
      "[epoch 1], [iter 1700 / 3127], [train loss 2.11189], [train acc 0.14176]\n",
      "[epoch 1], [iter 1800 / 3127], [train loss 2.11148], [train acc 0.14167]\n",
      "[epoch 1], [iter 1900 / 3127], [train loss 2.11380], [train acc 0.14263]\n",
      "[epoch 1], [iter 2000 / 3127], [train loss 2.11292], [train acc 0.13950]\n",
      "[epoch 1], [iter 2100 / 3127], [train loss 2.11126], [train acc 0.13952]\n",
      "[epoch 1], [iter 2200 / 3127], [train loss 2.10904], [train acc 0.14091]\n",
      "[epoch 1], [iter 2300 / 3127], [train loss 2.10477], [train acc 0.14174]\n",
      "[epoch 1], [iter 2400 / 3127], [train loss 2.10403], [train acc 0.14292]\n",
      "[epoch 1], [iter 2500 / 3127], [train loss 2.10157], [train acc 0.14280]\n",
      "[epoch 1], [iter 2600 / 3127], [train loss 2.09823], [train acc 0.14269]\n",
      "[epoch 1], [iter 2700 / 3127], [train loss 2.09733], [train acc 0.14333]\n",
      "[epoch 1], [iter 2800 / 3127], [train loss 2.09688], [train acc 0.14250]\n",
      "[epoch 1], [iter 2900 / 3127], [train loss 2.09554], [train acc 0.14345]\n",
      "[epoch 1], [iter 3000 / 3127], [train loss 2.09430], [train acc 0.14233]\n",
      "[epoch 1], [iter 3100 / 3127], [train loss 2.09406], [train acc 0.14290]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 3.34706], [val acc 0.69634]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 1], [val loss 3.34706], [val acc 0.69634]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 / 3127], [train loss 2.03090], [train acc 0.16000]\n",
      "[epoch 2], [iter 200 / 3127], [train loss 2.05941], [train acc 0.13000]\n",
      "[epoch 2], [iter 300 / 3127], [train loss 2.05688], [train acc 0.12000]\n",
      "[epoch 2], [iter 400 / 3127], [train loss 2.05503], [train acc 0.13000]\n",
      "[epoch 2], [iter 500 / 3127], [train loss 2.04054], [train acc 0.15200]\n",
      "[epoch 2], [iter 600 / 3127], [train loss 2.04915], [train acc 0.14333]\n",
      "[epoch 2], [iter 700 / 3127], [train loss 2.04499], [train acc 0.14000]\n",
      "[epoch 2], [iter 800 / 3127], [train loss 2.04207], [train acc 0.14875]\n",
      "[epoch 2], [iter 900 / 3127], [train loss 2.03828], [train acc 0.14889]\n",
      "[epoch 2], [iter 1000 / 3127], [train loss 2.03860], [train acc 0.14700]\n",
      "[epoch 2], [iter 1100 / 3127], [train loss 2.03936], [train acc 0.14727]\n",
      "[epoch 2], [iter 1200 / 3127], [train loss 2.03499], [train acc 0.14417]\n",
      "[epoch 2], [iter 1300 / 3127], [train loss 2.03533], [train acc 0.14769]\n",
      "[epoch 2], [iter 1400 / 3127], [train loss 2.03543], [train acc 0.14571]\n",
      "[epoch 2], [iter 1500 / 3127], [train loss 2.03495], [train acc 0.14467]\n",
      "[epoch 2], [iter 1600 / 3127], [train loss 2.03413], [train acc 0.14938]\n",
      "[epoch 2], [iter 1700 / 3127], [train loss 2.03474], [train acc 0.14941]\n",
      "[epoch 2], [iter 1800 / 3127], [train loss 2.03307], [train acc 0.15056]\n",
      "[epoch 2], [iter 1900 / 3127], [train loss 2.02640], [train acc 0.15105]\n",
      "[epoch 2], [iter 2000 / 3127], [train loss 2.02374], [train acc 0.15350]\n",
      "[epoch 2], [iter 2100 / 3127], [train loss 2.02635], [train acc 0.15095]\n",
      "[epoch 2], [iter 2200 / 3127], [train loss 2.02531], [train acc 0.15182]\n",
      "[epoch 2], [iter 2300 / 3127], [train loss 2.02197], [train acc 0.15130]\n",
      "[epoch 2], [iter 2400 / 3127], [train loss 2.01927], [train acc 0.15333]\n",
      "[epoch 2], [iter 2500 / 3127], [train loss 2.01927], [train acc 0.15160]\n",
      "[epoch 2], [iter 2600 / 3127], [train loss 2.02038], [train acc 0.15000]\n",
      "[epoch 2], [iter 2700 / 3127], [train loss 2.01995], [train acc 0.14815]\n",
      "[epoch 2], [iter 2800 / 3127], [train loss 2.01825], [train acc 0.14857]\n",
      "[epoch 2], [iter 2900 / 3127], [train loss 2.01898], [train acc 0.14828]\n",
      "[epoch 2], [iter 3000 / 3127], [train loss 2.01780], [train acc 0.15033]\n",
      "[epoch 2], [iter 3100 / 3127], [train loss 2.01571], [train acc 0.15097]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.82079], [val acc 0.60733]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [iter 100 / 3127], [train loss 2.00356], [train acc 0.11000]\n",
      "[epoch 3], [iter 200 / 3127], [train loss 2.04186], [train acc 0.10500]\n",
      "[epoch 3], [iter 300 / 3127], [train loss 2.03494], [train acc 0.10667]\n",
      "[epoch 3], [iter 400 / 3127], [train loss 2.02736], [train acc 0.12500]\n",
      "[epoch 3], [iter 500 / 3127], [train loss 2.03138], [train acc 0.12600]\n",
      "[epoch 3], [iter 600 / 3127], [train loss 2.03163], [train acc 0.12500]\n",
      "[epoch 3], [iter 700 / 3127], [train loss 2.02547], [train acc 0.12714]\n",
      "[epoch 3], [iter 800 / 3127], [train loss 2.02466], [train acc 0.13125]\n",
      "[epoch 3], [iter 900 / 3127], [train loss 2.02693], [train acc 0.12667]\n",
      "[epoch 3], [iter 1000 / 3127], [train loss 2.02183], [train acc 0.12800]\n",
      "[epoch 3], [iter 1100 / 3127], [train loss 2.01897], [train acc 0.12818]\n",
      "[epoch 3], [iter 1200 / 3127], [train loss 2.01620], [train acc 0.13333]\n",
      "[epoch 3], [iter 1300 / 3127], [train loss 2.01629], [train acc 0.13231]\n",
      "[epoch 3], [iter 1400 / 3127], [train loss 2.01411], [train acc 0.13500]\n",
      "[epoch 3], [iter 1500 / 3127], [train loss 2.01581], [train acc 0.13400]\n",
      "[epoch 3], [iter 1600 / 3127], [train loss 2.01161], [train acc 0.13687]\n",
      "[epoch 3], [iter 1700 / 3127], [train loss 2.01057], [train acc 0.13588]\n",
      "[epoch 3], [iter 1800 / 3127], [train loss 2.00896], [train acc 0.13611]\n",
      "[epoch 3], [iter 1900 / 3127], [train loss 2.00772], [train acc 0.13579]\n",
      "[epoch 3], [iter 2000 / 3127], [train loss 2.00870], [train acc 0.13500]\n",
      "[epoch 3], [iter 2100 / 3127], [train loss 2.00704], [train acc 0.13714]\n",
      "[epoch 3], [iter 2200 / 3127], [train loss 2.00696], [train acc 0.13864]\n",
      "[epoch 3], [iter 2300 / 3127], [train loss 2.00572], [train acc 0.13957]\n",
      "[epoch 3], [iter 2400 / 3127], [train loss 2.00471], [train acc 0.13875]\n",
      "[epoch 3], [iter 2500 / 3127], [train loss 2.00349], [train acc 0.13880]\n",
      "[epoch 3], [iter 2600 / 3127], [train loss 2.00190], [train acc 0.14077]\n",
      "[epoch 3], [iter 2700 / 3127], [train loss 2.00156], [train acc 0.14074]\n",
      "[epoch 3], [iter 2800 / 3127], [train loss 2.00078], [train acc 0.14286]\n",
      "[epoch 3], [iter 2900 / 3127], [train loss 2.00054], [train acc 0.14276]\n",
      "[epoch 3], [iter 3000 / 3127], [train loss 1.99888], [train acc 0.14267]\n",
      "[epoch 3], [iter 3100 / 3127], [train loss 1.99713], [train acc 0.14484]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 69.63276], [val acc 0.01571]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [iter 100 / 3127], [train loss 1.99750], [train acc 0.12000]\n",
      "[epoch 4], [iter 200 / 3127], [train loss 1.98403], [train acc 0.14000]\n",
      "[epoch 4], [iter 300 / 3127], [train loss 1.97781], [train acc 0.13333]\n",
      "[epoch 4], [iter 400 / 3127], [train loss 1.98135], [train acc 0.13500]\n",
      "[epoch 4], [iter 500 / 3127], [train loss 1.97870], [train acc 0.13600]\n",
      "[epoch 4], [iter 600 / 3127], [train loss 1.96546], [train acc 0.13667]\n",
      "[epoch 4], [iter 700 / 3127], [train loss 1.96393], [train acc 0.14286]\n",
      "[epoch 4], [iter 800 / 3127], [train loss 1.97023], [train acc 0.14125]\n",
      "[epoch 4], [iter 900 / 3127], [train loss 1.96761], [train acc 0.15222]\n",
      "[epoch 4], [iter 1000 / 3127], [train loss 1.96075], [train acc 0.16100]\n",
      "[epoch 4], [iter 1100 / 3127], [train loss 1.96301], [train acc 0.15818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4], [iter 1200 / 3127], [train loss 1.96204], [train acc 0.15583]\n",
      "[epoch 4], [iter 1300 / 3127], [train loss 1.96504], [train acc 0.15308]\n",
      "[epoch 4], [iter 1400 / 3127], [train loss 1.96478], [train acc 0.15071]\n",
      "[epoch 4], [iter 1500 / 3127], [train loss 1.96466], [train acc 0.15467]\n",
      "[epoch 4], [iter 1600 / 3127], [train loss 1.96521], [train acc 0.15937]\n",
      "[epoch 4], [iter 1700 / 3127], [train loss 1.96379], [train acc 0.16176]\n",
      "[epoch 4], [iter 1800 / 3127], [train loss 1.96439], [train acc 0.16167]\n",
      "[epoch 4], [iter 1900 / 3127], [train loss 1.96395], [train acc 0.16105]\n",
      "[epoch 4], [iter 2000 / 3127], [train loss 1.96557], [train acc 0.16000]\n",
      "[epoch 4], [iter 2100 / 3127], [train loss 1.96631], [train acc 0.15667]\n",
      "[epoch 4], [iter 2200 / 3127], [train loss 1.96561], [train acc 0.15682]\n",
      "[epoch 4], [iter 2300 / 3127], [train loss 1.96505], [train acc 0.15609]\n",
      "[epoch 4], [iter 2400 / 3127], [train loss 1.96435], [train acc 0.15667]\n",
      "[epoch 4], [iter 2500 / 3127], [train loss 1.96467], [train acc 0.15640]\n",
      "[epoch 4], [iter 2600 / 3127], [train loss 1.96552], [train acc 0.15577]\n",
      "[epoch 4], [iter 2700 / 3127], [train loss 1.96559], [train acc 0.15222]\n",
      "[epoch 4], [iter 2800 / 3127], [train loss 1.96711], [train acc 0.15000]\n",
      "[epoch 4], [iter 2900 / 3127], [train loss 1.96722], [train acc 0.15138]\n",
      "[epoch 4], [iter 3000 / 3127], [train loss 1.96722], [train acc 0.14967]\n",
      "[epoch 4], [iter 3100 / 3127], [train loss 1.96739], [train acc 0.14806]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 53.29354], [val acc 0.31414]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [iter 100 / 3127], [train loss 1.97399], [train acc 0.11000]\n",
      "[epoch 5], [iter 200 / 3127], [train loss 1.96414], [train acc 0.14000]\n",
      "[epoch 5], [iter 300 / 3127], [train loss 1.94736], [train acc 0.14333]\n",
      "[epoch 5], [iter 400 / 3127], [train loss 1.94977], [train acc 0.14500]\n",
      "[epoch 5], [iter 500 / 3127], [train loss 1.95280], [train acc 0.15400]\n",
      "[epoch 5], [iter 600 / 3127], [train loss 1.95301], [train acc 0.14833]\n",
      "[epoch 5], [iter 700 / 3127], [train loss 1.95234], [train acc 0.14571]\n",
      "[epoch 5], [iter 800 / 3127], [train loss 1.94468], [train acc 0.15500]\n",
      "[epoch 5], [iter 900 / 3127], [train loss 1.95123], [train acc 0.15111]\n",
      "[epoch 5], [iter 1000 / 3127], [train loss 1.95312], [train acc 0.14900]\n",
      "[epoch 5], [iter 1100 / 3127], [train loss 1.95183], [train acc 0.15182]\n",
      "[epoch 5], [iter 1200 / 3127], [train loss 1.95360], [train acc 0.14833]\n",
      "[epoch 5], [iter 1300 / 3127], [train loss 1.95155], [train acc 0.15308]\n",
      "[epoch 5], [iter 1400 / 3127], [train loss 1.95112], [train acc 0.15929]\n",
      "[epoch 5], [iter 1500 / 3127], [train loss 1.95158], [train acc 0.15800]\n",
      "[epoch 5], [iter 1600 / 3127], [train loss 1.95222], [train acc 0.15812]\n",
      "[epoch 5], [iter 1700 / 3127], [train loss 1.95191], [train acc 0.15588]\n",
      "[epoch 5], [iter 1800 / 3127], [train loss 1.95217], [train acc 0.15667]\n",
      "[epoch 5], [iter 1900 / 3127], [train loss 1.95207], [train acc 0.15895]\n",
      "[epoch 5], [iter 2000 / 3127], [train loss 1.95073], [train acc 0.16350]\n",
      "[epoch 5], [iter 2100 / 3127], [train loss 1.95025], [train acc 0.16524]\n",
      "[epoch 5], [iter 2200 / 3127], [train loss 1.95098], [train acc 0.16364]\n",
      "[epoch 5], [iter 2300 / 3127], [train loss 1.94928], [train acc 0.16522]\n",
      "[epoch 5], [iter 2400 / 3127], [train loss 1.94878], [train acc 0.16375]\n",
      "[epoch 5], [iter 2500 / 3127], [train loss 1.94706], [train acc 0.16720]\n",
      "[epoch 5], [iter 2600 / 3127], [train loss 1.94731], [train acc 0.16808]\n",
      "[epoch 5], [iter 2700 / 3127], [train loss 1.94727], [train acc 0.16667]\n",
      "[epoch 5], [iter 2800 / 3127], [train loss 1.94807], [train acc 0.16607]\n",
      "[epoch 5], [iter 2900 / 3127], [train loss 1.94881], [train acc 0.16379]\n",
      "[epoch 5], [iter 3000 / 3127], [train loss 1.94881], [train acc 0.16333]\n",
      "[epoch 5], [iter 3100 / 3127], [train loss 1.94899], [train acc 0.16419]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 40.31390], [val acc 0.04712]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [iter 100 / 3127], [train loss 1.93326], [train acc 0.16000]\n",
      "[epoch 6], [iter 200 / 3127], [train loss 1.93731], [train acc 0.14500]\n",
      "[epoch 6], [iter 300 / 3127], [train loss 1.93291], [train acc 0.16667]\n",
      "[epoch 6], [iter 400 / 3127], [train loss 1.93406], [train acc 0.15250]\n",
      "[epoch 6], [iter 500 / 3127], [train loss 1.93272], [train acc 0.17000]\n",
      "[epoch 6], [iter 600 / 3127], [train loss 1.92742], [train acc 0.17500]\n",
      "[epoch 6], [iter 700 / 3127], [train loss 1.93109], [train acc 0.17286]\n",
      "[epoch 6], [iter 800 / 3127], [train loss 1.93175], [train acc 0.17750]\n",
      "[epoch 6], [iter 900 / 3127], [train loss 1.93170], [train acc 0.17667]\n",
      "[epoch 6], [iter 1000 / 3127], [train loss 1.93065], [train acc 0.17600]\n",
      "[epoch 6], [iter 1100 / 3127], [train loss 1.92715], [train acc 0.18636]\n",
      "[epoch 6], [iter 1200 / 3127], [train loss 1.92533], [train acc 0.18667]\n",
      "[epoch 6], [iter 1300 / 3127], [train loss 1.92758], [train acc 0.18462]\n",
      "[epoch 6], [iter 1400 / 3127], [train loss 1.92813], [train acc 0.18286]\n",
      "[epoch 6], [iter 1500 / 3127], [train loss 1.92377], [train acc 0.18600]\n",
      "[epoch 6], [iter 1600 / 3127], [train loss 1.92395], [train acc 0.18688]\n",
      "[epoch 6], [iter 1700 / 3127], [train loss 1.91794], [train acc 0.19294]\n",
      "[epoch 6], [iter 1800 / 3127], [train loss 1.91540], [train acc 0.19667]\n",
      "[epoch 6], [iter 1900 / 3127], [train loss 1.91385], [train acc 0.19895]\n",
      "[epoch 6], [iter 2000 / 3127], [train loss 1.91351], [train acc 0.19900]\n",
      "[epoch 6], [iter 2100 / 3127], [train loss 1.90947], [train acc 0.19952]\n",
      "[epoch 6], [iter 2200 / 3127], [train loss 1.90613], [train acc 0.20091]\n",
      "[epoch 6], [iter 2300 / 3127], [train loss 1.90782], [train acc 0.19739]\n",
      "[epoch 6], [iter 2400 / 3127], [train loss 1.90772], [train acc 0.19583]\n",
      "[epoch 6], [iter 2500 / 3127], [train loss 1.90781], [train acc 0.19760]\n",
      "[epoch 6], [iter 2600 / 3127], [train loss 1.90547], [train acc 0.19846]\n",
      "[epoch 6], [iter 2700 / 3127], [train loss 1.90379], [train acc 0.19889]\n",
      "[epoch 6], [iter 2800 / 3127], [train loss 1.90050], [train acc 0.20179]\n",
      "[epoch 6], [iter 2900 / 3127], [train loss 1.89639], [train acc 0.20379]\n",
      "[epoch 6], [iter 3000 / 3127], [train loss 1.89630], [train acc 0.20500]\n",
      "[epoch 6], [iter 3100 / 3127], [train loss 1.89349], [train acc 0.20484]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 2.03207], [val acc 0.53927]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [iter 100 / 3127], [train loss 1.79584], [train acc 0.28000]\n",
      "[epoch 7], [iter 200 / 3127], [train loss 1.85252], [train acc 0.24500]\n",
      "[epoch 7], [iter 300 / 3127], [train loss 1.82891], [train acc 0.26333]\n",
      "[epoch 7], [iter 400 / 3127], [train loss 1.83522], [train acc 0.24250]\n",
      "[epoch 7], [iter 500 / 3127], [train loss 1.82394], [train acc 0.24400]\n",
      "[epoch 7], [iter 600 / 3127], [train loss 1.82740], [train acc 0.23500]\n",
      "[epoch 7], [iter 700 / 3127], [train loss 1.81833], [train acc 0.24429]\n",
      "[epoch 7], [iter 800 / 3127], [train loss 1.81322], [train acc 0.24750]\n",
      "[epoch 7], [iter 900 / 3127], [train loss 1.81068], [train acc 0.24667]\n",
      "[epoch 7], [iter 1000 / 3127], [train loss 1.81160], [train acc 0.24000]\n",
      "[epoch 7], [iter 1100 / 3127], [train loss 1.80873], [train acc 0.24182]\n",
      "[epoch 7], [iter 1200 / 3127], [train loss 1.80751], [train acc 0.23833]\n",
      "[epoch 7], [iter 1300 / 3127], [train loss 1.80315], [train acc 0.24154]\n",
      "[epoch 7], [iter 1400 / 3127], [train loss 1.80352], [train acc 0.24357]\n",
      "[epoch 7], [iter 1500 / 3127], [train loss 1.80598], [train acc 0.24533]\n",
      "[epoch 7], [iter 1600 / 3127], [train loss 1.80540], [train acc 0.24750]\n",
      "[epoch 7], [iter 1700 / 3127], [train loss 1.80152], [train acc 0.24941]\n",
      "[epoch 7], [iter 1800 / 3127], [train loss 1.80507], [train acc 0.24611]\n",
      "[epoch 7], [iter 1900 / 3127], [train loss 1.80375], [train acc 0.24474]\n",
      "[epoch 7], [iter 2000 / 3127], [train loss 1.80305], [train acc 0.24500]\n",
      "[epoch 7], [iter 2100 / 3127], [train loss 1.80076], [train acc 0.24571]\n",
      "[epoch 7], [iter 2200 / 3127], [train loss 1.79922], [train acc 0.25000]\n",
      "[epoch 7], [iter 2300 / 3127], [train loss 1.79380], [train acc 0.24870]\n",
      "[epoch 7], [iter 2400 / 3127], [train loss 1.79229], [train acc 0.24708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7], [iter 2500 / 3127], [train loss 1.79255], [train acc 0.24640]\n",
      "[epoch 7], [iter 2600 / 3127], [train loss 1.79258], [train acc 0.24731]\n",
      "[epoch 7], [iter 2700 / 3127], [train loss 1.78834], [train acc 0.24926]\n",
      "[epoch 7], [iter 2800 / 3127], [train loss 1.78687], [train acc 0.24929]\n",
      "[epoch 7], [iter 2900 / 3127], [train loss 1.78378], [train acc 0.24931]\n",
      "[epoch 7], [iter 3000 / 3127], [train loss 1.78400], [train acc 0.24700]\n",
      "[epoch 7], [iter 3100 / 3127], [train loss 1.78516], [train acc 0.24581]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 3.37154], [val acc 0.52356]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [iter 100 / 3127], [train loss 1.63396], [train acc 0.36000]\n",
      "[epoch 8], [iter 200 / 3127], [train loss 1.67451], [train acc 0.33500]\n",
      "[epoch 8], [iter 300 / 3127], [train loss 1.67842], [train acc 0.32000]\n",
      "[epoch 8], [iter 400 / 3127], [train loss 1.68863], [train acc 0.30750]\n",
      "[epoch 8], [iter 500 / 3127], [train loss 1.69098], [train acc 0.31000]\n",
      "[epoch 8], [iter 600 / 3127], [train loss 1.70835], [train acc 0.28667]\n",
      "[epoch 8], [iter 700 / 3127], [train loss 1.71157], [train acc 0.28571]\n",
      "[epoch 8], [iter 800 / 3127], [train loss 1.71041], [train acc 0.28500]\n",
      "[epoch 8], [iter 900 / 3127], [train loss 1.71727], [train acc 0.28111]\n",
      "[epoch 8], [iter 1000 / 3127], [train loss 1.71860], [train acc 0.28300]\n",
      "[epoch 8], [iter 1100 / 3127], [train loss 1.72816], [train acc 0.27727]\n",
      "[epoch 8], [iter 1200 / 3127], [train loss 1.73581], [train acc 0.27333]\n",
      "[epoch 8], [iter 1300 / 3127], [train loss 1.72878], [train acc 0.28000]\n",
      "[epoch 8], [iter 1400 / 3127], [train loss 1.72634], [train acc 0.27857]\n",
      "[epoch 8], [iter 1500 / 3127], [train loss 1.72028], [train acc 0.28400]\n",
      "[epoch 8], [iter 1600 / 3127], [train loss 1.72000], [train acc 0.28563]\n",
      "[epoch 8], [iter 1700 / 3127], [train loss 1.71672], [train acc 0.28824]\n",
      "[epoch 8], [iter 1800 / 3127], [train loss 1.71102], [train acc 0.29056]\n",
      "[epoch 8], [iter 1900 / 3127], [train loss 1.71316], [train acc 0.28684]\n",
      "[epoch 8], [iter 2000 / 3127], [train loss 1.71073], [train acc 0.28700]\n",
      "[epoch 8], [iter 2100 / 3127], [train loss 1.71274], [train acc 0.28619]\n",
      "[epoch 8], [iter 2200 / 3127], [train loss 1.71147], [train acc 0.28682]\n",
      "[epoch 8], [iter 2300 / 3127], [train loss 1.70738], [train acc 0.28913]\n",
      "[epoch 8], [iter 2400 / 3127], [train loss 1.71004], [train acc 0.28875]\n",
      "[epoch 8], [iter 2500 / 3127], [train loss 1.70825], [train acc 0.29120]\n",
      "[epoch 8], [iter 2600 / 3127], [train loss 1.71031], [train acc 0.29192]\n",
      "[epoch 8], [iter 2700 / 3127], [train loss 1.70825], [train acc 0.29259]\n",
      "[epoch 8], [iter 2800 / 3127], [train loss 1.70676], [train acc 0.29500]\n",
      "[epoch 8], [iter 2900 / 3127], [train loss 1.70493], [train acc 0.29759]\n",
      "[epoch 8], [iter 3000 / 3127], [train loss 1.70531], [train acc 0.29567]\n",
      "[epoch 8], [iter 3100 / 3127], [train loss 1.70206], [train acc 0.29806]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 2.40853], [val acc 0.24084]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [iter 100 / 3127], [train loss 1.54653], [train acc 0.36000]\n",
      "[epoch 9], [iter 200 / 3127], [train loss 1.58762], [train acc 0.36000]\n",
      "[epoch 9], [iter 300 / 3127], [train loss 1.61338], [train acc 0.33667]\n",
      "[epoch 9], [iter 400 / 3127], [train loss 1.61077], [train acc 0.35000]\n",
      "[epoch 9], [iter 500 / 3127], [train loss 1.64069], [train acc 0.34200]\n",
      "[epoch 9], [iter 600 / 3127], [train loss 1.63082], [train acc 0.35167]\n",
      "[epoch 9], [iter 700 / 3127], [train loss 1.62133], [train acc 0.35000]\n",
      "[epoch 9], [iter 800 / 3127], [train loss 1.62602], [train acc 0.34750]\n",
      "[epoch 9], [iter 900 / 3127], [train loss 1.62565], [train acc 0.34556]\n",
      "[epoch 9], [iter 1000 / 3127], [train loss 1.62197], [train acc 0.34900]\n",
      "[epoch 9], [iter 1100 / 3127], [train loss 1.62975], [train acc 0.34727]\n",
      "[epoch 9], [iter 1200 / 3127], [train loss 1.62946], [train acc 0.34333]\n",
      "[epoch 9], [iter 1300 / 3127], [train loss 1.61488], [train acc 0.34692]\n",
      "[epoch 9], [iter 1400 / 3127], [train loss 1.61585], [train acc 0.35071]\n",
      "[epoch 9], [iter 1500 / 3127], [train loss 1.60951], [train acc 0.35733]\n",
      "[epoch 9], [iter 1600 / 3127], [train loss 1.59985], [train acc 0.36375]\n",
      "[epoch 9], [iter 1700 / 3127], [train loss 1.60236], [train acc 0.36118]\n",
      "[epoch 9], [iter 1800 / 3127], [train loss 1.59124], [train acc 0.36722]\n",
      "[epoch 9], [iter 1900 / 3127], [train loss 1.59791], [train acc 0.36263]\n",
      "[epoch 9], [iter 2000 / 3127], [train loss 1.59050], [train acc 0.36600]\n",
      "[epoch 9], [iter 2100 / 3127], [train loss 1.58941], [train acc 0.36762]\n",
      "[epoch 9], [iter 2200 / 3127], [train loss 1.58098], [train acc 0.37227]\n",
      "[epoch 9], [iter 2300 / 3127], [train loss 1.57655], [train acc 0.37522]\n",
      "[epoch 9], [iter 2400 / 3127], [train loss 1.57818], [train acc 0.37458]\n",
      "[epoch 9], [iter 2500 / 3127], [train loss 1.57494], [train acc 0.37640]\n",
      "[epoch 9], [iter 2600 / 3127], [train loss 1.57128], [train acc 0.37808]\n",
      "[epoch 9], [iter 2700 / 3127], [train loss 1.56572], [train acc 0.37815]\n",
      "[epoch 9], [iter 2800 / 3127], [train loss 1.56087], [train acc 0.38214]\n",
      "[epoch 9], [iter 2900 / 3127], [train loss 1.55427], [train acc 0.38483]\n",
      "[epoch 9], [iter 3000 / 3127], [train loss 1.54726], [train acc 0.38633]\n",
      "[epoch 9], [iter 3100 / 3127], [train loss 1.54145], [train acc 0.38871]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 6.37970], [val acc 0.47120]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [iter 100 / 3127], [train loss 1.29647], [train acc 0.54000]\n",
      "[epoch 10], [iter 200 / 3127], [train loss 1.38536], [train acc 0.48500]\n",
      "[epoch 10], [iter 300 / 3127], [train loss 1.43220], [train acc 0.46333]\n",
      "[epoch 10], [iter 400 / 3127], [train loss 1.46187], [train acc 0.45750]\n",
      "[epoch 10], [iter 500 / 3127], [train loss 1.43025], [train acc 0.45800]\n",
      "[epoch 10], [iter 600 / 3127], [train loss 1.42816], [train acc 0.45167]\n",
      "[epoch 10], [iter 700 / 3127], [train loss 1.42333], [train acc 0.45286]\n",
      "[epoch 10], [iter 800 / 3127], [train loss 1.43200], [train acc 0.44500]\n",
      "[epoch 10], [iter 900 / 3127], [train loss 1.42591], [train acc 0.44444]\n",
      "[epoch 10], [iter 1000 / 3127], [train loss 1.43813], [train acc 0.44200]\n",
      "[epoch 10], [iter 1100 / 3127], [train loss 1.43507], [train acc 0.44545]\n",
      "[epoch 10], [iter 1200 / 3127], [train loss 1.43086], [train acc 0.44333]\n",
      "[epoch 10], [iter 1300 / 3127], [train loss 1.44011], [train acc 0.43769]\n",
      "[epoch 10], [iter 1400 / 3127], [train loss 1.43069], [train acc 0.44143]\n",
      "[epoch 10], [iter 1500 / 3127], [train loss 1.42218], [train acc 0.43933]\n",
      "[epoch 10], [iter 1600 / 3127], [train loss 1.42455], [train acc 0.43812]\n",
      "[epoch 10], [iter 1700 / 3127], [train loss 1.42004], [train acc 0.43941]\n",
      "[epoch 10], [iter 1800 / 3127], [train loss 1.40526], [train acc 0.44444]\n",
      "[epoch 10], [iter 1900 / 3127], [train loss 1.41411], [train acc 0.43895]\n",
      "[epoch 10], [iter 2000 / 3127], [train loss 1.41072], [train acc 0.44300]\n",
      "[epoch 10], [iter 2100 / 3127], [train loss 1.40642], [train acc 0.44667]\n",
      "[epoch 10], [iter 2200 / 3127], [train loss 1.39669], [train acc 0.45045]\n",
      "[epoch 10], [iter 2300 / 3127], [train loss 1.40201], [train acc 0.44783]\n",
      "[epoch 10], [iter 2400 / 3127], [train loss 1.39766], [train acc 0.44625]\n",
      "[epoch 10], [iter 2500 / 3127], [train loss 1.39095], [train acc 0.44720]\n",
      "[epoch 10], [iter 2600 / 3127], [train loss 1.38912], [train acc 0.44769]\n",
      "[epoch 10], [iter 2700 / 3127], [train loss 1.38876], [train acc 0.44852]\n",
      "[epoch 10], [iter 2800 / 3127], [train loss 1.38863], [train acc 0.44643]\n",
      "[epoch 10], [iter 2900 / 3127], [train loss 1.38317], [train acc 0.45034]\n",
      "[epoch 10], [iter 3000 / 3127], [train loss 1.37868], [train acc 0.45133]\n",
      "[epoch 10], [iter 3100 / 3127], [train loss 1.37278], [train acc 0.45419]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [val loss 22.21402], [val acc 0.23560]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(num = 2)\n",
    "fig1 = fig.add_subplot(2,1,1)\n",
    "fig2 = fig.add_subplot(2,1,2)\n",
    "fig1.plot(total_loss_train, label = 'training loss')\n",
    "fig1.plot(total_acc_train, label = 'training accuracy')\n",
    "fig2.plot(np.array(total_loss_val) / (np.max(np.array(total_loss_val))), label = 'validation loss normalized')\n",
    "fig2.plot(total_acc_val, label = 'validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "y_label = []\n",
    "y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        y_label.extend(labels.cpu().numpy())\n",
    "        y_predict.extend(prediction.cpu().numpy().T)\n",
    "        #y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_label, y_predict)\n",
    "# plot the confusion matrix\n",
    "plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'nv', 'vasc','mel']\n",
    "plot_confusion_matrix(confusion_mtx, plot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predict.extend(prediction.cpu().numpy().T)\n",
    "#print(np.squeeze(prediction.cpu().numpy().T))\n",
    "#np.squeeze(prediction.cpu().numpy().T)\n",
    "#y_predict.extend(np.array([3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.00      0.00      0.00       1.0\n",
      "         bcc       0.00      0.00      0.00       3.0\n",
      "         bkl       0.00      0.00      0.00       6.0\n",
      "          df       0.00      0.00      0.00       0.0\n",
      "          nv       0.00      0.00      0.00      26.0\n",
      "        vasc       0.00      0.00      0.00       1.0\n",
      "         mel       0.00      0.00      0.00       3.0\n",
      "\n",
      "    accuracy                           0.00      40.0\n",
      "   macro avg       0.00      0.00      0.00      40.0\n",
      "weighted avg       0.00      0.00      0.00      40.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elias\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elias\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elias\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elias\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elias\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "report = classification_report(y_label, y_predict, target_names=plot_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elias\\AppData\\Local\\Temp/ipykernel_2092/1127229655.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Fraction classified incorrectly')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
    "plt.bar(np.arange(7),label_frac_error)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction classified incorrectly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to train with different network structures. When using Densenet-121, the average accuracy of 7 classes on the validation set can reach 92% in 10 epochs. We also calculated the confusion matrix for all classes and the F1-score for each class, which is a more comprehensive indicator that can take into account both the precision and recall of the classification model.Our model can achieve more than 90% on the F1-score indicator.\n",
    "\n",
    "Due to limited time, we did not spend much time on model training. By increasing in training epochs, adjustmenting of model hyperparameters, and attempting at different networks may further enhance the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use image data and patient case data at the same time, my plan is to use CNN to extract features from images, use xgboost to convert medical records into vectors and then concat them with CNN network full-layer features. Two branch networks are trained simultaneously using a loss function. We can refer to the methods used in the advertising CTR estimation task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
